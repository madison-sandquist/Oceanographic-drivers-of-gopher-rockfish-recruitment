---
title: "Recruitment Devs"
author: "Madison Sandquist"
date: "2025-03-14"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Libraries Needed
```{r, results='hide'}
library(tidyverse)
library(ggplot2)
library(ggeffects)
library(car)
library(broom)
library(tidyr)
library(purrr)
library(lme4)
library(lmerTest)
library(glmmTMB)
library(brms)
library(factoextra)  # For visualizing PCA results
library(DHARMa)
library(emmeans)#pairwise comparisons
library(influence.ME) #outlier
library(mgcv) #GAM
library("wesanderson")
#remotes::install_github("r4ss/r4ss")
library(FactoMineR)
library(factoextra)
library(plotly)
library(pls)
library(plsVarSel)
library(wesanderson)
library(patchwork)
library(zoo)
```

# Increasing font size for graphs and colors
```{r}
full_palette <- wes_palette("Moonrise2", type = "discrete")
ESM_colors <- c("GFDL" = full_palette[1], 
                      "HADL" = full_palette[2],
                 "IPSL" = full_palette[3])

parameter_colors <- ("value" = full_palette[1])

# Set theme with larger axis titles and numbers
larger_axis_theme <-
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(color = "black"),
    legend.position = "none",
    axis.title = element_text(size = 16),   # Axis titles
    axis.text = element_text(size = 14),
    title = element_text(size = 20)# Axis numbers
  )

colors <- wes_palette("AsteroidCity1", type = "discrete")

spatial_colors <- c("mid" = colors[1], 
                      "north" = colors[4],
                 "south" = colors[3], 
                 "all" = colors[2])
```


# Ocean model outputs 
```{r}
# Load the ocean data that was produced in python
ocean <- read.csv("Data/may_july_averages_1995_2020.csv")
wind <- read.csv('Data/vwind_offshore_may_july_1995_2020.csv')
ocean_2 <- read.csv("Data/may_june_1995_2020.csv")
ocean_3 <- read.csv("Data/march_june_1995_2020.csv")
monthly_averages <- read.csv('Data/monthly_averages_1995_2020.csv')
monthly_averages_all_year <- read.csv('Data/monthly_averages_allyear_1995_2020.csv')
monthly_averages_wind_1 <- read.csv("Data/monthly_vwind_offshore_averages.csv")
monthly_averages_wind_2 <- read.csv("Data/monthly_vwind_offshore_averages_at_25km.csv")
monthy_averages_wind_allyear <- read.csv("Data/monthly_vwind_offshore_averages_all_months.csv")


monthy_averages_wind_allyear <- monthy_averages_wind_allyear %>%
  mutate(Month = case_when(
    Month == "January"   ~ "Jan",
    Month == "February"  ~ "Feb",
    Month == "March"     ~ "Mar",
    Month == "April"     ~ "Apr",
    Month == "May"       ~ "May",
    Month == "June"      ~ "Jun",
    Month == "July"      ~ "Jul",
    Month == "August"    ~ "Aug",
    Month == "September" ~ "Sep",
    Month == "October"   ~ "Oct",
    Month == "November"  ~ "Nov",
    Month == "December"  ~ "Dec",
    TRUE ~ Month  # keep original if no match
  ))

monthly_averages_all_year <- monthly_averages_all_year %>%
  mutate(Month = case_when(
    Month == "January"   ~ "Jan",
    Month == "February"  ~ "Feb",
    Month == "March"     ~ "Mar",
    Month == "April"     ~ "Apr",
    Month == "May"       ~ "May",
    Month == "June"      ~ "Jun",
    Month == "July"      ~ "Jul",
    Month == "August"    ~ "Aug",
    Month == "September" ~ "Sep",
    Month == "October"   ~ "Oct",
    Month == "November"  ~ "Nov",
    Month == "December"  ~ "Dec",
    TRUE ~ Month  # keep original if no match
  ))



wind <- wind %>% 
  mutate(Wind = Mean) %>% 
  mutate(Wind_SD = SD) %>% 
  select(Wind,Year,Wind_SD)



# Combine into one data frame 
ROMS_outputs <- left_join(ocean, wind, by = c("Year"))

# Combine into one data frame 
ROMS_output_monthly <- left_join(monthly_averages, monthly_averages_wind_2, by = c("Year", "Month"))

monthly_averages_all_year <- left_join(monthly_averages_all_year, monthy_averages_wind_allyear, by = c("Year", "Month"))

ROMS_output_monthly <- ROMS_output_monthly %>%
  mutate(Month = case_match(Month,
                            "Feb"   ~ "Feb",
                            "March" ~ "Mar",
                            "April" ~ "Apr",
                            "May"   ~ "May",
                            "June"  ~ "Jun",
                            "July"  ~ "Jul"))

# March month only
march_ROMS <- monthly_averages %>% 
  filter(Month == "March")
march_ROMS_wind <- monthly_averages_wind_2 %>% 
  filter(Month == "March")
march_ROMS_outputs_ <- left_join(march_ROMS, march_ROMS_wind, by = c("Year"))

# July month only
July_ROMS <- monthly_averages %>% 
  filter(Month == "July")
July_ROMS_wind <- monthly_averages_wind_2 %>% 
  filter(Month == "July")
July_ROMS_outputs_ <- left_join(July_ROMS, July_ROMS_wind, by = c("Year"))
```



# Ocean Models outputs spatially separated 
```{r}
# Load the ocean data that was produced in python 
monthly_averages_south <- read.csv('Data/monthly_averages_allyear_1995_2020_37to34p4.csv')
monthly_averages_mid <- read.csv('Data/monthly_averages_allyear_1995_2020_39to37.csv')
monthly_averages_north <- read.csv('Data/monthly_averages_allyear_1995_2020_41to39.csv')

#put into one data set
monthly_averages_spatial <- bind_rows(
  monthly_averages_south %>% mutate(region = "south"),
  monthly_averages_mid   %>% mutate(region = "mid"),
  monthly_averages_north %>% mutate(region = "north")
) %>%
  mutate(region = factor(region, levels = c("south", "mid", "north")))

# load in wind csv
monthly_wind_averages_south <- read.csv('Data/monthly_Vwind_offshore_averages_37to34p4.csv')
monthly_wind_averages_mid <- read.csv('Data/monthly_Vwind_offshore_averages_39to37.csv')
monthly_wind_averages_north <- read.csv('Data/monthly_Vwind_offshore_averages_41to39.csv')

#combined
monthly_averages_spatial_wind <- bind_rows(
  monthly_wind_averages_south %>% mutate(region = "south"),
  monthly_wind_averages_mid   %>% mutate(region = "mid"),
  monthly_wind_averages_north %>% mutate(region = "north")
) %>%
  mutate(region = factor(region, levels = c("south", "mid", "north")))

monthly_averages_spatial_wind <- monthly_averages_spatial_wind %>%
  mutate(Month = case_when(
    Month == "January"   ~ "Jan",
    Month == "February"  ~ "Feb",
    Month == "March"     ~ "Mar",
    Month == "April"     ~ "Apr",
    Month == "May"       ~ "May",
    Month == "June"      ~ "Jun",
    Month == "July"      ~ "Jul",
    Month == "August"    ~ "Aug",
    Month == "September" ~ "Sep",
    Month == "October"   ~ "Oct",
    Month == "November"  ~ "Nov",
    Month == "December"  ~ "Dec",
    TRUE ~ Month  # keep original if no match
  ))

monthly_averages_spatial <- monthly_averages_spatial %>%
  mutate(Month = case_when(
    Month == "January"   ~ "Jan",
    Month == "February"  ~ "Feb",
    Month == "March"     ~ "Mar",
    Month == "April"     ~ "Apr",
    Month == "May"       ~ "May",
    Month == "June"      ~ "Jun",
    Month == "July"      ~ "Jul",
    Month == "August"    ~ "Aug",
    Month == "September" ~ "Sep",
    Month == "October"   ~ "Oct",
    Month == "November"  ~ "Nov",
    Month == "December"  ~ "Dec",
    TRUE ~ Month  # keep original if no match
  ))

# Combine into one data frame 
ROMS_output_monthly_spatial <- left_join(monthly_averages_spatial, monthly_averages_spatial_wind, by = c("Year", "Month", "region"))

ROMS_output_monthly_spatial_2 <-  ROMS_output_monthly_spatial %>% 
  select(!Vwind_sd)

#combined with averaged spatial scale 
monthly_averages_all_year_combine  <- monthly_averages_all_year %>% 
  mutate(region = "all")

ROMS_output_monthly_NMSA <- rbind(ROMS_output_monthly_spatial_2, monthly_averages_all_year_combine)
```




# Coastal Upwelling Transport Index
```{r}
cuti <- read.csv("Data/CUTI_daily.csv") %>% 
  select(year, month, day,X34N, X35N,X36N,X37N,X38N,
         X39N,X40N,X41N) %>% 
  #filter(year > 1994) %>% 
  filter(year < 2020) 


monthly_yearly_averages_lat_cuti <- cuti %>%
  group_by(year) %>%
  summarise(across(starts_with("X"), mean, na.rm = TRUE)) %>% 
  rename(Year = year)


yearly_averages_cuti <- cuti %>%
  group_by(year, month) %>%
  summarise(across(starts_with("X"), mean, na.rm = TRUE), .groups = "drop") %>%
  mutate(
    average_CUTI = rowMeans(select(., starts_with("X")), na.rm = TRUE)
  ) %>%
  rename(Year = year) %>%
  rename (Month = month)%>% 
  select(Month, average_CUTI, Year)

yearly_averages_cuti


yearly_averages_cuti_spatially <- cuti %>%
  # 1) Average each latitude within month/year (averages over days)
  group_by(year, month) %>%
  summarise(across(starts_with("X"), ~ mean(.x, na.rm = TRUE)), .groups = "drop") %>%
  # 2) Compute regional means and overall mean across all lats
  mutate(
    north_CUTI = rowMeans(select(., matches("^X(39|40|41)N$")), na.rm = TRUE),
    mid_CUTI   = rowMeans(select(., matches("^X(37|38)N$")),    na.rm = TRUE),
    south_CUTI = rowMeans(select(., matches("^X(34|35|36)N$")), na.rm = TRUE),
    average_CUTI = rowMeans(select(., starts_with("X")), na.rm = TRUE)  # mean across ALL lats
  ) %>%
  rename(Year = year, Month = month) %>%
  select(Year, Month, north_CUTI, mid_CUTI, south_CUTI, average_CUTI) %>%
  arrange(Year, Month)

```

```{r}
library(stringr)

# 1) Monthly mean for each latitude (averaging over days)
monthly_lat <- cuti %>%
  group_by(year, month) %>%
  summarise(across(starts_with("X"), ~ mean(.x, na.rm = TRUE)), .groups = "drop") %>%
  pivot_longer(cols = starts_with("X"), names_to = "lat_col", values_to = "CUTI") %>%
  mutate(lat = as.integer(str_extract(lat_col, "\\d+"))) %>%
  filter(between(lat, 34, 41))

# 2) Region means (equal weight per latitude within each region)
by_region <- monthly_lat %>%
  mutate(region = case_when(
    lat %in% 39:41 ~ "north",
    lat %in% 37:38 ~ "mid",
    lat %in% 34:36 ~ "south",
    TRUE ~ NA_character_
  )) %>%
  filter(!is.na(region)) %>%
  group_by(year, month, region) %>%
  summarise(CUTI = mean(CUTI, na.rm = TRUE), .groups = "drop")

# 3) "all" = mean across all eight latitudes (matches your previous rowMeans)
overall <- monthly_lat %>%
  group_by(year, month) %>%
  summarise(CUTI = mean(CUTI, na.rm = TRUE), .groups = "drop") %>%
  mutate(region = "all")

# Final tidy table
cuti_tidy <- bind_rows(by_region, overall) %>%
  rename(Year = year, Month = month) %>%
  arrange(Year, Month, factor(region, levels = c("north", "mid", "south", "all")))

cuti_tidy %>% 
  filter(Year > 1994)

cuti_tidy <- cuti_tidy %>%
  dplyr::mutate(region = factor(region, levels = c("north", "mid", "south", "all"))) %>%
  dplyr::arrange(Year, Month, region)  # uses the factor order %>% 

cuti_tidy$Month <- is.factor(cuti_tidy$Month)

cuti_tidy <- bind_rows(by_region, overall) %>%
  rename(Year = year, Month = month) %>%
  mutate(
    # region factor (if you still want it)
    region = factor(region, levels = c("north", "mid", "south", "all")),
    # Month as character "Jan".."Dec"
    Month  = month.abb[as.integer(Month)]
  ) %>%
  # keep chronological order after converting Month to text
  arrange(Year, match(Month, month.abb), region)


```

# SL
```{r}
sl <- read.csv("Data/Sea_surf_annomalies.csv")

monthly_avg_sl <- sl %>%
  mutate(time = ymd_hms(time),
         year = year(time),
         month = month(time)) %>%
  group_by(year, month) %>%
  summarize(mean_sl = mean(sea_level, na.rm = TRUE), .groups = "drop") %>%
  rename(Year = year, Month = month)
```

# PDO
```{r}
pdo <- read.csv("Data/PDO_monthly.csv")

monthly_avg_pdo <- pdo %>%
  mutate(time = ymd_hms(time),
         year = year(time),
         month = month(time)) %>%
  group_by(year, month) %>%
  summarize(mean_pdo = mean(PDO, na.rm = TRUE), .groups = "drop") %>%
  rename(Year = year, Month = month)

pdo <- read.csv("Data/pdo.timeseries.sstens.csv")

# Convert the Date column to Date type
pdo$Date <- as.Date(pdo$Date)

# Filter the dataframe between 1995 and 2018
monthly_avg_pdo <- pdo %>%
  filter(Date >= as.Date("1995-01-01") & Date <= as.Date("2018-12-01")) %>% 
  rename(mean_pdo = PDO.from.Ensemble.SST.https...psl.noaa.gov..pdo..Using.EOF.from.1920.to.2014.for.N.Pacific..see.webpage.) %>% 
    mutate(
    Year = year(Date),
    Month = month(Date)
  )

```

# NPGO
```{r}
npgo <- read.csv("Data/npgo.csv")
npgo

monthly_avg_npgo <- npgo %>%
  mutate(Date = mdy(Date),
         Year = year(Date),
         Month = month(Date)) %>%
  filter(Year > 1994 & Year < 2019) %>%
  group_by(Year, Month) %>%
  summarise(npgo_avg = mean(NPGO, na.rm = TRUE), .groups = "drop")

monthly_avg_npgo
```

# ONI
```{r}
ONI <- read.csv("Data/ONI_data.csv")

monthly_avg_ONI <- ONI %>%
  pivot_longer(
    cols = all_of(month.abb),  # Ensures only "Jan" to "Dec"
    names_to = "Month_name",
    values_to = "oni_avg"
  ) %>%
  mutate(
    Month = match(Month_name, month.abb)
  ) %>%
  select(Year, Month, oni_avg) %>%
  arrange(Year, Month)

print(monthly_avg_ONI)
```




# Combine indicies into two dataframes
there will be on for parameters separated by region and parameters that are not separated by region
```{r}
combined_monthly_indices_NOT_SPATIAL <- monthly_avg_sl %>%
  full_join(monthly_avg_pdo, by = c("Year", "Month")) %>%
  full_join(monthly_avg_npgo, by = c("Year", "Month")) %>%
  full_join(monthly_avg_ONI, by = c("Year", "Month")) %>%
  arrange(Year, Month) %>%
  filter(Year > 1994, Year < 2020) %>%
 # filter(Month %in% 2:7) %>%  
  mutate(Month = month.abb[Month])  

# Combined with ROMS with cuti 
ROMS_CUTI_environmental_combined_all_yr <- ROMS_output_monthly_NMSA %>%
  full_join(cuti_tidy, by = c("Year", "Month", "region"))

# Select for march only for ROMS 
ROMS_environmental_combined_mar_only <- ROMS_CUTI_environmental_combined_all_yr %>% 
  filter(Month == "Mar")
print(ROMS_environmental_combined_mar_only)

combined_monthly_indices_mar_only <- combined_monthly_indices %>% 
  filter(Month == "Mar")

#July only
ROMS_environmental_combined_july_only <- ROMS_environmental_combined %>% 
  filter(Month == "Jul")
print(ROMS_environmental_combined_july_only)

# Make data frame that is feb - july average 
ROMS_feb_july_avg <- ROMS_environmental_combined %>%
  group_by(Year) %>%
  summarise(across(
    c(DO_avg, pH_avg, Temperature_avg, Chla_avg, Vwind_avg,
      mean_sl, mean_pdo, npgo_avg, oni_avg, average_CUTI),
    ~ mean(.x, na.rm = TRUE),
    .names = "mean_{.col}"
  )) %>%
  ungroup()

ROMS_feb_july_avg
```

# gopher rockfish stock assessment
```{r}
#recommended work flow, define model directory
# this is the files from the pfmc website 
model_path <- "Old_stock_assessments/GPBY"
goph2019 <- r4ss::SS_output(model_path, printstats = FALSE)
with.covar = T	 
parameters <- goph2019$parameters
goph_recruit <- goph2019$recruit

#not filtered for graphing 
goph_recruit_nf <-goph_recruit %>% 
  filter(Yr >= 1987, Yr <= 2018) %>% 
  rename(Year = Yr)

#filter for years
goph_recruit <-goph_recruit %>% 
  filter(Yr >= 1995, Yr <= 2018) %>% 
  rename(Year = Yr) %>% 
  mutate(Species = "gopher")

```

# PLSR - spatially separated YEAR
## PLSR YEAR spatially separated, all regions averaged 
```{r}
# combined 
ROMS_CUTI_environmental_combined_average <- ROMS_CUTI_environmental_combined_all_yr %>% 
  filter(Region == 'all') %>% 
  #filter(Month %in% c("Feb", "Mar", "Apr", "May", "Jun", "Jul")) %>% 
  group_by(Year) %>%
  summarise(across(
    c(DO_avg, pH_avg, Temperature_avg, Chla_avg, Vwind_avg,CUTI),
    ~ mean(.x, na.rm = TRUE),
    .names = "mean_{.col}"
  )) %>%
  ungroup()

df_gopher <-left_join(ROMS_CUTI_environmental_combined_average,goph_recruit, by = "Year")

df_gopher <- df_gopher %>% 
  select(dev, mean_CUTI,mean_pH_avg, mean_DO_avg, mean_Temperature_avg, mean_Chla_avg, mean_Vwind_avg) %>% 
  rename(deviation = dev,
         CUTI = mean_CUTI,
         pH = mean_pH_avg, 
         DO = mean_DO_avg, 
         Temperature = mean_Temperature_avg, 
         "Primary Production" = mean_Chla_avg, 
         "Meridonal Wind" = mean_Vwind_avg)

# Define X and Y together and filter complete cases
X_raw <- df_gopher %>% 
  select(CUTI, "Meridonal Wind" ,pH, DO, Temperature, "Primary Production")

# Combine into one frame with response
data_complete <- cbind(deviation = df_gopher$deviation, X_raw) %>% 
  as.data.frame() %>% 
  na.omit()  # remove rows with any NA

# Now separate into X and Y
Y <- data_complete$deviation
X <- as.matrix(data_complete %>% select(-deviation))

plsr <- plsr(deviation ~ ., data = data_complete, scale = TRUE, validation = "LOO")
pls_scores <- scores(plsr)

df_pls <- data.frame(
  dev = Y,
  Comp1 = pls_scores[, 1],
  Comp2 = pls_scores[, 2]
)

# Summary of model
summary(plsr)

# Root Mean Squared Error of Prediction
RMSEP(plsr)

# Choose number of components based on RMSEP or % variance explained
plot(RMSEP(plsr), legendpos = "topright")

# Variance explained
explvar(plsr)  # % of variance explained in X by each component

# Component loadings: how original vars contribute to latent variables
loadings(plsr)

# Scores: the new coordinate representation of observations
pls_scores <- scores(plsr)

# Biplot: visualize scores and loadings
biplot(plsr_march, comps = 1:2)

# Fit a linear model using first 2 PLS components
lm_pls <- lm(dev ~ Comp1 + Comp2, data = df_pls)
summary(lm_pls)

# check residuals 
simulated_res <- simulateResiduals(fittedModel = lm_pls)
plot(simulated_res) #these look good

selectNcomp(plsr, method = "onesigma")

lm_pls_1comp <- lm(dev ~ Comp1, data = df_pls)
summary(lm_pls_1comp)

plot(RMSEP(plsr), legendpos = "topright")

# 1-component model is optimal, so we use opt.comp = 1
vip_scores <- VIP(plsr, opt.comp = 1)

# Turn into data frame properly
vip_df <- data.frame(
  Variable = names(vip_scores),
  VIP = vip_scores
)

ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = .8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "Variable Importance in Projection (VIP)",
       x = "Predictor",
       y = "VIP Score")
```

### table of correlations and weights
```{r}
# Choose which component to analyze 
comp_num <- 1

# 1. WEIGHT² - Variable importance/contribution to the component
weights_raw <- loading.weights(plsr)[, comp_num]
weights_squared <- weights_raw^2

# 2. CORRELATION - Between each predictor and the response variable
# Get the names of predictors used in the PLS model
predictor_names <- colnames(X)

# Use same predictors from the original full dataset for correlation
X_original <- plsr$model %>% select(all_of(predictor_names))
Y_original <- plsr$model$dev  # <-- Fixed line

# Ensure there are no NAs in either X_original or Y_original
complete_rows <- complete.cases(X_original, Y_original)
X_original <- X_original[complete_rows, ]
Y_original <- Y_original[complete_rows]

# Calculate correlations
correlations <- cor(X_original, Y_original)

# 3. LOADING - Direction and magnitude
loadings_values <- loadings(plsr)[, comp_num]

# Create summary table
pls_summary_table <- data.frame(
  Predictor = predictor_names,
  Weight_squared = round(weights_squared, 3),
  Correlation = round(correlations, 3),
  Loading_value = round(loadings_values, 3),
  Loading_direction = ifelse(loadings_values > 0, "+", "-")
)

# View the table
print(pls_summary_table)
```




### figure for plsr
```{r}
library(ggplot2)
library(gridExtra)
library(grid)

# Extract predictor names from X
predictor_names <- colnames(X)

# ========== FIGURE A: PLS BIPLOT ==========

loadings_data <- loadings(plsr_march)[, 1:2]
loadings_df <- data.frame(
  Variable = rownames(loadings_data),
  Component1 = loadings_data[, 1],
  Component2 = loadings_data[, 2]
)

fig_a_all <- ggplot(loadings_df, aes(x = Component1, y = Component2)) +
  geom_path(data = data.frame(
    x = cos(seq(0, 2 * pi, length.out = 100)),
    y = sin(seq(0, 2 * pi, length.out = 100))
  ), aes(x = x, y = y), color = "black", linewidth = 1) +

  # Arrows and labels
  geom_segment(aes(x = 0, y = 0, xend = Component1, yend = Component2),
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "steelblue", linewidth = 1.2) +
  geom_text(aes(label = Variable), 
            color = "steelblue", size = 4, fontface = "bold",
            nudge_x = ifelse(loadings_df$Component1 > 0, 0.05, -0.05),
            nudge_y = ifelse(loadings_df$Component2 > 0, 0.05, -0.05)) +
  
  # Optional: Response direction (illustrative only)
  # You can calculate actual correlation direction if desired
  geom_segment(aes(x = 0, y = 0, xend = 0.6, yend = 0.4), 
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "indianred", linewidth = 1.5) +
  geom_text(aes(x = 0.68, y = 0.45, label = "Recruitment"), 
             color = "indianred", size = 4, fontface = "bold") +
  
  xlim(-1.1, 1.1) + ylim(-1.1, 1.1) +
  labs(x = "Component 1", y = "Component 2", title = "") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  coord_fixed()


# ========== FIGURE B: COMPONENT 1 vs RESPONSE ==========

# Ensure response is matched to filtered data
component1_scores <- scores(plsr_march)[, 1]
response_var <- Y  # this Y comes from the filtered, complete-case data

# Compute R² and p-value
var_explained <- explvar(plsr_march)[1]
lm_comp1 <- lm(response_var ~ component1_scores)
lm_summary <- summary(lm_comp1)
p_value <- lm_summary$coefficients[2, 4]
r_squared <- lm_summary$r.squared

# Format p-value
p_text <- if (p_value < 0.001) {
  "p < 0.001"
} else if (p_value < 0.01) {
  paste0("p = ", format(round(p_value, 3), nsmall = 3))
} else {
  paste0("p = ", format(round(p_value, 2), nsmall = 2))
}

annotation_text <- paste0("R² = ", format(round(r_squared, 3), nsmall = 3), "\n", p_text)

fig_b_all <- ggplot(data.frame(Component1 = component1_scores, Response = response_var),
                aes(x = Component1, y = Response)) +
  geom_point(size = 2.5, alpha = 0.7) +
  geom_smooth(method = "lm", color = "steelblue", fill = "black", alpha = 0.3) +
  annotate("text", 
           x = Inf, y = Inf, 
           label = annotation_text,
           hjust = 1.3, vjust = 1.3,
           size = 4, 
           fontface = "bold",
           color = "black") +
  labs(
    x = paste0("PLSR component 1 (", round(var_explained, 1), "%)"),
    y = "Recruitment Deviations",
    title = "Entire Region"
  ) +
  theme_classic() +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )



# ========== FIGURE C: VIP PLOT ==========

fig_c_all <- ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "",
       x = "Predictor",
       y = "VIP Score") +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )


# ========== COMBINE ALL THREE FIGURES ==========
ALL_AVG_PSLR <- fig_a_all + fig_b_all + fig_c_all + 
  plot_layout(ncol = 3)
ALL_AVG_PSLR

```

## PLSR YEAR spatially separated,  north region averaged 
```{r}
# combined 
ROMS_CUTI_environmental_combined_average <- ROMS_CUTI_environmental_combined_all_yr %>% 
  filter(Region == 'north') %>% 
 # filter(Month %in% c("Feb", "Mar", "Apr", "May", "Jun", "Jul")) %>% 
  group_by(Year) %>%
  summarise(across(
    c(DO_avg, pH_avg, Temperature_avg, Chla_avg, Vwind_avg,CUTI),
    ~ mean(.x, na.rm = TRUE),
    .names = "mean_{.col}"
  )) %>%
  ungroup()

df_gopher <-left_join(ROMS_CUTI_environmental_combined_average,goph_recruit, by = "Year")

df_gopher <- df_gopher %>% 
  select(dev, mean_CUTI,mean_pH_avg, mean_DO_avg, mean_Temperature_avg, mean_Chla_avg, mean_Vwind_avg) %>% 
  rename(deviation = dev,
         CUTI = mean_CUTI,
         pH = mean_pH_avg, 
         DO = mean_DO_avg, 
         Temperature = mean_Temperature_avg, 
         "Primary Production" = mean_Chla_avg, 
         "Meridonal Wind" = mean_Vwind_avg)

# Define X and Y together and filter complete cases
X_raw <- df_gopher %>% 
  select(CUTI, "Meridonal Wind" ,pH, DO, Temperature, "Primary Production")

# Combine into one frame with response
data_complete <- cbind(deviation = df_gopher$deviation, X_raw) %>% 
  as.data.frame() %>% 
  na.omit()  # remove rows with any NA

# Now separate into X and Y
Y <- data_complete$deviation
X <- as.matrix(data_complete %>% select(-deviation))

plsr <- plsr(deviation ~ ., data = data_complete, scale = TRUE, validation = "LOO")
pls_scores <- scores(plsr)

df_pls <- data.frame(
  dev = Y,
  Comp1 = pls_scores[, 1],
  Comp2 = pls_scores[, 2]
)

# Summary of model
summary(plsr)

# Root Mean Squared Error of Prediction
RMSEP(plsr)

# Choose number of components based on RMSEP or % variance explained
plot(RMSEP(plsr), legendpos = "topright")

# Variance explained
explvar(plsr)  # % of variance explained in X by each component

# Component loadings: how original vars contribute to latent variables
loadings(plsr)

# Scores: the new coordinate representation of observations
pls_scores <- scores(plsr)

# Biplot: visualize scores and loadings
biplot(plsr_march, comps = 1:2)

# Fit a linear model using first 2 PLS components
lm_pls <- lm(dev ~ Comp1 + Comp2, data = df_pls)
summary(lm_pls)

# check residuals 
simulated_res <- simulateResiduals(fittedModel = lm_pls)
plot(simulated_res) #these look good

selectNcomp(plsr, method = "onesigma")

lm_pls_1comp <- lm(dev ~ Comp1, data = df_pls)
summary(lm_pls_1comp)

plot(RMSEP(plsr), legendpos = "topright")

# 1-component model is optimal, so we use opt.comp = 1
vip_scores <- VIP(plsr, opt.comp = 1)

# Turn into data frame properly
vip_df <- data.frame(
  Variable = names(vip_scores),
  VIP = vip_scores
)

ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = .8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "Variable Importance in Projection (VIP)",
       x = "Predictor",
       y = "VIP Score")
```

### table of correlations and weights
```{r}
# Choose which component to analyze 
comp_num <- 1

# 1. WEIGHT² - Variable importance/contribution to the component
weights_raw <- loading.weights(plsr)[, comp_num]
weights_squared <- weights_raw^2

# 2. CORRELATION - Between each predictor and the response variable
# Get the names of predictors used in the PLS model
predictor_names <- colnames(X)

# Use same predictors from the original full dataset for correlation
X_original <- plsr$model %>% select(all_of(predictor_names))
Y_original <- plsr$model$dev  # <-- Fixed line

# Ensure there are no NAs in either X_original or Y_original
complete_rows <- complete.cases(X_original, Y_original)
X_original <- X_original[complete_rows, ]
Y_original <- Y_original[complete_rows]

# Calculate correlations
correlations <- cor(X_original, Y_original)

# 3. LOADING - Direction and magnitude
loadings_values <- loadings(plsr)[, comp_num]

# Create summary table
pls_summary_table <- data.frame(
  Predictor = predictor_names,
  Weight_squared = round(weights_squared, 3),
  Correlation = round(correlations, 3),
  Loading_value = round(loadings_values, 3),
  Loading_direction = ifelse(loadings_values > 0, "+", "-")
)

# View the table
print(pls_summary_table)
```

### figure for plsr
```{r}
library(ggplot2)
library(gridExtra)
library(grid)

# Extract predictor names from X
predictor_names <- colnames(X)

# ========== FIGURE A: PLS BIPLOT ==========

loadings_data <- loadings(plsr)[, 1:2]
loadings_df <- data.frame(
  Variable = rownames(loadings_data),
  Component1 = loadings_data[, 1],
  Component2 = loadings_data[, 2]
)

fig_a_north <- ggplot(loadings_df, aes(x = Component1, y = Component2)) +
  geom_path(data = data.frame(
    x = cos(seq(0, 2 * pi, length.out = 100)),
    y = sin(seq(0, 2 * pi, length.out = 100))
  ), aes(x = x, y = y), color = "black", linewidth = 1) +

  # Arrows and labels
  geom_segment(aes(x = 0, y = 0, xend = Component1, yend = Component2),
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "steelblue", linewidth = 1.2) +
  geom_text(aes(label = Variable), 
            color = "steelblue", size = 4, fontface = "bold",
            nudge_x = ifelse(loadings_df$Component1 > 0, 0.05, -0.05),
            nudge_y = ifelse(loadings_df$Component2 > 0, 0.05, -0.05)) +
  
  # Optional: Response direction (illustrative only)
  # You can calculate actual correlation direction if desired
  geom_segment(aes(x = 0, y = 0, xend = 0.6, yend = 0.4), 
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "indianred", linewidth = 1.5) +
  geom_text(aes(x = 0.68, y = 0.45, label = "Recruitment"), 
             color = "indianred", size = 4, fontface = "bold") +
  
  xlim(-1.1, 1.1) + ylim(-1.1, 1.1) +
  labs(x = "Component 1", y = "Component 2", title = "") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  coord_fixed()


# ========== FIGURE B: COMPONENT 1 vs RESPONSE ==========

# Ensure response is matched to filtered data
component1_scores <- scores(plsr)[, 1]
response_var <- Y  # this Y comes from the filtered, complete-case data

# Compute R² and p-value
var_explained <- explvar(plsr)[1]
lm_comp1 <- lm(response_var ~ component1_scores)
lm_summary <- summary(lm_comp1)
p_value <- lm_summary$coefficients[2, 4]
r_squared <- lm_summary$r.squared

# Format p-value
p_text <- if (p_value < 0.001) {
  "p < 0.001"
} else if (p_value < 0.01) {
  paste0("p = ", format(round(p_value, 3), nsmall = 3))
} else {
  paste0("p = ", format(round(p_value, 2), nsmall = 2))
}

annotation_text <- paste0("R² = ", format(round(r_squared, 3), nsmall = 3), "\n", p_text)

fig_b_north <- ggplot(data.frame(Component1 = component1_scores, Response = response_var),
                aes(x = Component1, y = Response)) +
  geom_point(size = 2.5, alpha = 0.7) +
  geom_smooth(method = "lm", color = "steelblue", fill = "black", alpha = 0.3) +
  annotate("text", 
           x = Inf, y = Inf, 
           label = annotation_text,
           hjust = 1.3, vjust = 1.3,
           size = 4, 
           fontface = "bold",
           color = "black") +
  labs(
    x = paste0("PLSR component 1 (", round(var_explained, 1), "%)"),
    y = "Recruitment Deviations",
    title = "Northern Region"
  ) +
  theme_classic() +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )



# ========== FIGURE C: VIP PLOT ==========

fig_c_north <- ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "",
       x = "Predictor",
       y = "VIP Score") +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )


# ========== COMBINE ALL THREE FIGURES ==========
NORTH_AVG_PSLR <- fig_a_north + fig_b_north + fig_c_north + 
  plot_layout(ncol = 3)
NORTH_AVG_PSLR

# ========== SAVE ==========
ggsave("north_feb_aug_pslr.png", width = 15, height = 5, dpi = 300)

```

## PLSR YEAR spatially separated,  mid region averaged 
```{r}
# combined 
ROMS_CUTI_environmental_combined_average <- ROMS_CUTI_environmental_combined_all_yr %>% 
  filter(Region == 'mid') %>% 
 # filter(Month %in% c("Feb", "Mar", "Apr", "May", "Jun", "Jul")) %>% 
  group_by(Year) %>%
  summarise(across(
    c(DO_avg, pH_avg, Temperature_avg, Chla_avg, Vwind_avg,CUTI),
    ~ mean(.x, na.rm = TRUE),
    .names = "mean_{.col}"
  )) %>%
  ungroup()

df_gopher <-left_join(ROMS_CUTI_environmental_combined_average,goph_recruit, by = "Year")

df_gopher <- df_gopher %>% 
  select(dev, mean_CUTI,mean_pH_avg, mean_DO_avg, mean_Temperature_avg, mean_Chla_avg, mean_Vwind_avg) %>% 
  rename(deviation = dev,
         CUTI = mean_CUTI,
         pH = mean_pH_avg, 
         DO = mean_DO_avg, 
         Temperature = mean_Temperature_avg, 
         "Primary Production" = mean_Chla_avg, 
         "Meridonal Wind" = mean_Vwind_avg)

# Define X and Y together and filter complete cases
X_raw <- df_gopher %>% 
  select(CUTI, "Meridonal Wind" ,pH, DO, Temperature, "Primary Production")

# Combine into one frame with response
data_complete <- cbind(deviation = df_gopher$deviation, X_raw) %>% 
  as.data.frame() %>% 
  na.omit()  # remove rows with any NA

# Now separate into X and Y
Y <- data_complete$deviation
X <- as.matrix(data_complete %>% select(-deviation))

plsr <- plsr(deviation ~ ., data = data_complete, scale = TRUE, validation = "LOO")
pls_scores <- scores(plsr)

df_pls <- data.frame(
  dev = Y,
  Comp1 = pls_scores[, 1],
  Comp2 = pls_scores[, 2]
)

# Summary of model
summary(plsr)

# Root Mean Squared Error of Prediction
RMSEP(plsr)

# Choose number of components based on RMSEP or % variance explained
plot(RMSEP(plsr), legendpos = "topright")

# Variance explained
explvar(plsr)  # % of variance explained in X by each component

# Component loadings: how original vars contribute to latent variables
loadings(plsr)

# Scores: the new coordinate representation of observations
pls_scores <- scores(plsr)

# Biplot: visualize scores and loadings
biplot(plsr_march, comps = 1:2)

# Fit a linear model using first 2 PLS components
lm_pls <- lm(dev ~ Comp1 + Comp2, data = df_pls)
summary(lm_pls)

# check residuals 
simulated_res <- simulateResiduals(fittedModel = lm_pls)
plot(simulated_res) #these look good

selectNcomp(plsr, method = "onesigma")

lm_pls_1comp <- lm(dev ~ Comp1, data = df_pls)
summary(lm_pls_1comp)

plot(RMSEP(plsr), legendpos = "topright")

# 1-component model is optimal, so we use opt.comp = 1
vip_scores <- VIP(plsr, opt.comp = 1)

# Turn into data frame properly
vip_df <- data.frame(
  Variable = names(vip_scores),
  VIP = vip_scores
)

ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = .8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "Variable Importance in Projection (VIP)",
       x = "Predictor",
       y = "VIP Score")
```

### table of correlations and weights
```{r}
# Choose which component to analyze 
comp_num <- 1

# 1. WEIGHT² - Variable importance/contribution to the component
weights_raw <- loading.weights(plsr)[, comp_num]
weights_squared <- weights_raw^2

# 2. CORRELATION - Between each predictor and the response variable
# Get the names of predictors used in the PLS model
predictor_names <- colnames(X)

# Use same predictors from the original full dataset for correlation
X_original <- plsr$model %>% select(all_of(predictor_names))
Y_original <- plsr$model$dev  # <-- Fixed line

# Ensure there are no NAs in either X_original or Y_original
complete_rows <- complete.cases(X_original, Y_original)
X_original <- X_original[complete_rows, ]
Y_original <- Y_original[complete_rows]

# Calculate correlations
correlations <- cor(X_original, Y_original)

# 3. LOADING - Direction and magnitude
loadings_values <- loadings(plsr)[, comp_num]

# Create summary table
pls_summary_table <- data.frame(
  Predictor = predictor_names,
  Weight_squared = round(weights_squared, 3),
  Correlation = round(correlations, 3),
  Loading_value = round(loadings_values, 3),
  Loading_direction = ifelse(loadings_values > 0, "+", "-")
)

# View the table
print(pls_summary_table)
```

### figure for plsr
```{r}
library(ggplot2)
library(gridExtra)
library(grid)

# Extract predictor names from X
predictor_names <- colnames(X)

# ========== FIGURE A: PLS BIPLOT ==========

loadings_data <- loadings(plsr)[, 1:2]
loadings_df <- data.frame(
  Variable = rownames(loadings_data),
  Component1 = loadings_data[, 1],
  Component2 = loadings_data[, 2]
)

fig_a_mid <- ggplot(loadings_df, aes(x = Component1, y = Component2)) +
  geom_path(data = data.frame(
    x = cos(seq(0, 2 * pi, length.out = 100)),
    y = sin(seq(0, 2 * pi, length.out = 100))
  ), aes(x = x, y = y), color = "black", linewidth = 1) +

  # Arrows and labels
  geom_segment(aes(x = 0, y = 0, xend = Component1, yend = Component2),
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "steelblue", linewidth = 1.2) +
  geom_text(aes(label = Variable), 
            color = "steelblue", size = 4, fontface = "bold",
            nudge_x = ifelse(loadings_df$Component1 > 0, 0.05, -0.05),
            nudge_y = ifelse(loadings_df$Component2 > 0, 0.05, -0.05)) +
  
  # Optional: Response direction (illustrative only)
  # You can calculate actual correlation direction if desired
  geom_segment(aes(x = 0, y = 0, xend = 0.6, yend = 0.4), 
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "indianred", linewidth = 1.5) +
  geom_text(aes(x = 0.68, y = 0.45, label = "Recruitment"), 
             color = "indianred", size = 4, fontface = "bold") +
  
  xlim(-1.1, 1.1) + ylim(-1.1, 1.1) +
  labs(x = "Component 1", y = "Component 2", title = "") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  coord_fixed()


# ========== FIGURE B: COMPONENT 1 vs RESPONSE ==========

# Ensure response is matched to filtered data
component1_scores <- scores(plsr)[, 1]
response_var <- Y  # this Y comes from the filtered, complete-case data

# Compute R² and p-value
var_explained <- explvar(plsr)[1]
lm_comp1 <- lm(response_var ~ component1_scores)
lm_summary <- summary(lm_comp1)
p_value <- lm_summary$coefficients[2, 4]
r_squared <- lm_summary$r.squared

# Format p-value
p_text <- if (p_value < 0.001) {
  "p < 0.001"
} else if (p_value < 0.01) {
  paste0("p = ", format(round(p_value, 3), nsmall = 3))
} else {
  paste0("p = ", format(round(p_value, 2), nsmall = 2))
}

annotation_text <- paste0("R² = ", format(round(r_squared, 3), nsmall = 3), "\n", p_text)

fig_b_mid <- ggplot(data.frame(Component1 = component1_scores, Response = response_var),
                aes(x = Component1, y = Response)) +
  geom_point(size = 2.5, alpha = 0.7) +
  geom_smooth(method = "lm", color = "steelblue", fill = "black", alpha = 0.3) +
  annotate("text", 
           x = Inf, y = Inf, 
           label = annotation_text,
           hjust = 1.3, vjust = 1.3,
           size = 4, 
           fontface = "bold",
           color = "black") +
  labs(
    x = paste0("PLSR component 1 (", round(var_explained, 1), "%)"),
    y = "Recruitment Deviations",
    title = "Central Region"
  ) +
  theme_classic() +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )



# ========== FIGURE C: VIP PLOT ==========

fig_c_mid <- ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "",
       x = "Predictor",
       y = "VIP Score") +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )


# ========== COMBINE ALL THREE FIGURES ==========
mid_AVG_PSLR <- fig_a_mid + fig_b_mid + fig_c_mid + 
  plot_layout(ncol = 3)
mid_AVG_PSLR

# ========== SAVE ==========
ggsave("mid_feb_aug_pslr.png", width = 15, height = 5, dpi = 300)

```


## PLSR YEAR spatially separated,  south region averaged 
```{r}
# combined 
ROMS_CUTI_environmental_combined_average <- ROMS_CUTI_environmental_combined_all_yr %>% 
  filter(Region == 'south') %>% 
 # filter(Month %in% c("Feb", "Mar", "Apr", "May", "Jun", "Jul")) %>% 
  group_by(Year) %>%
  summarise(across(
    c(DO_avg, pH_avg, Temperature_avg, Chla_avg, Vwind_avg,CUTI),
    ~ mean(.x, na.rm = TRUE),
    .names = "mean_{.col}"
  )) %>%
  ungroup()

df_gopher <-left_join(ROMS_CUTI_environmental_combined_average,goph_recruit, by = "Year")

df_gopher <- df_gopher %>% 
  select(dev, mean_CUTI,mean_pH_avg, mean_DO_avg, mean_Temperature_avg, mean_Chla_avg, mean_Vwind_avg) %>% 
  rename(deviation = dev,
         CUTI = mean_CUTI,
         pH = mean_pH_avg, 
         DO = mean_DO_avg, 
         Temperature = mean_Temperature_avg, 
         "Primary Production" = mean_Chla_avg, 
         "Meridonal Wind" = mean_Vwind_avg)

# Define X and Y together and filter complete cases
X_raw <- df_gopher %>% 
  select(CUTI, "Meridonal Wind" ,pH, DO, Temperature, "Primary Production")

# Combine into one frame with response
data_complete <- cbind(deviation = df_gopher$deviation, X_raw) %>% 
  as.data.frame() %>% 
  na.omit()  # remove rows with any NA

# Now separate into X and Y
Y <- data_complete$deviation
X <- as.matrix(data_complete %>% select(-deviation))

plsr <- plsr(deviation ~ ., data = data_complete, scale = TRUE, validation = "LOO")
pls_scores <- scores(plsr)

df_pls <- data.frame(
  dev = Y,
  Comp1 = pls_scores[, 1],
  Comp2 = pls_scores[, 2]
)

# Summary of model
summary(plsr)

# Root Mean Squared Error of Prediction
RMSEP(plsr)

# Choose number of components based on RMSEP or % variance explained
plot(RMSEP(plsr), legendpos = "topright")

# Variance explained
explvar(plsr)  # % of variance explained in X by each component

# Component loadings: how original vars contribute to latent variables
loadings(plsr)

# Scores: the new coordinate representation of observations
pls_scores <- scores(plsr)

# Biplot: visualize scores and loadings
biplot(plsr_march, comps = 1:2)

# Fit a linear model using first 2 PLS components
lm_pls <- lm(dev ~ Comp1 + Comp2, data = df_pls)
summary(lm_pls)

# check residuals 
simulated_res <- simulateResiduals(fittedModel = lm_pls)
plot(simulated_res) #these look good

selectNcomp(plsr, method = "onesigma")

lm_pls_1comp <- lm(dev ~ Comp1, data = df_pls)
summary(lm_pls_1comp)

plot(RMSEP(plsr), legendpos = "topright")

# 1-component model is optimal, so we use opt.comp = 1
vip_scores <- VIP(plsr, opt.comp = 1)

# Turn into data frame properly
vip_df <- data.frame(
  Variable = names(vip_scores),
  VIP = vip_scores
)

ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = .8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "Variable Importance in Projection (VIP)",
       x = "Predictor",
       y = "VIP Score")
```

### table of correlations and weights
```{r}
# Choose which component to analyze 
comp_num <- 1

# 1. WEIGHT² - Variable importance/contribution to the component
weights_raw <- loading.weights(plsr)[, comp_num]
weights_squared <- weights_raw^2

# 2. CORRELATION - Between each predictor and the response variable
# Get the names of predictors used in the PLS model
predictor_names <- colnames(X)

# Use same predictors from the original full dataset for correlation
X_original <- plsr$model %>% select(all_of(predictor_names))
Y_original <- plsr$model$dev  # <-- Fixed line

# Ensure there are no NAs in either X_original or Y_original
complete_rows <- complete.cases(X_original, Y_original)
X_original <- X_original[complete_rows, ]
Y_original <- Y_original[complete_rows]

# Calculate correlations
correlations <- cor(X_original, Y_original)

# 3. LOADING - Direction and magnitude
loadings_values <- loadings(plsr)[, comp_num]

# Create summary table
pls_summary_table <- data.frame(
  Predictor = predictor_names,
  Weight_squared = round(weights_squared, 3),
  Correlation = round(correlations, 3),
  Loading_value = round(loadings_values, 3),
  Loading_direction = ifelse(loadings_values > 0, "+", "-")
)

# View the table
print(pls_summary_table)
```

### figure for plsr
```{r}
library(ggplot2)
library(gridExtra)
library(grid)

# Extract predictor names from X
predictor_names <- colnames(X)

# ========== FIGURE A: PLS BIPLOT ==========

loadings_data <- loadings(plsr)[, 1:2]
loadings_df <- data.frame(
  Variable = rownames(loadings_data),
  Component1 = loadings_data[, 1],
  Component2 = loadings_data[, 2]
)

fig_a_south <- ggplot(loadings_df, aes(x = Component1, y = Component2)) +
  geom_path(data = data.frame(
    x = cos(seq(0, 2 * pi, length.out = 100)),
    y = sin(seq(0, 2 * pi, length.out = 100))
  ), aes(x = x, y = y), color = "black", linewidth = 1) +

  # Arrows and labels
  geom_segment(aes(x = 0, y = 0, xend = Component1, yend = Component2),
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "steelblue", linewidth = 1.2) +
  geom_text(aes(label = Variable), 
            color = "steelblue", size = 4, fontface = "bold",
            nudge_x = ifelse(loadings_df$Component1 > 0, 0.05, -0.05),
            nudge_y = ifelse(loadings_df$Component2 > 0, 0.05, -0.05)) +
  
  # Optional: Response direction (illustrative only)
  # You can calculate actual correlation direction if desired
  geom_segment(aes(x = 0, y = 0, xend = 0.6, yend = 0.4), 
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "indianred", linewidth = 1.5) +
  geom_text(aes(x = 0.68, y = 0.45, label = "Recruitment"), 
             color = "indianred", size = 4, fontface = "bold") +
  
  xlim(-1.1, 1.1) + ylim(-1.1, 1.1) +
  labs(x = "Component 1", y = "Component 2", title = "") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  coord_fixed()


# ========== FIGURE B: COMPONENT 1 vs RESPONSE ==========

# Ensure response is matched to filtered data
component1_scores <- scores(plsr)[, 1]
response_var <- Y  # this Y comes from the filtered, complete-case data

# Compute R² and p-value
var_explained <- explvar(plsr)[1]
lm_comp1 <- lm(response_var ~ component1_scores)
lm_summary <- summary(lm_comp1)
p_value <- lm_summary$coefficients[2, 4]
r_squared <- lm_summary$r.squared

# Format p-value
p_text <- if (p_value < 0.001) {
  "p < 0.001"
} else if (p_value < 0.01) {
  paste0("p = ", format(round(p_value, 3), nsmall = 3))
} else {
  paste0("p = ", format(round(p_value, 2), nsmall = 2))
}

annotation_text <- paste0("R² = ", format(round(r_squared, 3), nsmall = 3), "\n", p_text)

fig_b_south <- ggplot(data.frame(Component1 = component1_scores, Response = response_var),
                aes(x = Component1, y = Response)) +
  geom_point(size = 2.5, alpha = 0.7) +
  geom_smooth(method = "lm", color = "steelblue", fill = "black", alpha = 0.3) +
  annotate("text", 
           x = Inf, y = Inf, 
           label = annotation_text,
           hjust = 1.3, vjust = 1.3,
           size = 4, 
           fontface = "bold",
           color = "black") +
  labs(
    x = paste0("PLSR component 1 (", round(var_explained, 1), "%)"),
    y = "Recruitment Deviations",
    title = "Southern Region"
  ) +
  theme_classic() +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )



# ========== FIGURE C: VIP PLOT ==========

fig_c_south <- ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "",
       x = "Predictor",
       y = "VIP Score") +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )


# ========== COMBINE ALL THREE FIGURES ==========
south_AVG_PSLR <- fig_a_south + fig_b_south + fig_c_south + 
  plot_layout(ncol = 3)
south_AVG_PSLR

# ========== SAVE ==========
ggsave("south_feb_aug_pslr.png", width = 15, height = 5, dpi = 300)

```



## Putting all regional YEAR averages PLSR together 
```{r}
combined_plot <-  fig_b_all + fig_c_all +fig_b_north + fig_c_north + fig_b_mid + fig_c_mid +  fig_b_south + fig_c_south +
  plot_layout(ncol = 2) 
combined_plot
ggsave("combined_pslr_spatially_separated_YEARLY_AVG.png", width = 15, height = 10, dpi = 300)
```


# PSLR - spatially separated Feb to Sept
## PLSR Jan - Sep spatially separated, all regions averaged 
```{r}
# combined 
ROMS_CUTI_environmental_combined_average <- ROMS_CUTI_environmental_combined_all_yr %>% 
  filter(Region == 'all') %>% 
  filter(Month %in% c("Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep")) %>% 
  group_by(Year) %>%
  summarise(across(
    c(DO_avg, pH_avg, Temperature_avg, Chla_avg, Vwind_avg,CUTI),
    ~ mean(.x, na.rm = TRUE),
    .names = "mean_{.col}"
  )) %>%
  ungroup()

df_gopher <-left_join(ROMS_CUTI_environmental_combined_average,goph_recruit, by = "Year")

df_gopher <- df_gopher %>% 
  select(dev, mean_CUTI,mean_pH_avg, mean_DO_avg, mean_Temperature_avg, mean_Chla_avg, mean_Vwind_avg) %>% 
  rename(deviation = dev,
         CUTI = mean_CUTI,
         pH = mean_pH_avg, 
         DO = mean_DO_avg, 
         Temperature = mean_Temperature_avg, 
         "Primary Production" = mean_Chla_avg, 
         "Meridonal Wind" = mean_Vwind_avg)

# Define X and Y together and filter complete cases
X_raw <- df_gopher %>% 
  select(CUTI, "Meridonal Wind" ,pH, DO, Temperature, "Primary Production")

# Combine into one frame with response
data_complete <- cbind(deviation = df_gopher$deviation, X_raw) %>% 
  as.data.frame() %>% 
  na.omit()  # remove rows with any NA

# Now separate into X and Y
Y <- data_complete$deviation
X <- as.matrix(data_complete %>% select(-deviation))

plsr <- plsr(deviation ~ ., data = data_complete, scale = TRUE, validation = "LOO")
pls_scores <- scores(plsr)

df_pls <- data.frame(
  dev = Y,
  Comp1 = pls_scores[, 1],
  Comp2 = pls_scores[, 2]
)

# Summary of model
summary(plsr)

# Root Mean Squared Error of Prediction
RMSEP(plsr)

# Choose number of components based on RMSEP or % variance explained
plot(RMSEP(plsr), legendpos = "topright")

# Variance explained
explvar(plsr)  # % of variance explained in X by each component

# Component loadings: how original vars contribute to latent variables
loadings(plsr)

# Scores: the new coordinate representation of observations
pls_scores <- scores(plsr)

# Biplot: visualize scores and loadings
biplot(plsr_march, comps = 1:2)

# Fit a linear model using first 2 PLS components
lm_pls <- lm(dev ~ Comp1 + Comp2, data = df_pls)
summary(lm_pls)

# check residuals 
simulated_res <- simulateResiduals(fittedModel = lm_pls)
plot(simulated_res) #these look good

selectNcomp(plsr, method = "onesigma")

lm_pls_1comp <- lm(dev ~ Comp1, data = df_pls)
summary(lm_pls_1comp)

plot(RMSEP(plsr), legendpos = "topright")

# 1-component model is optimal, so we use opt.comp = 1
vip_scores <- VIP(plsr, opt.comp = 1)

# Turn into data frame properly
vip_df <- data.frame(
  Variable = names(vip_scores),
  VIP = vip_scores
)

ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = .8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "Variable Importance in Projection (VIP)",
       x = "Predictor",
       y = "VIP Score")
```

### table of correlations and weights
```{r}
# Choose which component to analyze 
comp_num <- 1

# 1. WEIGHT² - Variable importance/contribution to the component
weights_raw <- loading.weights(plsr)[, comp_num]
weights_squared <- weights_raw^2

# 2. CORRELATION - Between each predictor and the response variable
# Get the names of predictors used in the PLS model
predictor_names <- colnames(X)

# Use same predictors from the original full dataset for correlation
X_original <- plsr$model %>% select(all_of(predictor_names))
Y_original <- plsr$model$dev  # <-- Fixed line

# Ensure there are no NAs in either X_original or Y_original
complete_rows <- complete.cases(X_original, Y_original)
X_original <- X_original[complete_rows, ]
Y_original <- Y_original[complete_rows]

# Calculate correlations
correlations <- cor(X_original, Y_original)

# 3. LOADING - Direction and magnitude
loadings_values <- loadings(plsr)[, comp_num]

# Create summary table
pls_summary_table <- data.frame(
  Predictor = predictor_names,
  Weight_squared = round(weights_squared, 3),
  Correlation = round(correlations, 3),
  Loading_value = round(loadings_values, 3),
  Loading_direction = ifelse(loadings_values > 0, "+", "-")
)

# View the table
print(pls_summary_table)
```




### figure for plsr
```{r}
library(ggplot2)
library(gridExtra)
library(grid)

# Extract predictor names from X
predictor_names <- colnames(X)

# ========== FIGURE A: PLS BIPLOT ==========

loadings_data <- loadings(plsr_march)[, 1:2]
loadings_df <- data.frame(
  Variable = rownames(loadings_data),
  Component1 = loadings_data[, 1],
  Component2 = loadings_data[, 2]
)

fig_a_all <- ggplot(loadings_df, aes(x = Component1, y = Component2)) +
  geom_path(data = data.frame(
    x = cos(seq(0, 2 * pi, length.out = 100)),
    y = sin(seq(0, 2 * pi, length.out = 100))
  ), aes(x = x, y = y), color = "black", linewidth = 1) +

  # Arrows and labels
  geom_segment(aes(x = 0, y = 0, xend = Component1, yend = Component2),
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "steelblue", linewidth = 1.2) +
  geom_text(aes(label = Variable), 
            color = "steelblue", size = 4, fontface = "bold",
            nudge_x = ifelse(loadings_df$Component1 > 0, 0.05, -0.05),
            nudge_y = ifelse(loadings_df$Component2 > 0, 0.05, -0.05)) +
  
  # Optional: Response direction (illustrative only)
  # You can calculate actual correlation direction if desired
  geom_segment(aes(x = 0, y = 0, xend = 0.6, yend = 0.4), 
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "indianred", linewidth = 1.5) +
  geom_text(aes(x = 0.68, y = 0.45, label = "Recruitment"), 
             color = "indianred", size = 4, fontface = "bold") +
  
  xlim(-1.1, 1.1) + ylim(-1.1, 1.1) +
  labs(x = "Component 1", y = "Component 2", title = "Entire Region") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  coord_fixed()


# ========== FIGURE B: COMPONENT 1 vs RESPONSE ==========

# Ensure response is matched to filtered data
component1_scores <- scores(plsr_march)[, 1]
response_var <- Y  # this Y comes from the filtered, complete-case data

# Compute R² and p-value
var_explained <- explvar(plsr_march)[1]
lm_comp1 <- lm(response_var ~ component1_scores)
lm_summary <- summary(lm_comp1)
p_value <- lm_summary$coefficients[2, 4]
r_squared <- lm_summary$r.squared

# Format p-value
p_text <- if (p_value < 0.001) {
  "p < 0.001"
} else if (p_value < 0.01) {
  paste0("p = ", format(round(p_value, 3), nsmall = 3))
} else {
  paste0("p = ", format(round(p_value, 2), nsmall = 2))
}

annotation_text <- paste0("R² = ", format(round(r_squared, 3), nsmall = 3), "\n", p_text)

fig_b_all <- ggplot(data.frame(Component1 = component1_scores, Response = response_var),
                aes(x = Component1, y = Response)) +
  geom_point(size = 2.5, alpha = 0.7) +
  geom_smooth(method = "lm", color = "steelblue", fill = "black", alpha = 0.3) +
  annotate("text", 
           x = Inf, y = Inf, 
           label = annotation_text,
           hjust = 1.3, vjust = 1.3,
           size = 4, 
           fontface = "bold",
           color = "black") +
  labs(
    x = paste0("PLSR component 1 (", round(var_explained, 1), "%)"),
    y = "Recruitment Deviations",
    title = "Entire Region"
  ) +
  theme_classic() +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )



# ========== FIGURE C: VIP PLOT ==========

fig_c_all <- ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "",
       x = "Predictor",
       y = "VIP Score") +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )


# ========== COMBINE ALL THREE FIGURES ==========
ALL_AVG_PSLR <- fig_a_all + fig_b_all + fig_c_all + 
  plot_layout(ncol = 3)
ALL_AVG_PSLR

# ========== SAVE ==========
ggsave("all_feb_aug_pslr.png", width = 15, height = 5, dpi = 300)
```

## PLSR Feb - Sep spatially separated,  north region averaged 
```{r}
# combined 
ROMS_CUTI_environmental_combined_average <- ROMS_CUTI_environmental_combined_all_yr %>% 
  filter(Region == 'north') %>% 
  filter(Month %in% c("Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep")) %>% 
  group_by(Year) %>%
  summarise(across(
    c(DO_avg, pH_avg, Temperature_avg, Chla_avg, Vwind_avg,CUTI),
    ~ mean(.x, na.rm = TRUE),
    .names = "mean_{.col}"
  )) %>%
  ungroup()

df_gopher <-left_join(ROMS_CUTI_environmental_combined_average,goph_recruit, by = "Year")

df_gopher <- df_gopher %>% 
  select(dev, mean_CUTI,mean_pH_avg, mean_DO_avg, mean_Temperature_avg, mean_Chla_avg, mean_Vwind_avg) %>% 
  rename(deviation = dev,
         CUTI = mean_CUTI,
         pH = mean_pH_avg, 
         DO = mean_DO_avg, 
         Temperature = mean_Temperature_avg, 
         "Primary Production" = mean_Chla_avg, 
         "Meridonal Wind" = mean_Vwind_avg)

# Define X and Y together and filter complete cases
X_raw <- df_gopher %>% 
  select(CUTI, "Meridonal Wind" ,pH, DO, Temperature, "Primary Production")

# Combine into one frame with response
data_complete <- cbind(deviation = df_gopher$deviation, X_raw) %>% 
  as.data.frame() %>% 
  na.omit()  # remove rows with any NA

# Now separate into X and Y
Y <- data_complete$deviation
X <- as.matrix(data_complete %>% select(-deviation))

plsr <- plsr(deviation ~ ., data = data_complete, scale = TRUE, validation = "LOO")
pls_scores <- scores(plsr)

df_pls <- data.frame(
  dev = Y,
  Comp1 = pls_scores[, 1],
  Comp2 = pls_scores[, 2]
)

# Summary of model
summary(plsr)

# Root Mean Squared Error of Prediction
RMSEP(plsr)

# Choose number of components based on RMSEP or % variance explained
plot(RMSEP(plsr), legendpos = "topright")

# Variance explained
explvar(plsr)  # % of variance explained in X by each component

# Component loadings: how original vars contribute to latent variables
loadings(plsr)

# Scores: the new coordinate representation of observations
pls_scores <- scores(plsr)

# Biplot: visualize scores and loadings
biplot(plsr_march, comps = 1:2)

# Fit a linear model using first 2 PLS components
lm_pls <- lm(dev ~ Comp1 + Comp2, data = df_pls)
summary(lm_pls)

# check residuals 
simulated_res <- simulateResiduals(fittedModel = lm_pls)
plot(simulated_res) #these look good

selectNcomp(plsr, method = "onesigma")

lm_pls_1comp <- lm(dev ~ Comp1, data = df_pls)
summary(lm_pls_1comp)

plot(RMSEP(plsr), legendpos = "topright")

# 1-component model is optimal, so we use opt.comp = 1
vip_scores <- VIP(plsr, opt.comp = 1)

# Turn into data frame properly
vip_df <- data.frame(
  Variable = names(vip_scores),
  VIP = vip_scores
)

ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = .8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "Variable Importance in Projection (VIP)",
       x = "Predictor",
       y = "VIP Score")
```

### table of correlations and weights
```{r}
# Choose which component to analyze 
comp_num <- 1

# 1. WEIGHT² - Variable importance/contribution to the component
weights_raw <- loading.weights(plsr)[, comp_num]
weights_squared <- weights_raw^2

# 2. CORRELATION - Between each predictor and the response variable
# Get the names of predictors used in the PLS model
predictor_names <- colnames(X)

# Use same predictors from the original full dataset for correlation
X_original <- plsr$model %>% select(all_of(predictor_names))
Y_original <- plsr$model$dev  # <-- Fixed line

# Ensure there are no NAs in either X_original or Y_original
complete_rows <- complete.cases(X_original, Y_original)
X_original <- X_original[complete_rows, ]
Y_original <- Y_original[complete_rows]

# Calculate correlations
correlations <- cor(X_original, Y_original)

# 3. LOADING - Direction and magnitude
loadings_values <- loadings(plsr)[, comp_num]

# Create summary table
pls_summary_table <- data.frame(
  Predictor = predictor_names,
  Weight_squared = round(weights_squared, 3),
  Correlation = round(correlations, 3),
  Loading_value = round(loadings_values, 3),
  Loading_direction = ifelse(loadings_values > 0, "+", "-")
)

# View the table
print(pls_summary_table)
```

### figure for plsr
```{r}
library(ggplot2)
library(gridExtra)
library(grid)

# Extract predictor names from X
predictor_names <- colnames(X)

# ========== FIGURE A: PLS BIPLOT ==========

loadings_data <- loadings(plsr)[, 1:2]
loadings_df <- data.frame(
  Variable = rownames(loadings_data),
  Component1 = loadings_data[, 1],
  Component2 = loadings_data[, 2]
)

fig_a_north <- ggplot(loadings_df, aes(x = Component1, y = Component2)) +
  geom_path(data = data.frame(
    x = cos(seq(0, 2 * pi, length.out = 100)),
    y = sin(seq(0, 2 * pi, length.out = 100))
  ), aes(x = x, y = y), color = "black", linewidth = 1) +

  # Arrows and labels
  geom_segment(aes(x = 0, y = 0, xend = Component1, yend = Component2),
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "steelblue", linewidth = 1.2) +
  geom_text(aes(label = Variable), 
            color = "steelblue", size = 4, fontface = "bold",
            nudge_x = ifelse(loadings_df$Component1 > 0, 0.05, -0.05),
            nudge_y = ifelse(loadings_df$Component2 > 0, 0.05, -0.05)) +
  
  # Optional: Response direction (illustrative only)
  # You can calculate actual correlation direction if desired
  geom_segment(aes(x = 0, y = 0, xend = 0.6, yend = 0.4), 
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "indianred", linewidth = 1.5) +
  geom_text(aes(x = 0.68, y = 0.45, label = "Recruitment"), 
             color = "indianred", size = 4, fontface = "bold") +
  
  xlim(-1.1, 1.1) + ylim(-1.1, 1.1) +
  labs(x = "Component 1", y = "Component 2", title = "(a)") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  coord_fixed()


# ========== FIGURE B: COMPONENT 1 vs RESPONSE ==========

# Ensure response is matched to filtered data
component1_scores <- scores(plsr)[, 1]
response_var <- Y  # this Y comes from the filtered, complete-case data

# Compute R² and p-value
var_explained <- explvar(plsr)[1]
lm_comp1 <- lm(response_var ~ component1_scores)
lm_summary <- summary(lm_comp1)
p_value <- lm_summary$coefficients[2, 4]
r_squared <- lm_summary$r.squared

# Format p-value
p_text <- if (p_value < 0.001) {
  "p < 0.001"
} else if (p_value < 0.01) {
  paste0("p = ", format(round(p_value, 3), nsmall = 3))
} else {
  paste0("p = ", format(round(p_value, 2), nsmall = 2))
}

annotation_text <- paste0("R² = ", format(round(r_squared, 3), nsmall = 3), "\n", p_text)

fig_b_north <- ggplot(data.frame(Component1 = component1_scores, Response = response_var),
                aes(x = Component1, y = Response)) +
  geom_point(size = 2.5, alpha = 0.7) +
  geom_smooth(method = "lm", color = "steelblue", fill = "black", alpha = 0.3) +
  annotate("text", 
           x = Inf, y = Inf, 
           label = annotation_text,
           hjust = 1.3, vjust = 1.3,
           size = 4, 
           fontface = "bold",
           color = "black") +
  labs(
    x = paste0("PLSR component 1 (", round(var_explained, 1), "%)"),
    y = "Recruitment Deviations",
    title = "North Region"
  ) +
  theme_classic() +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )



# ========== FIGURE C: VIP PLOT ==========

fig_c_north <- ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "",
       x = "Predictor",
       y = "VIP Score") +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )


# ========== COMBINE ALL THREE FIGURES ==========
NORTH_AVG_PSLR <- fig_a_north + fig_b_north + fig_c_north + 
  plot_layout(ncol = 3)
NORTH_AVG_PSLR

# ========== SAVE ==========
ggsave("north_feb_aug_pslr.png", width = 15, height = 5, dpi = 300)

```

## PLSR Feb - Sep spatially separated,  mid region averaged 
```{r}
# combined 
ROMS_CUTI_environmental_combined_average <- ROMS_CUTI_environmental_combined_all_yr %>% 
  filter(Region == 'mid') %>% 
  filter(Month %in% c("Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep")) %>% 
  group_by(Year) %>%
  summarise(across(
    c(DO_avg, pH_avg, Temperature_avg, Chla_avg, Vwind_avg,CUTI),
    ~ mean(.x, na.rm = TRUE),
    .names = "mean_{.col}"
  )) %>%
  ungroup()

df_gopher <-left_join(ROMS_CUTI_environmental_combined_average,goph_recruit, by = "Year")

df_gopher <- df_gopher %>% 
  select(dev, mean_CUTI,mean_pH_avg, mean_DO_avg, mean_Temperature_avg, mean_Chla_avg, mean_Vwind_avg) %>% 
  rename(deviation = dev,
         CUTI = mean_CUTI,
         pH = mean_pH_avg, 
         DO = mean_DO_avg, 
         Temperature = mean_Temperature_avg, 
         "Primary Production" = mean_Chla_avg, 
         "Meridonal Wind" = mean_Vwind_avg)

# Define X and Y together and filter complete cases
X_raw <- df_gopher %>% 
  select(CUTI, "Meridonal Wind" ,pH, DO, Temperature, "Primary Production")

# Combine into one frame with response
data_complete <- cbind(deviation = df_gopher$deviation, X_raw) %>% 
  as.data.frame() %>% 
  na.omit()  # remove rows with any NA

# Now separate into X and Y
Y <- data_complete$deviation
X <- as.matrix(data_complete %>% select(-deviation))

plsr <- plsr(deviation ~ ., data = data_complete, scale = TRUE, validation = "LOO")
pls_scores <- scores(plsr)

df_pls <- data.frame(
  dev = Y,
  Comp1 = pls_scores[, 1],
  Comp2 = pls_scores[, 2]
)

# Summary of model
summary(plsr)

# Root Mean Squared Error of Prediction
RMSEP(plsr)

# Choose number of components based on RMSEP or % variance explained
plot(RMSEP(plsr), legendpos = "topright")

# Variance explained
explvar(plsr)  # % of variance explained in X by each component

# Component loadings: how original vars contribute to latent variables
loadings(plsr)

# Scores: the new coordinate representation of observations
pls_scores <- scores(plsr)

# Biplot: visualize scores and loadings
biplot(plsr_march, comps = 1:2)

# Fit a linear model using first 2 PLS components
lm_pls <- lm(dev ~ Comp1 + Comp2, data = df_pls)
summary(lm_pls)

# check residuals 
simulated_res <- simulateResiduals(fittedModel = lm_pls)
plot(simulated_res) #these look good

selectNcomp(plsr, method = "onesigma")

lm_pls_1comp <- lm(dev ~ Comp1, data = df_pls)
summary(lm_pls_1comp)

plot(RMSEP(plsr), legendpos = "topright")

# 1-component model is optimal, so we use opt.comp = 1
vip_scores <- VIP(plsr, opt.comp = 1)

# Turn into data frame properly
vip_df <- data.frame(
  Variable = names(vip_scores),
  VIP = vip_scores
)

ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = .8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "Variable Importance in Projection (VIP)",
       x = "Predictor",
       y = "VIP Score")
```

### table of correlations and weights
```{r}
# Choose which component to analyze 
comp_num <- 1

# 1. WEIGHT² - Variable importance/contribution to the component
weights_raw <- loading.weights(plsr)[, comp_num]
weights_squared <- weights_raw^2

# 2. CORRELATION - Between each predictor and the response variable
# Get the names of predictors used in the PLS model
predictor_names <- colnames(X)

# Use same predictors from the original full dataset for correlation
X_original <- plsr$model %>% select(all_of(predictor_names))
Y_original <- plsr$model$dev  # <-- Fixed line

# Ensure there are no NAs in either X_original or Y_original
complete_rows <- complete.cases(X_original, Y_original)
X_original <- X_original[complete_rows, ]
Y_original <- Y_original[complete_rows]

# Calculate correlations
correlations <- cor(X_original, Y_original)

# 3. LOADING - Direction and magnitude
loadings_values <- loadings(plsr)[, comp_num]

# Create summary table
pls_summary_table <- data.frame(
  Predictor = predictor_names,
  Weight_squared = round(weights_squared, 3),
  Correlation = round(correlations, 3),
  Loading_value = round(loadings_values, 3),
  Loading_direction = ifelse(loadings_values > 0, "+", "-")
)

# View the table
print(pls_summary_table)
```

### figure for plsr
```{r}
library(ggplot2)
library(gridExtra)
library(grid)

# Extract predictor names from X
predictor_names <- colnames(X)

# ========== FIGURE A: PLS BIPLOT ==========

loadings_data <- loadings(plsr)[, 1:2]
loadings_df <- data.frame(
  Variable = rownames(loadings_data),
  Component1 = loadings_data[, 1],
  Component2 = loadings_data[, 2]
)

fig_a_mid <- ggplot(loadings_df, aes(x = Component1, y = Component2)) +
  geom_path(data = data.frame(
    x = cos(seq(0, 2 * pi, length.out = 100)),
    y = sin(seq(0, 2 * pi, length.out = 100))
  ), aes(x = x, y = y), color = "black", linewidth = 1) +

  # Arrows and labels
  geom_segment(aes(x = 0, y = 0, xend = Component1, yend = Component2),
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "steelblue", linewidth = 1.2) +
  geom_text(aes(label = Variable), 
            color = "steelblue", size = 4, fontface = "bold",
            nudge_x = ifelse(loadings_df$Component1 > 0, 0.05, -0.05),
            nudge_y = ifelse(loadings_df$Component2 > 0, 0.05, -0.05)) +
  
  # Optional: Response direction (illustrative only)
  # You can calculate actual correlation direction if desired
  geom_segment(aes(x = 0, y = 0, xend = 0.6, yend = 0.4), 
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "indianred", linewidth = 1.5) +
  geom_text(aes(x = 0.68, y = 0.45, label = "Recruitment"), 
             color = "indianred", size = 4, fontface = "bold") +
  
  xlim(-1.1, 1.1) + ylim(-1.1, 1.1) +
  labs(x = "Component 1", y = "Component 2", title = "(a)") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  coord_fixed()


# ========== FIGURE B: COMPONENT 1 vs RESPONSE ==========

# Ensure response is matched to filtered data
component1_scores <- scores(plsr)[, 1]
response_var <- Y  # this Y comes from the filtered, complete-case data

# Compute R² and p-value
var_explained <- explvar(plsr)[1]
lm_comp1 <- lm(response_var ~ component1_scores)
lm_summary <- summary(lm_comp1)
p_value <- lm_summary$coefficients[2, 4]
r_squared <- lm_summary$r.squared

# Format p-value
p_text <- if (p_value < 0.001) {
  "p < 0.001"
} else if (p_value < 0.01) {
  paste0("p = ", format(round(p_value, 3), nsmall = 3))
} else {
  paste0("p = ", format(round(p_value, 2), nsmall = 2))
}

annotation_text <- paste0("R² = ", format(round(r_squared, 3), nsmall = 3), "\n", p_text)

fig_b_mid <- ggplot(data.frame(Component1 = component1_scores, Response = response_var),
                aes(x = Component1, y = Response)) +
  geom_point(size = 2.5, alpha = 0.7) +
  geom_smooth(method = "lm", color = "steelblue", fill = "black", alpha = 0.3) +
  annotate("text", 
           x = Inf, y = Inf, 
           label = annotation_text,
           hjust = 1.3, vjust = 1.3,
           size = 4, 
           fontface = "bold",
           color = "black") +
  labs(
    x = paste0("PLSR component 1 (", round(var_explained, 1), "%)"),
    y = "Recruitment Deviations",
    title = "Central Region"
  ) +
  theme_classic() +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )



# ========== FIGURE C: VIP PLOT ==========

fig_c_mid <- ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "",
       x = "Predictor",
       y = "VIP Score") +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )


# ========== COMBINE ALL THREE FIGURES ==========
mid_AVG_PSLR <- fig_a_mid + fig_b_mid + fig_c_mid + 
  plot_layout(ncol = 3)
mid_AVG_PSLR

# ========== SAVE ==========
ggsave("mid_feb_aug_pslr.png", width = 15, height = 5, dpi = 300)

```


## PLSR Feb - Sep spatially separated,  south region averaged 
```{r}
# combined 
ROMS_CUTI_environmental_combined_average <- ROMS_CUTI_environmental_combined_all_yr %>% 
  filter(Region == 'south') %>% 
  filter(Month %in% c("Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep")) %>% 
  group_by(Year) %>%
  summarise(across(
    c(DO_avg, pH_avg, Temperature_avg, Chla_avg, Vwind_avg,CUTI),
    ~ mean(.x, na.rm = TRUE),
    .names = "mean_{.col}"
  )) %>%
  ungroup()

df_gopher <-left_join(ROMS_CUTI_environmental_combined_average,goph_recruit, by = "Year")

df_gopher <- df_gopher %>% 
  select(dev, mean_CUTI,mean_pH_avg, mean_DO_avg, mean_Temperature_avg, mean_Chla_avg, mean_Vwind_avg) %>% 
  rename(deviation = dev,
         CUTI = mean_CUTI,
         pH = mean_pH_avg, 
         DO = mean_DO_avg, 
         Temperature = mean_Temperature_avg, 
         "Primary Production" = mean_Chla_avg, 
         "Meridonal Wind" = mean_Vwind_avg)

# Define X and Y together and filter complete cases
X_raw <- df_gopher %>% 
  select(CUTI, "Meridonal Wind" ,pH, DO, Temperature, "Primary Production")

# Combine into one frame with response
data_complete <- cbind(deviation = df_gopher$deviation, X_raw) %>% 
  as.data.frame() %>% 
  na.omit()  # remove rows with any NA

# Now separate into X and Y
Y <- data_complete$deviation
X <- as.matrix(data_complete %>% select(-deviation))

plsr <- plsr(deviation ~ ., data = data_complete, scale = TRUE, validation = "LOO")
pls_scores <- scores(plsr)

df_pls <- data.frame(
  dev = Y,
  Comp1 = pls_scores[, 1],
  Comp2 = pls_scores[, 2]
)

# Summary of model
summary(plsr)

# Root Mean Squared Error of Prediction
RMSEP(plsr)

# Choose number of components based on RMSEP or % variance explained
plot(RMSEP(plsr), legendpos = "topright")

# Variance explained
explvar(plsr)  # % of variance explained in X by each component

# Component loadings: how original vars contribute to latent variables
loadings(plsr)

# Scores: the new coordinate representation of observations
pls_scores <- scores(plsr)

# Biplot: visualize scores and loadings
biplot(plsr_march, comps = 1:2)

# Fit a linear model using first 2 PLS components
lm_pls <- lm(dev ~ Comp1 + Comp2, data = df_pls)
summary(lm_pls)

# check residuals 
simulated_res <- simulateResiduals(fittedModel = lm_pls)
plot(simulated_res) #these look good

selectNcomp(plsr, method = "onesigma")

lm_pls_1comp <- lm(dev ~ Comp1, data = df_pls)
summary(lm_pls_1comp)

plot(RMSEP(plsr), legendpos = "topright")

# 1-component model is optimal, so we use opt.comp = 1
vip_scores <- VIP(plsr, opt.comp = 1)

# Turn into data frame properly
vip_df <- data.frame(
  Variable = names(vip_scores),
  VIP = vip_scores
)

ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = .8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "Variable Importance in Projection (VIP)",
       x = "Predictor",
       y = "VIP Score")
```

### table of correlations and weights
```{r}
# Choose which component to analyze 
comp_num <- 1

# 1. WEIGHT² - Variable importance/contribution to the component
weights_raw <- loading.weights(plsr)[, comp_num]
weights_squared <- weights_raw^2

# 2. CORRELATION - Between each predictor and the response variable
# Get the names of predictors used in the PLS model
predictor_names <- colnames(X)

# Use same predictors from the original full dataset for correlation
X_original <- plsr$model %>% select(all_of(predictor_names))
Y_original <- plsr$model$dev  # <-- Fixed line

# Ensure there are no NAs in either X_original or Y_original
complete_rows <- complete.cases(X_original, Y_original)
X_original <- X_original[complete_rows, ]
Y_original <- Y_original[complete_rows]

# Calculate correlations
correlations <- cor(X_original, Y_original)

# 3. LOADING - Direction and magnitude
loadings_values <- loadings(plsr)[, comp_num]

# Create summary table
pls_summary_table <- data.frame(
  Predictor = predictor_names,
  Weight_squared = round(weights_squared, 3),
  Correlation = round(correlations, 3),
  Loading_value = round(loadings_values, 3),
  Loading_direction = ifelse(loadings_values > 0, "+", "-")
)

# View the table
print(pls_summary_table)
```

### figure for plsr
```{r}
library(ggplot2)
library(gridExtra)
library(grid)

# Extract predictor names from X
predictor_names <- colnames(X)

# ========== FIGURE A: PLS BIPLOT ==========

loadings_data <- loadings(plsr)[, 1:2]
loadings_df <- data.frame(
  Variable = rownames(loadings_data),
  Component1 = loadings_data[, 1],
  Component2 = loadings_data[, 2]
)

fig_a_south <- ggplot(loadings_df, aes(x = Component1, y = Component2)) +
  geom_path(data = data.frame(
    x = cos(seq(0, 2 * pi, length.out = 100)),
    y = sin(seq(0, 2 * pi, length.out = 100))
  ), aes(x = x, y = y), color = "black", linewidth = 1) +

  # Arrows and labels
  geom_segment(aes(x = 0, y = 0, xend = Component1, yend = Component2),
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "steelblue", linewidth = 1.2) +
  geom_text(aes(label = Variable), 
            color = "steelblue", size = 4, fontface = "bold",
            nudge_x = ifelse(loadings_df$Component1 > 0, 0.05, -0.05),
            nudge_y = ifelse(loadings_df$Component2 > 0, 0.05, -0.05)) +
  
  # Optional: Response direction (illustrative only)
  # You can calculate actual correlation direction if desired
  geom_segment(aes(x = 0, y = 0, xend = 0.6, yend = 0.4), 
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "indianred", linewidth = 1.5) +
  geom_text(aes(x = 0.68, y = 0.45, label = "Recruitment"), 
             color = "indianred", size = 4, fontface = "bold") +
  
  xlim(-1.1, 1.1) + ylim(-1.1, 1.1) +
  labs(x = "Component 1", y = "Component 2", title = "(a)") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  coord_fixed()


# ========== FIGURE B: COMPONENT 1 vs RESPONSE ==========

# Ensure response is matched to filtered data
component1_scores <- scores(plsr)[, 1]
response_var <- Y  # this Y comes from the filtered, complete-case data

# Compute R² and p-value
var_explained <- explvar(plsr)[1]
lm_comp1 <- lm(response_var ~ component1_scores)
lm_summary <- summary(lm_comp1)
p_value <- lm_summary$coefficients[2, 4]
r_squared <- lm_summary$r.squared

# Format p-value
p_text <- if (p_value < 0.001) {
  "p < 0.001"
} else if (p_value < 0.01) {
  paste0("p = ", format(round(p_value, 3), nsmall = 3))
} else {
  paste0("p = ", format(round(p_value, 2), nsmall = 2))
}

annotation_text <- paste0("R² = ", format(round(r_squared, 3), nsmall = 3), "\n", p_text)

fig_b_south <- ggplot(data.frame(Component1 = component1_scores, Response = response_var),
                aes(x = Component1, y = Response)) +
  geom_point(size = 2.5, alpha = 0.7) +
  geom_smooth(method = "lm", color = "steelblue", fill = "black", alpha = 0.3) +
  annotate("text", 
           x = Inf, y = Inf, 
           label = annotation_text,
           hjust = 1.3, vjust = 1.3,
           size = 4, 
           fontface = "bold",
           color = "black") +
  labs(
    x = paste0("PLSR component 1 (", round(var_explained, 1), "%)"),
    y = "Recruitment Deviations",
    title = "Southern Region"
  ) +
  theme_classic() +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )



# ========== FIGURE C: VIP PLOT ==========

fig_c_south <- ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "",
       x = "Predictor",
       y = "VIP Score") +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )


# ========== COMBINE ALL THREE FIGURES ==========
south_AVG_PSLR <- fig_a_south + fig_b_south + fig_c_south + 
  plot_layout(ncol = 3)
south_AVG_PSLR

# ========== SAVE ==========
ggsave("south_feb_aug_pslr.png", width = 15, height = 5, dpi = 300)

```
## Putting all regional Feb - Sep average PLSR together 
```{r}
combined_plot <- fig_a_all + fig_b_all + fig_c_all + fig_a_north + fig_b_north + fig_c_north + fig_a_mid + fig_b_mid + fig_c_mid + fig_a_south + fig_b_south + fig_c_south +
  plot_layout(ncol = 3) 
combined_plot

combined_plot <- (fig_b_all + fig_c_all) / (fig_b_north + fig_c_north) / (fig_b_mid + fig_c_mid) / (fig_b_south + fig_c_south)
combined_plot
ggsave("combined_pslr_spatially_separated.png", width = 15, height = 10, dpi = 300)
```







# PSLR - spatialy separated march
## PLSR March spatially separated, all regions averaged 
```{r}
# combined 
ROMS_CUTI_environmental_combined_average <- ROMS_CUTI_environmental_combined_all_yr %>% 
  filter(Region == 'all') %>% 
  filter(Month %in% c("Mar"))

df_gopher <-left_join(ROMS_CUTI_environmental_combined_average,goph_recruit, by = "Year")

df_gopher <- df_gopher %>% 
  select(dev, CUTI, pH_avg, DO_avg, Temperature_avg, Chla_avg, Vwind_avg) %>% 
  rename(deviation = dev,
         CUTI = CUTI,
         pH = pH_avg, 
         DO = DO_avg, 
         Temperature = Temperature_avg, 
         "Primary Production" = Chla_avg, 
         "Meridonal Wind" = Vwind_avg)

# Define X and Y together and filter complete cases
X_raw <- df_gopher %>% 
  select(CUTI, "Meridonal Wind" ,pH, DO, Temperature, "Primary Production")

# Combine into one frame with response
data_complete <- cbind(deviation = df_gopher$deviation, X_raw) %>% 
  as.data.frame() %>% 
  na.omit()  # remove rows with any NA

# Now separate into X and Y
Y <- data_complete$deviation
X <- as.matrix(data_complete %>% select(-deviation))

plsr <- plsr(deviation ~ ., data = data_complete, scale = TRUE, validation = "LOO")
pls_scores <- scores(plsr)

df_pls <- data.frame(
  dev = Y,
  Comp1 = pls_scores[, 1],
  Comp2 = pls_scores[, 2]
)

# Summary of model
summary(plsr)

# Root Mean Squared Error of Prediction
RMSEP(plsr)

# Choose number of components based on RMSEP or % variance explained
plot(RMSEP(plsr), legendpos = "topright")

# Variance explained
explvar(plsr)  # % of variance explained in X by each component

# Component loadings: how original vars contribute to latent variables
loadings(plsr)

# Scores: the new coordinate representation of observations
pls_scores <- scores(plsr)

# Biplot: visualize scores and loadings
biplot(plsr_march, comps = 1:2)

# Fit a linear model using first 2 PLS components
lm_pls <- lm(dev ~ Comp1 + Comp2, data = df_pls)
summary(lm_pls)

# check residuals 
simulated_res <- simulateResiduals(fittedModel = lm_pls)
plot(simulated_res) #these look good

selectNcomp(plsr, method = "onesigma")

lm_pls_1comp <- lm(dev ~ Comp1, data = df_pls)
summary(lm_pls_1comp)

plot(RMSEP(plsr), legendpos = "topright")

# 1-component model is optimal, so we use opt.comp = 1
vip_scores <- VIP(plsr, opt.comp = 1)

# Turn into data frame properly
vip_df <- data.frame(
  Variable = names(vip_scores),
  VIP = vip_scores
)

ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = .8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "Variable Importance in Projection (VIP)",
       x = "Predictor",
       y = "VIP Score")
```

### table of correlations and weights
```{r}
# Choose which component to analyze 
comp_num <- 1

# 1. WEIGHT² - Variable importance/contribution to the component
weights_raw <- loading.weights(plsr)[, comp_num]
weights_squared <- weights_raw^2

# 2. CORRELATION - Between each predictor and the response variable
# Get the names of predictors used in the PLS model
predictor_names <- colnames(X)

# Use same predictors from the original full dataset for correlation
X_original <- plsr$model %>% select(all_of(predictor_names))
Y_original <- plsr$model$dev  # <-- Fixed line

# Ensure there are no NAs in either X_original or Y_original
complete_rows <- complete.cases(X_original, Y_original)
X_original <- X_original[complete_rows, ]
Y_original <- Y_original[complete_rows]

# Calculate correlations
correlations <- cor(X_original, Y_original)

# 3. LOADING - Direction and magnitude
loadings_values <- loadings(plsr)[, comp_num]

# Create summary table
pls_summary_table <- data.frame(
  Predictor = predictor_names,
  Weight_squared = round(weights_squared, 3),
  Correlation = round(correlations, 3),
  Loading_value = round(loadings_values, 3),
  Loading_direction = ifelse(loadings_values > 0, "+", "-")
)

# View the table
print(pls_summary_table)
```




### figure for plsr
```{r}
library(ggplot2)
library(gridExtra)
library(grid)

# Extract predictor names from X
predictor_names <- colnames(X)

# ========== FIGURE A: PLS BIPLOT ==========

loadings_data <- loadings(plsr_march)[, 1:2]
loadings_df <- data.frame(
  Variable = rownames(loadings_data),
  Component1 = loadings_data[, 1],
  Component2 = loadings_data[, 2]
)

fig_a_all <- ggplot(loadings_df, aes(x = Component1, y = Component2)) +
  geom_path(data = data.frame(
    x = cos(seq(0, 2 * pi, length.out = 100)),
    y = sin(seq(0, 2 * pi, length.out = 100))
  ), aes(x = x, y = y), color = "black", linewidth = 1) +

  # Arrows and labels
  geom_segment(aes(x = 0, y = 0, xend = Component1, yend = Component2),
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "steelblue", linewidth = 1.2) +
  geom_text(aes(label = Variable), 
            color = "steelblue", size = 4, fontface = "bold",
            nudge_x = ifelse(loadings_df$Component1 > 0, 0.05, -0.05),
            nudge_y = ifelse(loadings_df$Component2 > 0, 0.05, -0.05)) +
  
  # Optional: Response direction (illustrative only)
  # You can calculate actual correlation direction if desired
  geom_segment(aes(x = 0, y = 0, xend = 0.6, yend = 0.4), 
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "indianred", linewidth = 1.5) +
  geom_text(aes(x = 0.68, y = 0.45, label = "Recruitment"), 
             color = "indianred", size = 4, fontface = "bold") +
  
  xlim(-1.1, 1.1) + ylim(-1.1, 1.1) +
  labs(x = "Component 1", y = "Component 2", title = "Entire Region") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  coord_fixed()


# ========== FIGURE B: COMPONENT 1 vs RESPONSE ==========

# Ensure response is matched to filtered data
component1_scores <- scores(plsr_march)[, 1]
response_var <- Y  # this Y comes from the filtered, complete-case data

# Compute R² and p-value
var_explained <- explvar(plsr_march)[1]
lm_comp1 <- lm(response_var ~ component1_scores)
lm_summary <- summary(lm_comp1)
p_value <- lm_summary$coefficients[2, 4]
r_squared <- lm_summary$r.squared

# Format p-value
p_text <- if (p_value < 0.001) {
  "p < 0.001"
} else if (p_value < 0.01) {
  paste0("p = ", format(round(p_value, 3), nsmall = 3))
} else {
  paste0("p = ", format(round(p_value, 2), nsmall = 2))
}

annotation_text <- paste0("R² = ", format(round(r_squared, 3), nsmall = 3), "\n", p_text)

fig_b_all <- ggplot(data.frame(Component1 = component1_scores, Response = response_var),
                aes(x = Component1, y = Response)) +
  geom_point(size = 2.5, alpha = 0.7) +
  geom_smooth(method = "lm", color = "steelblue", fill = "black", alpha = 0.3) +
  annotate("text", 
           x = Inf, y = Inf, 
           label = annotation_text,
           hjust = 1.3, vjust = 1.3,
           size = 4, 
           fontface = "bold",
           color = "black") +
  labs(
    x = paste0("PLSR component 1 (", round(var_explained, 1), "%)"),
    y = "Recruitment Deviations",
    title = "Entire Region"
  ) +
  theme_classic() +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )



# ========== FIGURE C: VIP PLOT ==========

fig_c_all <- ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "",
       x = "Predictor",
       y = "VIP Score") +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )


# ========== COMBINE ALL THREE FIGURES ==========
ALL_AVG_PSLR <- fig_a_all + fig_b_all + fig_c_all + 
  plot_layout(ncol = 3)
ALL_AVG_PSLR

# ========== SAVE ==========
ggsave("all_feb_aug_pslr.png", width = 15, height = 5, dpi = 300)
```

## PLSR March spatially separated,  north region averaged 
```{r}
# combined 
ROMS_CUTI_environmental_combined_average <- ROMS_CUTI_environmental_combined_all_yr %>% 
  filter(Region == 'north') %>% 
  filter(Month %in% c("Mar"))

df_gopher <-left_join(ROMS_CUTI_environmental_combined_average,goph_recruit, by = "Year")

df_gopher <- df_gopher %>% 
  select(dev, CUTI, pH_avg, DO_avg, Temperature_avg, Chla_avg, Vwind_avg) %>% 
  rename(deviation = dev,
         CUTI = CUTI,
         pH = pH_avg, 
         DO = DO_avg, 
         Temperature = Temperature_avg, 
         "Primary Production" = Chla_avg, 
         "Meridonal Wind" = Vwind_avg)

# Define X and Y together and filter complete cases
X_raw <- df_gopher %>% 
  select(CUTI, "Meridonal Wind" ,pH, DO, Temperature, "Primary Production")

# Combine into one frame with response
data_complete <- cbind(deviation = df_gopher$deviation, X_raw) %>% 
  as.data.frame() %>% 
  na.omit()  # remove rows with any NA

# Now separate into X and Y
Y <- data_complete$deviation
X <- as.matrix(data_complete %>% select(-deviation))

plsr <- plsr(deviation ~ ., data = data_complete, scale = TRUE, validation = "LOO")
pls_scores <- scores(plsr)

df_pls <- data.frame(
  dev = Y,
  Comp1 = pls_scores[, 1],
  Comp2 = pls_scores[, 2]
)

# Summary of model
summary(plsr)

# Root Mean Squared Error of Prediction
RMSEP(plsr)

# Choose number of components based on RMSEP or % variance explained
plot(RMSEP(plsr), legendpos = "topright")

# Variance explained
explvar(plsr)  # % of variance explained in X by each component

# Component loadings: how original vars contribute to latent variables
loadings(plsr)

# Scores: the new coordinate representation of observations
pls_scores <- scores(plsr)

# Biplot: visualize scores and loadings
biplot(plsr_march, comps = 1:2)

# Fit a linear model using first 2 PLS components
lm_pls <- lm(dev ~ Comp1 + Comp2, data = df_pls)
summary(lm_pls)

# check residuals 
simulated_res <- simulateResiduals(fittedModel = lm_pls)
plot(simulated_res) #these look good

selectNcomp(plsr, method = "onesigma")

lm_pls_1comp <- lm(dev ~ Comp1, data = df_pls)
summary(lm_pls_1comp)

plot(RMSEP(plsr), legendpos = "topright")

# 1-component model is optimal, so we use opt.comp = 1
vip_scores <- VIP(plsr, opt.comp = 1)

# Turn into data frame properly
vip_df <- data.frame(
  Variable = names(vip_scores),
  VIP = vip_scores
)

ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = .8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "Variable Importance in Projection (VIP)",
       x = "Predictor",
       y = "VIP Score")
```

### table of correlations and weights
```{r}
# Choose which component to analyze 
comp_num <- 1

# 1. WEIGHT² - Variable importance/contribution to the component
weights_raw <- loading.weights(plsr)[, comp_num]
weights_squared <- weights_raw^2

# 2. CORRELATION - Between each predictor and the response variable
# Get the names of predictors used in the PLS model
predictor_names <- colnames(X)

# Use same predictors from the original full dataset for correlation
X_original <- plsr$model %>% select(all_of(predictor_names))
Y_original <- plsr$model$dev  # <-- Fixed line

# Ensure there are no NAs in either X_original or Y_original
complete_rows <- complete.cases(X_original, Y_original)
X_original <- X_original[complete_rows, ]
Y_original <- Y_original[complete_rows]

# Calculate correlations
correlations <- cor(X_original, Y_original)

# 3. LOADING - Direction and magnitude
loadings_values <- loadings(plsr)[, comp_num]

# Create summary table
pls_summary_table <- data.frame(
  Predictor = predictor_names,
  Weight_squared = round(weights_squared, 3),
  Correlation = round(correlations, 3),
  Loading_value = round(loadings_values, 3),
  Loading_direction = ifelse(loadings_values > 0, "+", "-")
)

# View the table
print(pls_summary_table)
```

### figure for plsr
```{r}
library(ggplot2)
library(gridExtra)
library(grid)

# Extract predictor names from X
predictor_names <- colnames(X)

# ========== FIGURE A: PLS BIPLOT ==========

loadings_data <- loadings(plsr)[, 1:2]
loadings_df <- data.frame(
  Variable = rownames(loadings_data),
  Component1 = loadings_data[, 1],
  Component2 = loadings_data[, 2]
)

fig_a_north <- ggplot(loadings_df, aes(x = Component1, y = Component2)) +
  geom_path(data = data.frame(
    x = cos(seq(0, 2 * pi, length.out = 100)),
    y = sin(seq(0, 2 * pi, length.out = 100))
  ), aes(x = x, y = y), color = "black", linewidth = 1) +

  # Arrows and labels
  geom_segment(aes(x = 0, y = 0, xend = Component1, yend = Component2),
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "steelblue", linewidth = 1.2) +
  geom_text(aes(label = Variable), 
            color = "steelblue", size = 4, fontface = "bold",
            nudge_x = ifelse(loadings_df$Component1 > 0, 0.05, -0.05),
            nudge_y = ifelse(loadings_df$Component2 > 0, 0.05, -0.05)) +
  
  # Optional: Response direction (illustrative only)
  # You can calculate actual correlation direction if desired
  geom_segment(aes(x = 0, y = 0, xend = 0.6, yend = 0.4), 
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "indianred", linewidth = 1.5) +
  geom_text(aes(x = 0.68, y = 0.45, label = "Recruitment"), 
             color = "indianred", size = 4, fontface = "bold") +
  
  xlim(-1.1, 1.1) + ylim(-1.1, 1.1) +
  labs(x = "Component 1", y = "Component 2", title = "(a)") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  coord_fixed()


# ========== FIGURE B: COMPONENT 1 vs RESPONSE ==========

# Ensure response is matched to filtered data
component1_scores <- scores(plsr)[, 1]
response_var <- Y  # this Y comes from the filtered, complete-case data

# Compute R² and p-value
var_explained <- explvar(plsr)[1]
lm_comp1 <- lm(response_var ~ component1_scores)
lm_summary <- summary(lm_comp1)
p_value <- lm_summary$coefficients[2, 4]
r_squared <- lm_summary$r.squared

# Format p-value
p_text <- if (p_value < 0.001) {
  "p < 0.001"
} else if (p_value < 0.01) {
  paste0("p = ", format(round(p_value, 3), nsmall = 3))
} else {
  paste0("p = ", format(round(p_value, 2), nsmall = 2))
}

annotation_text <- paste0("R² = ", format(round(r_squared, 3), nsmall = 3), "\n", p_text)

fig_b_north <- ggplot(data.frame(Component1 = component1_scores, Response = response_var),
                aes(x = Component1, y = Response)) +
  geom_point(size = 2.5, alpha = 0.7) +
  geom_smooth(method = "lm", color = "steelblue", fill = "black", alpha = 0.3) +
  annotate("text", 
           x = Inf, y = Inf, 
           label = annotation_text,
           hjust = 1.3, vjust = 1.3,
           size = 4, 
           fontface = "bold",
           color = "black") +
  labs(
    x = paste0("PLSR component 1 (", round(var_explained, 1), "%)"),
    y = "Recruitment Deviations",
    title = "North Region"
  ) +
  theme_classic() +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )



# ========== FIGURE C: VIP PLOT ==========

fig_c_north <- ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "",
       x = "Predictor",
       y = "VIP Score") +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )


# ========== COMBINE ALL THREE FIGURES ==========
NORTH_AVG_PSLR <- fig_a_north + fig_b_north + fig_c_north + 
  plot_layout(ncol = 3)
NORTH_AVG_PSLR

# ========== SAVE ==========
ggsave("north_feb_aug_pslr.png", width = 15, height = 5, dpi = 300)

```

## PLSR March spatially separated,  mid region averaged 
```{r}
# combined 
ROMS_CUTI_environmental_combined_average <- ROMS_CUTI_environmental_combined_all_yr %>% 
  filter(Region == 'mid') %>% 
  filter(Month %in% c("Mar"))

df_gopher <-left_join(ROMS_CUTI_environmental_combined_average,goph_recruit, by = "Year")

df_gopher <- df_gopher %>% 
  select(dev, CUTI, pH_avg, DO_avg, Temperature_avg, Chla_avg, Vwind_avg) %>% 
  rename(deviation = dev,
         CUTI = CUTI,
         pH = pH_avg, 
         DO = DO_avg, 
         Temperature = Temperature_avg, 
         "Primary Production" = Chla_avg, 
         "Meridonal Wind" = Vwind_avg)

# Define X and Y together and filter complete cases
X_raw <- df_gopher %>% 
  select(CUTI, "Meridonal Wind" ,pH, DO, Temperature, "Primary Production")

# Combine into one frame with response
data_complete <- cbind(deviation = df_gopher$deviation, X_raw) %>% 
  as.data.frame() %>% 
  na.omit()  # remove rows with any NA

# Now separate into X and Y
Y <- data_complete$deviation
X <- as.matrix(data_complete %>% select(-deviation))

plsr <- plsr(deviation ~ ., data = data_complete, scale = TRUE, validation = "LOO")
pls_scores <- scores(plsr)

df_pls <- data.frame(
  dev = Y,
  Comp1 = pls_scores[, 1],
  Comp2 = pls_scores[, 2]
)

# Summary of model
summary(plsr)

# Root Mean Squared Error of Prediction
RMSEP(plsr)

# Choose number of components based on RMSEP or % variance explained
plot(RMSEP(plsr), legendpos = "topright")

# Variance explained
explvar(plsr)  # % of variance explained in X by each component

# Component loadings: how original vars contribute to latent variables
loadings(plsr)

# Scores: the new coordinate representation of observations
pls_scores <- scores(plsr)

# Biplot: visualize scores and loadings
biplot(plsr_march, comps = 1:2)

# Fit a linear model using first 2 PLS components
lm_pls <- lm(dev ~ Comp1 + Comp2, data = df_pls)
summary(lm_pls)

# check residuals 
simulated_res <- simulateResiduals(fittedModel = lm_pls)
plot(simulated_res) #these look good

selectNcomp(plsr, method = "onesigma")

lm_pls_1comp <- lm(dev ~ Comp1, data = df_pls)
summary(lm_pls_1comp)

plot(RMSEP(plsr), legendpos = "topright")

# 1-component model is optimal, so we use opt.comp = 1
vip_scores <- VIP(plsr, opt.comp = 1)

# Turn into data frame properly
vip_df <- data.frame(
  Variable = names(vip_scores),
  VIP = vip_scores
)

ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = .8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "Variable Importance in Projection (VIP)",
       x = "Predictor",
       y = "VIP Score")
```

### table of correlations and weights
```{r}
# Choose which component to analyze 
comp_num <- 1

# 1. WEIGHT² - Variable importance/contribution to the component
weights_raw <- loading.weights(plsr)[, comp_num]
weights_squared <- weights_raw^2

# 2. CORRELATION - Between each predictor and the response variable
# Get the names of predictors used in the PLS model
predictor_names <- colnames(X)

# Use same predictors from the original full dataset for correlation
X_original <- plsr$model %>% select(all_of(predictor_names))
Y_original <- plsr$model$dev  # <-- Fixed line

# Ensure there are no NAs in either X_original or Y_original
complete_rows <- complete.cases(X_original, Y_original)
X_original <- X_original[complete_rows, ]
Y_original <- Y_original[complete_rows]

# Calculate correlations
correlations <- cor(X_original, Y_original)

# 3. LOADING - Direction and magnitude
loadings_values <- loadings(plsr)[, comp_num]

# Create summary table
pls_summary_table <- data.frame(
  Predictor = predictor_names,
  Weight_squared = round(weights_squared, 3),
  Correlation = round(correlations, 3),
  Loading_value = round(loadings_values, 3),
  Loading_direction = ifelse(loadings_values > 0, "+", "-")
)

# View the table
print(pls_summary_table)
```

### figure for plsr
```{r}
library(ggplot2)
library(gridExtra)
library(grid)

# Extract predictor names from X
predictor_names <- colnames(X)

# ========== FIGURE A: PLS BIPLOT ==========

loadings_data <- loadings(plsr)[, 1:2]
loadings_df <- data.frame(
  Variable = rownames(loadings_data),
  Component1 = loadings_data[, 1],
  Component2 = loadings_data[, 2]
)

fig_a_mid <- ggplot(loadings_df, aes(x = Component1, y = Component2)) +
  geom_path(data = data.frame(
    x = cos(seq(0, 2 * pi, length.out = 100)),
    y = sin(seq(0, 2 * pi, length.out = 100))
  ), aes(x = x, y = y), color = "black", linewidth = 1) +

  # Arrows and labels
  geom_segment(aes(x = 0, y = 0, xend = Component1, yend = Component2),
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "steelblue", linewidth = 1.2) +
  geom_text(aes(label = Variable), 
            color = "steelblue", size = 4, fontface = "bold",
            nudge_x = ifelse(loadings_df$Component1 > 0, 0.05, -0.05),
            nudge_y = ifelse(loadings_df$Component2 > 0, 0.05, -0.05)) +
  
  # Optional: Response direction (illustrative only)
  # You can calculate actual correlation direction if desired
  geom_segment(aes(x = 0, y = 0, xend = 0.6, yend = 0.4), 
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "indianred", linewidth = 1.5) +
  geom_text(aes(x = 0.68, y = 0.45, label = "Recruitment"), 
             color = "indianred", size = 4, fontface = "bold") +
  
  xlim(-1.1, 1.1) + ylim(-1.1, 1.1) +
  labs(x = "Component 1", y = "Component 2", title = "(a)") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  coord_fixed()


# ========== FIGURE B: COMPONENT 1 vs RESPONSE ==========

# Ensure response is matched to filtered data
component1_scores <- scores(plsr)[, 1]
response_var <- Y  # this Y comes from the filtered, complete-case data

# Compute R² and p-value
var_explained <- explvar(plsr)[1]
lm_comp1 <- lm(response_var ~ component1_scores)
lm_summary <- summary(lm_comp1)
p_value <- lm_summary$coefficients[2, 4]
r_squared <- lm_summary$r.squared

# Format p-value
p_text <- if (p_value < 0.001) {
  "p < 0.001"
} else if (p_value < 0.01) {
  paste0("p = ", format(round(p_value, 3), nsmall = 3))
} else {
  paste0("p = ", format(round(p_value, 2), nsmall = 2))
}

annotation_text <- paste0("R² = ", format(round(r_squared, 3), nsmall = 3), "\n", p_text)

fig_b_mid <- ggplot(data.frame(Component1 = component1_scores, Response = response_var),
                aes(x = Component1, y = Response)) +
  geom_point(size = 2.5, alpha = 0.7) +
  geom_smooth(method = "lm", color = "steelblue", fill = "black", alpha = 0.3) +
  annotate("text", 
           x = Inf, y = Inf, 
           label = annotation_text,
           hjust = 1.3, vjust = 1.3,
           size = 4, 
           fontface = "bold",
           color = "black") +
  labs(
    x = paste0("PLSR component 1 (", round(var_explained, 1), "%)"),
    y = "Recruitment Deviations",
    title = "Central Region"
  ) +
  theme_classic() +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )



# ========== FIGURE C: VIP PLOT ==========

fig_c_mid <- ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "",
       x = "Predictor",
       y = "VIP Score") +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )


# ========== COMBINE ALL THREE FIGURES ==========
mid_AVG_PSLR <- fig_a_mid + fig_b_mid + fig_c_mid + 
  plot_layout(ncol = 3)
mid_AVG_PSLR

# ========== SAVE ==========
ggsave("mid_feb_aug_pslr.png", width = 15, height = 5, dpi = 300)

```


## PLSR March spatially separated,  south region averaged 
```{r}
# combined 
ROMS_CUTI_environmental_combined_average <- ROMS_CUTI_environmental_combined_all_yr %>% 
  filter(Region == 'south') %>% 
  filter(Month %in% c("Mar"))

df_gopher <-left_join(ROMS_CUTI_environmental_combined_average,goph_recruit, by = "Year")

df_gopher <- df_gopher %>% 
  select(dev, CUTI, pH_avg, DO_avg, Temperature_avg, Chla_avg, Vwind_avg) %>% 
  rename(deviation = dev,
         CUTI = CUTI,
         pH = pH_avg, 
         DO = DO_avg, 
         Temperature = Temperature_avg, 
         "Primary Production" = Chla_avg, 
         "Meridonal Wind" = Vwind_avg)

# Define X and Y together and filter complete cases
X_raw <- df_gopher %>% 
  select(CUTI, "Meridonal Wind" ,pH, DO, Temperature, "Primary Production")

# Combine into one frame with response
data_complete <- cbind(deviation = df_gopher$deviation, X_raw) %>% 
  as.data.frame() %>% 
  na.omit()  # remove rows with any NA

# Now separate into X and Y
Y <- data_complete$deviation
X <- as.matrix(data_complete %>% select(-deviation))

plsr <- plsr(deviation ~ ., data = data_complete, scale = TRUE, validation = "LOO")
pls_scores <- scores(plsr)

df_pls <- data.frame(
  dev = Y,
  Comp1 = pls_scores[, 1],
  Comp2 = pls_scores[, 2]
)

# Summary of model
summary(plsr)

# Root Mean Squared Error of Prediction
RMSEP(plsr)

# Choose number of components based on RMSEP or % variance explained
plot(RMSEP(plsr), legendpos = "topright")

# Variance explained
explvar(plsr)  # % of variance explained in X by each component

# Component loadings: how original vars contribute to latent variables
loadings(plsr)

# Scores: the new coordinate representation of observations
pls_scores <- scores(plsr)

# Biplot: visualize scores and loadings
biplot(plsr_march, comps = 1:2)

# Fit a linear model using first 2 PLS components
lm_pls <- lm(dev ~ Comp1 + Comp2, data = df_pls)
summary(lm_pls)

# check residuals 
simulated_res <- simulateResiduals(fittedModel = lm_pls)
plot(simulated_res) #these look good

selectNcomp(plsr, method = "onesigma")

lm_pls_1comp <- lm(dev ~ Comp1, data = df_pls)
summary(lm_pls_1comp)

plot(RMSEP(plsr), legendpos = "topright")

# 1-component model is optimal, so we use opt.comp = 1
vip_scores <- VIP(plsr, opt.comp = 1)

# Turn into data frame properly
vip_df <- data.frame(
  Variable = names(vip_scores),
  VIP = vip_scores
)

ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = .8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "Variable Importance in Projection (VIP)",
       x = "Predictor",
       y = "VIP Score")
```

### table of correlations and weights
```{r}
# Choose which component to analyze 
comp_num <- 1

# 1. WEIGHT² - Variable importance/contribution to the component
weights_raw <- loading.weights(plsr)[, comp_num]
weights_squared <- weights_raw^2

# 2. CORRELATION - Between each predictor and the response variable
# Get the names of predictors used in the PLS model
predictor_names <- colnames(X)

# Use same predictors from the original full dataset for correlation
X_original <- plsr$model %>% select(all_of(predictor_names))
Y_original <- plsr$model$dev  # <-- Fixed line

# Ensure there are no NAs in either X_original or Y_original
complete_rows <- complete.cases(X_original, Y_original)
X_original <- X_original[complete_rows, ]
Y_original <- Y_original[complete_rows]

# Calculate correlations
correlations <- cor(X_original, Y_original)

# 3. LOADING - Direction and magnitude
loadings_values <- loadings(plsr)[, comp_num]

# Create summary table
pls_summary_table <- data.frame(
  Predictor = predictor_names,
  Weight_squared = round(weights_squared, 3),
  Correlation = round(correlations, 3),
  Loading_value = round(loadings_values, 3),
  Loading_direction = ifelse(loadings_values > 0, "+", "-")
)

# View the table
print(pls_summary_table)
```

### figure for plsr
```{r}
library(ggplot2)
library(gridExtra)
library(grid)

# Extract predictor names from X
predictor_names <- colnames(X)

# ========== FIGURE A: PLS BIPLOT ==========

loadings_data <- loadings(plsr)[, 1:2]
loadings_df <- data.frame(
  Variable = rownames(loadings_data),
  Component1 = loadings_data[, 1],
  Component2 = loadings_data[, 2]
)

fig_a_south <- ggplot(loadings_df, aes(x = Component1, y = Component2)) +
  geom_path(data = data.frame(
    x = cos(seq(0, 2 * pi, length.out = 100)),
    y = sin(seq(0, 2 * pi, length.out = 100))
  ), aes(x = x, y = y), color = "black", linewidth = 1) +

  # Arrows and labels
  geom_segment(aes(x = 0, y = 0, xend = Component1, yend = Component2),
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "steelblue", linewidth = 1.2) +
  geom_text(aes(label = Variable), 
            color = "steelblue", size = 4, fontface = "bold",
            nudge_x = ifelse(loadings_df$Component1 > 0, 0.05, -0.05),
            nudge_y = ifelse(loadings_df$Component2 > 0, 0.05, -0.05)) +
  
  # Optional: Response direction (illustrative only)
  # You can calculate actual correlation direction if desired
  geom_segment(aes(x = 0, y = 0, xend = 0.6, yend = 0.4), 
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "indianred", linewidth = 1.5) +
  geom_text(aes(x = 0.68, y = 0.45, label = "Recruitment"), 
             color = "indianred", size = 4, fontface = "bold") +
  
  xlim(-1.1, 1.1) + ylim(-1.1, 1.1) +
  labs(x = "Component 1", y = "Component 2", title = "(a)") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  coord_fixed()


# ========== FIGURE B: COMPONENT 1 vs RESPONSE ==========

# Ensure response is matched to filtered data
component1_scores <- scores(plsr)[, 1]
response_var <- Y  # this Y comes from the filtered, complete-case data

# Compute R² and p-value
var_explained <- explvar(plsr)[1]
lm_comp1 <- lm(response_var ~ component1_scores)
lm_summary <- summary(lm_comp1)
p_value <- lm_summary$coefficients[2, 4]
r_squared <- lm_summary$r.squared

# Format p-value
p_text <- if (p_value < 0.001) {
  "p < 0.001"
} else if (p_value < 0.01) {
  paste0("p = ", format(round(p_value, 3), nsmall = 3))
} else {
  paste0("p = ", format(round(p_value, 2), nsmall = 2))
}

annotation_text <- paste0("R² = ", format(round(r_squared, 3), nsmall = 3), "\n", p_text)

fig_b_south <- ggplot(data.frame(Component1 = component1_scores, Response = response_var),
                aes(x = Component1, y = Response)) +
  geom_point(size = 2.5, alpha = 0.7) +
  geom_smooth(method = "lm", color = "steelblue", fill = "black", alpha = 0.3) +
  annotate("text", 
           x = Inf, y = Inf, 
           label = annotation_text,
           hjust = 1.3, vjust = 1.3,
           size = 4, 
           fontface = "bold",
           color = "black") +
  labs(
    x = paste0("PLSR component 1 (", round(var_explained, 1), "%)"),
    y = "Recruitment Deviations",
    title = "Southern Region"
  ) +
  theme_classic() +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )



# ========== FIGURE C: VIP PLOT ==========

fig_c_south <- ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "",
       x = "Predictor",
       y = "VIP Score") +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )


# ========== COMBINE ALL THREE FIGURES ==========
south_AVG_PSLR <- fig_a_south + fig_b_south + fig_c_south + 
  plot_layout(ncol = 3)
south_AVG_PSLR

# ========== SAVE ==========
ggsave("south_feb_aug_pslr.png", width = 15, height = 5, dpi = 300)

```

## Putting all regional March average PLSR together 
```{r}
combined_plot <- fig_a_all + fig_b_all + fig_c_all + fig_a_north + fig_b_north + fig_c_north + fig_a_mid + fig_b_mid + fig_c_mid + fig_a_south + fig_b_south + fig_c_south +
  plot_layout(ncol = 3) 
combined_plot

combined_plot <- (fig_b_all + fig_c_all) / (fig_b_north + fig_c_north) / (fig_b_mid + fig_c_mid) / (fig_b_south + fig_c_south)
combined_plot
ggsave("combined_pslr_spatially_separated_march_only.png", width = 15, height = 10, dpi = 300)
```


# PSLR MASSIVE COMBO OF SPATIALLY SEP
```{r}
combined_plot <-  fig_b_all + fig_c_all +fig_b_north + fig_c_north + fig_b_mid + fig_c_mid +  fig_b_south + fig_c_south +
  plot_layout(ncol = 4) 
combined_plot
ggsave("combined_pslr_spatially_separated_YEARLY_AVG.png", width = 15, height = 10, dpi = 300)

```

# PSLR - NOT spatially separated march
```{r}
# combined 
ROMS_CUTI_environmental_combined_average_mar_only <- ROMS_CUTI_environmental_combined_all_yr %>% 
  filter(region == 'all') %>% 
  filter(Month %in% c("Mar"))

combined_monthly_indices_NOT_SPATIAL <- combined_monthly_indices_NOT_SPATIAL %>% 
  filter(Month %in% c("Mar"))


all_indices <-left_join(ROMS_CUTI_environmental_combined_average_mar_only,combined_monthly_indices_NOT_SPATIAL, by = "Year")

# combined 
df_gopher_mar <-left_join(all_indices,goph_recruit, by = "Year") 

df_gopher_mar <- df_gopher_mar %>% 
  select(dev, mean_pdo, CUTI, mean_sl,pH_avg, DO_avg, Temperature_avg, Chla_avg) %>% 
  rename(deviation = dev, 
         PDO = mean_pdo,
         "Sea level height" = mean_sl, 
         pH = pH_avg, 
         DO = DO_avg, 
         Temperature = Temperature_avg, 
         "Primary Production" = Chla_avg)

# Define X and Y together and filter complete cases
X_raw <- df_gopher_mar %>% 
  select(PDO, CUTI,  "Sea level height" ,pH, DO, Temperature, "Primary Production")

# Combine into one frame with response
data_complete <- cbind(dev = df_gopher_mar$dev, X_raw) %>% 
  as.data.frame() %>% 
  na.omit()  # remove rows with any NA

# Now separate into X and Y
Y <- data_complete$dev
X <- as.matrix(data_complete %>% select(-dev))

plsr_march <- plsr(dev ~ ., data = data_complete, scale = TRUE, validation = "LOO")
pls_scores <- scores(plsr_march)

df_pls <- data.frame(
  dev = Y,
  Comp1 = pls_scores[, 1],
  Comp2 = pls_scores[, 2]
)

# Summary of model
summary(plsr_march)

# Root Mean Squared Error of Prediction
RMSEP(plsr_march)

# Choose number of components based on RMSEP or % variance explained
plot(RMSEP(plsr_march), legendpos = "topright")

# Variance explained
explvar(plsr_march)  # % of variance explained in X by each component

# Component loadings: how original vars contribute to latent variables
loadings(plsr_march)

# Scores: the new coordinate representation of observations
pls_scores <- scores(plsr_march)

# Biplot: visualize scores and loadings
biplot(plsr_march, comps = 1:2)

# Fit a linear model using first 2 PLS components
lm_pls <- lm(dev ~ Comp1 + Comp2, data = df_pls)
summary(lm_pls)

# check residuals 
simulated_res <- simulateResiduals(fittedModel = lm_pls)
plot(simulated_res) #these look good

selectNcomp(plsr_march, method = "onesigma")

lm_pls_1comp <- lm(dev ~ Comp1, data = df_pls)
summary(lm_pls_1comp)

plot(RMSEP(plsr_march), legendpos = "topright")

# 1-component model is optimal, so we use opt.comp = 1
vip_scores <- VIP(plsr_march, opt.comp = 1)

# Turn into data frame properly
vip_df <- data.frame(
  Variable = names(vip_scores),
  VIP = vip_scores
)

ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = .8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "Variable Importance in Projection (VIP)",
       x = "Predictor",
       y = "VIP Score")
```

### table of correlations and weights
```{r}
# Choose which component to analyze 
comp_num <- 1

# 1. WEIGHT² - Variable importance/contribution to the component
weights_raw <- loading.weights(plsr_march)[, comp_num]
weights_squared <- weights_raw^2

# 2. CORRELATION - Between each predictor and the response variable
# Get the names of predictors used in the PLS model
predictor_names <- colnames(X)

# Use same predictors from the original full dataset for correlation
X_original <- plsr_march$model %>% select(all_of(predictor_names))
Y_original <- plsr_march$model$dev  # <-- Fixed line

# Ensure there are no NAs in either X_original or Y_original
complete_rows <- complete.cases(X_original, Y_original)
X_original <- X_original[complete_rows, ]
Y_original <- Y_original[complete_rows]

# Calculate correlations
correlations <- cor(X_original, Y_original)

# 3. LOADING - Direction and magnitude
loadings_values <- loadings(plsr_march)[, comp_num]

# Create summary table
pls_summary_table <- data.frame(
  Predictor = predictor_names,
  Weight_squared = round(weights_squared, 3),
  Correlation = round(correlations, 3),
  Loading_value = round(loadings_values, 3),
  Loading_direction = ifelse(loadings_values > 0, "+", "-")
)

# View the table
print(pls_summary_table)
```




### figure for plsr
```{r}
library(ggplot2)
library(gridExtra)
library(grid)

# Extract predictor names from X
predictor_names <- colnames(X)

# ========== FIGURE A: PLS BIPLOT ==========

loadings_data <- loadings(plsr_march)[, 1:2]
loadings_df <- data.frame(
  Variable = rownames(loadings_data),
  Component1 = loadings_data[, 1],
  Component2 = loadings_data[, 2]
)

fig_a_march <- ggplot(loadings_df, aes(x = Component1, y = Component2)) +
  geom_path(data = data.frame(
    x = cos(seq(0, 2 * pi, length.out = 100)),
    y = sin(seq(0, 2 * pi, length.out = 100))
  ), aes(x = x, y = y), color = "black", linewidth = 1) +

  # Arrows and labels
  geom_segment(aes(x = 0, y = 0, xend = Component1, yend = Component2),
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "steelblue", linewidth = 1.2) +
  geom_text(aes(label = Variable), 
            color = "steelblue", size = 4, fontface = "bold",
            nudge_x = ifelse(loadings_df$Component1 > 0, 0.05, -0.05),
            nudge_y = ifelse(loadings_df$Component2 > 0, 0.05, -0.05)) +
  
  # Optional: Response direction (illustrative only)
  # You can calculate actual correlation direction if desired
  geom_segment(aes(x = 0, y = 0, xend = 0.6, yend = 0.4), 
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "indianred", linewidth = 1.5) +
  geom_text(aes(x = 0.68, y = 0.45, label = "Recruitment"), 
             color = "indianred", size = 4, fontface = "bold") +
  
  xlim(-1.1, 1.1) + ylim(-1.1, 1.1) +
  labs(x = "Component 1", y = "Component 2", title = "March Only") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  coord_fixed()


# ========== FIGURE B: COMPONENT 1 vs RESPONSE ==========

# Ensure response is matched to filtered data
component1_scores <- scores(plsr_march)[, 1]
response_var <- Y  # this Y comes from the filtered, complete-case data

# Compute R² and p-value
var_explained <- explvar(plsr_march)[1]
lm_comp1 <- lm(response_var ~ component1_scores)
lm_summary <- summary(lm_comp1)
p_value <- lm_summary$coefficients[2, 4]
r_squared <- lm_summary$r.squared

# Format p-value
p_text <- if (p_value < 0.001) {
  "p < 0.001"
} else if (p_value < 0.01) {
  paste0("p = ", format(round(p_value, 3), nsmall = 3))
} else {
  paste0("p = ", format(round(p_value, 2), nsmall = 2))
}

annotation_text <- paste0("R² = ", format(round(r_squared, 3), nsmall = 3), "\n", p_text)

fig_b_march <- ggplot(data.frame(Component1 = component1_scores, Response = response_var),
                aes(x = Component1, y = Response)) +
  geom_point(size = 2.5, alpha = 0.7) +
  geom_smooth(method = "lm", color = "steelblue", fill = "black", alpha = 0.3) +
  annotate("text", 
           x = Inf, y = Inf, 
           label = annotation_text,
           hjust = 1.3, vjust = 1.3,
           size = 4, 
           fontface = "bold",
           color = "black") +
  labs(
    x = paste0("PLSR component 1 (", round(var_explained, 1), "%)"),
    y = "Recruitment Deviations",
    title = ""
  ) +
  theme_classic() +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )



# ========== FIGURE C: VIP PLOT ==========

fig_c_march <- ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "",
       x = "Predictor",
       y = "VIP Score") +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )


# ========== COMBINE ALL THREE FIGURES ==========
combined_plot <- fig_a_march + fig_b_march + fig_c_march + 
  plot_layout(ncol = 3)
combined_plot
# ========== SAVE ==========
#ggsave("march_pslr.png", width = 15, height = 5, dpi = 300)



```

#### pslr figure for defense
```{r}
fig_a <- ggplot(loadings_df, aes(x = Component1, y = Component2)) +
  geom_path(data = data.frame(
    x = cos(seq(0, 2 * pi, length.out = 100)),
    y = sin(seq(0, 2 * pi, length.out = 100))
  ), aes(x = x, y = y), color = "black", linewidth = 1) +

  # Arrows and labels
  geom_segment(aes(x = 0, y = 0, xend = Component1, yend = Component2),
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "steelblue", linewidth = 1.2) +
  geom_text(aes(label = Variable), 
            color = "steelblue", size = 4, fontface = "bold",
            nudge_x = ifelse(loadings_df$Component1 > 0, 0.05, -0.05),
            nudge_y = ifelse(loadings_df$Component2 > 0, 0.05, -0.05)) +
  
  # Optional: Response direction (illustrative only)
  # You can calculate actual correlation direction if desired
  geom_segment(aes(x = 0, y = 0, xend = 0.6, yend = 0.4), 
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "indianred", linewidth = 1.5) +
  geom_text(aes(x = 0.68, y = 0.45, label = "Recruitment"), 
             color = "indianred", size = 4, fontface = "bold") +
  
  xlim(-1.1, 1.1) + ylim(-1.1, 1.1) +
  labs(x = "Component 1", y = "Component 2", title = "") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  coord_fixed() + 
   theme(
    panel.background = element_rect(fill='transparent'), #transparent panel bg
    plot.background = element_rect(fill='transparent', color=NA), #transparent plot bg
    panel.grid.major = element_blank(), #remove major gridlines
    panel.grid.minor = element_blank(), #remove minor gridlines
    legend.background = element_rect(fill='transparent'), #transparent legend bg
    legend.box.background = element_rect(fill='transparent') #transparent legend panel
  )

fig_a


fig_b <- fig_b <- ggplot(data.frame(Component1 = component1_scores, Response = response_var),
                aes(x = Component1, y = Response)) +
  geom_point(size = 2.5, alpha = 0.7) +
  geom_smooth(method = "lm", color = "steelblue", fill = "black", alpha = 0.3) +
  annotate("text", 
           x = Inf, y = Inf, 
           label = annotation_text,
           hjust = 1.3, vjust = 1.3,
           size = 4, 
           fontface = "bold",
           color = "black") +
  labs(
    x = paste0("PLSR component 1 (", round(var_explained, 1), "%)"),
    y = "Recruitment Deviations",
    title = ""
  ) +
  theme_classic() +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
   theme(
    panel.background = element_rect(fill='transparent'), #transparent panel bg
    plot.background = element_rect(fill='transparent', color=NA), #transparent plot bg
    panel.grid.major = element_blank(), #remove major gridlines
    panel.grid.minor = element_blank(), #remove minor gridlines
    legend.background = element_rect(fill='transparent'), #transparent legend bg
    legend.box.background = element_rect(fill='transparent') #transparent legend panel
  )

fig_b

ggsave("march_lineareg_pc.png", fig_b, bg = "transparent", width = 5.5, height = 4.5, dpi = 300)

fig_c <- ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "",
       x = "Predictor",
       y = "VIP Score") +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )+
   theme(
    panel.background = element_rect(fill='transparent'), #transparent panel bg
    plot.background = element_rect(fill='transparent', color=NA), #transparent plot bg
    panel.grid.major = element_blank(), #remove major gridlines
    panel.grid.minor = element_blank(), #remove minor gridlines
    legend.background = element_rect(fill='transparent'), #transparent legend bg
    legend.box.background = element_rect(fill='transparent') #transparent legend panel
  )

ggsave("march_VIP.png", fig_c, bg = "transparent", width = 5.5, height = 4.5, dpi = 300)
```


# PSLR - NOT spatially separated Whole year averagig
```{r}
# combined 
ROMS_CUTI_environmental_combined_average <- ROMS_CUTI_environmental_combined_all_yr %>% 
  filter(region == 'all') %>% 
 # filter(Month %in% c("Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug")) %>% 
  group_by(Year) %>%
  summarise(across(
    c(DO_avg, pH_avg, Temperature_avg, Chla_avg, Vwind_avg,CUTI),
    ~ mean(.x, na.rm = TRUE),
    .names = "mean_{.col}"
  )) %>%
  ungroup()

combined_monthly_indices_NOT_SPATIAL_averaging <- combined_monthly_indices_NOT_SPATIAL %>% 
 # filter(Month %in% c("Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug")) %>% 
  group_by(Year) %>%
  summarise(across(
    c(mean_pdo, npgo_avg, mean_sl, oni_avg),
    ~ mean(.x, na.rm = TRUE),
    .names = "mean_{.col}"
  )) %>%
  ungroup()


all_indices <-left_join(ROMS_CUTI_environmental_combined_average,combined_monthly_indices_NOT_SPATIAL_averaging, by = "Year")

# combined 
df_gopher_avg <-left_join(all_indices,goph_recruit, by = "Year") 

df_gopher_avg <- df_gopher_avg %>% 
  select(dev, mean_mean_pdo, mean_CUTI, mean_mean_sl,mean_pH_avg, mean_DO_avg, mean_Temperature_avg, mean_Chla_avg) %>% 
  rename(deviation = dev, 
         CUTI = mean_CUTI,
         PDO = mean_mean_pdo,
         "Sea level height" = mean_mean_sl, 
         pH = mean_pH_avg, 
         DO = mean_DO_avg, 
         Temperature = mean_Temperature_avg, 
         "Primary Production" = mean_Chla_avg)

# Define X and Y together and filter complete cases
X_raw <- df_gopher_avg %>% 
  select(PDO, CUTI,  "Sea level height" ,pH, DO, Temperature, "Primary Production")

# Combine into one frame with response
data_complete <- cbind(dev = df_gopher_avg$deviation, X_raw) %>% 
  as.data.frame() %>% 
  na.omit()  # remove rows with any NA

# Now separate into X and Y
Y <- data_complete$dev
X <- as.matrix(data_complete %>% select(-dev))

plsr_model <- plsr(Y ~ X, scale = TRUE, validation = "LOO")
pls_scores <- scores(plsr_model)

df_pls <- data.frame(
  dev = Y,
  Comp1 = pls_scores[, 1],
  Comp2 = pls_scores[, 2]
)

# Summary of model
summary(plsr_model)

# Root Mean Squared Error of Prediction
RMSEP(plsr_model)

# Choose number of components based on RMSEP or % variance explained
plot(RMSEP(plsr_model), legendpos = "topright")

# Variance explained
explvar(plsr_model)  # % of variance explained in X by each component

# Component loadings: how original vars contribute to latent variables
loadings(plsr_model)

# Scores: the new coordinate representation of observations
pls_scores <- scores(plsr_model)

# Biplot: visualize scores and loadings
biplot(plsr_model, comps = 1:2)

# Fit a linear model using first 2 PLS components
lm_pls <- lm(dev ~ Comp1 + Comp2, data = df_pls)
summary(lm_pls)

# check residuals 
simulated_res <- simulateResiduals(fittedModel = lm_pls)
plot(simulated_res) #these look good

selectNcomp(plsr_model, method = "onesigma")

lm_pls_1comp <- lm(dev ~ Comp1, data = df_pls)
summary(lm_pls_1comp)

plot(RMSEP(plsr_model), legendpos = "topright")

# 1-component model is optimal, so we use opt.comp = 1
vip_scores <- VIP(plsr_model, opt.comp = 1)

# Turn into data frame properly
vip_df <- data.frame(
  Variable = names(vip_scores),
  VIP = vip_scores
)

ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = .8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "Variable Importance in Projection (VIP)",
       x = "Predictor",
       y = "VIP Score")
```

### table of correlations and weights
```{r}
# Choose which component to analyze 
comp_num <- 1

# 1. WEIGHT² - Variable importance/contribution to the component
weights_raw <- loading.weights(plsr_model)[, comp_num]
weights_squared <- weights_raw^2

# 2. CORRELATION - Between each predictor and the response variable
# Get the names of predictors used in the PLS model
predictor_names <- colnames(X)

# Use same predictors from the original full dataset for correlation
X_original <- pslr_mar %>% select(all_of(predictor_names))
Y_original <- pslr_mar$dev

# Ensure there are no NAs in either X_original or Y_original
complete_rows <- complete.cases(X_original, Y_original)
X_original <- X_original[complete_rows, ]
Y_original <- Y_original[complete_rows]

# Calculate correlations
correlations <- cor(X_original, Y_original)

# 3. LOADING - Direction and magnitude
loadings_values <- loadings(plsr_model)[, comp_num]

# Create summary table
pls_summary_table <- data.frame(
  Predictor = predictor_names,
  Weight_squared = round(weights_squared, 3),
  Correlation = round(correlations, 3),
  Loading_value = round(loadings_values, 3),
  Loading_direction = ifelse(loadings_values > 0, "+", "-")
)

# View the table
print(pls_summary_table)

```


### figure for plsr
```{r}
# Extract predictor names from X
predictor_names <- colnames(X)

# ========== FIGURE A: PLS BIPLOT ==========

loadings_data <- loadings(plsr_model)[, 1:2]
loadings_df <- data.frame(
  Variable = rownames(loadings_data),
  Component1 = loadings_data[, 1],
  Component2 = loadings_data[, 2]
)

fig_a_year <- ggplot(loadings_df, aes(x = Component1, y = Component2)) +
  # Unit circle
  geom_path(data = data.frame(
    x = cos(seq(0, 2 * pi, length.out = 100)),
    y = sin(seq(0, 2 * pi, length.out = 100))
  ), aes(x = x, y = y), color = "black", linewidth = 1) +

  # Arrows and labels
  geom_segment(aes(x = 0, y = 0, xend = Component1, yend = Component2),
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "steelblue", linewidth = 1.2) +
  geom_text(aes(label = Variable), 
            color = "steelblue", size = 4, fontface = "bold",
            nudge_x = ifelse(loadings_df$Component1 > 0, 0.05, -0.05),
            nudge_y = ifelse(loadings_df$Component2 > 0, 0.05, -0.05)) +
  
  # Optional: Response direction (illustrative only)
  # You can calculate actual correlation direction if desired
  geom_segment(aes(x = 0, y = 0, xend = 0.6, yend = 0.4), 
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "indianred", linewidth = 1.5) +
  geom_text(aes(x = 0.68, y = 0.45, label = "Recruitment"), 
             color = "indianred", size = 4, fontface = "bold") +
  
  xlim(-1.1, 1.1) + ylim(-1.1, 1.1) +
  labs(x = "Component 1", y = "Component 2", title = "Yearly Averaging") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  coord_fixed()
# ========== FIGURE B: COMPONENT 1 vs RESPONSE ==========

# Ensure response is matched to filtered data
component1_scores <- scores(plsr_model)[, 1]
response_var <- Y  # this Y comes from the filtered, complete-case data

# Compute R² and p-value
var_explained <- explvar(plsr_model)[1]
lm_comp1 <- lm(response_var ~ component1_scores)
lm_summary <- summary(lm_comp1)
p_value <- lm_summary$coefficients[2, 4]
r_squared <- lm_summary$r.squared

# Format p-value
p_text <- if (p_value < 0.001) {
  "p < 0.001"
} else if (p_value < 0.01) {
  paste0("p = ", format(round(p_value, 3), nsmall = 3))
} else {
  paste0("p = ", format(round(p_value, 2), nsmall = 2))
}

annotation_text <- paste0("R² = ", format(round(r_squared, 3), nsmall = 3), "\n", p_text)

fig_b_year <- ggplot(data.frame(Component1 = component1_scores, Response = response_var),
                aes(x = Component1, y = Response)) +
  geom_point(size = 2.5, alpha = 0.7) +
  geom_smooth(method = "lm", color = "steelblue", fill = "black", alpha = 0.3) +
  annotate("text", 
           x = Inf, y = Inf, 
           label = annotation_text,
           hjust = 1.3, vjust = 1.3,
           size = 4, 
           fontface = "bold",
           color = "black") +
  labs(
    x = paste0("PLSR component 1 (", round(var_explained, 1), "%)"),
    y = "Recruitment Deviations",
    title = ""
  ) +
  theme_classic() +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )


# ========== FIGURE C: VIP PLOT ==========

fig_c_year <- ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "",
       x = "Predictor",
       y = "VIP Score") +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )


# ========== COMBINE ALL THREE FIGURES ==========
combined_plot <- fig_a_year + fig_b_year + fig_c_year + 
  plot_layout(ncol = 3)
combined_plot


```

### pslr figure for defense
```{r}
fig_a_1 <- ggplot(loadings_df, aes(x = Component1, y = Component2)) +
  geom_path(data = data.frame(
    x = cos(seq(0, 2 * pi, length.out = 100)),
    y = sin(seq(0, 2 * pi, length.out = 100))
  ), aes(x = x, y = y), color = "black", linewidth = 1) +

  # Arrows and labels
  geom_segment(aes(x = 0, y = 0, xend = Component1, yend = Component2),
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "steelblue", linewidth = 1.2) +
  geom_text(aes(label = Variable), 
            color = "steelblue", size = 4, fontface = "bold",
            nudge_x = ifelse(loadings_df$Component1 > 0, 0.05, -0.05),
            nudge_y = ifelse(loadings_df$Component2 > 0, 0.05, -0.05)) +
  
  # Optional: Response direction (illustrative only)
  # You can calculate actual correlation direction if desired
  geom_segment(aes(x = 0, y = 0, xend = 0.6, yend = 0.4), 
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "indianred", linewidth = 1.5) +
  geom_text(aes(x = 0.68, y = 0.45, label = "Recruitment"), 
             color = "indianred", size = 4, fontface = "bold") +
  
  xlim(-1.1, 1.1) + ylim(-1.1, 1.1) +
  labs(x = "Component 1", y = "Component 2", title = "") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  coord_fixed() + 
   theme(
    panel.background = element_rect(fill='transparent'), #transparent panel bg
    plot.background = element_rect(fill='transparent', color=NA), #transparent plot bg
    panel.grid.major = element_blank(), #remove major gridlines
    panel.grid.minor = element_blank(), #remove minor gridlines
    legend.background = element_rect(fill='transparent'), #transparent legend bg
    legend.box.background = element_rect(fill='transparent') #transparent legend panel
  )

fig_a_1

ggsave("avg_radarplot_pc.png", fig_a_1, bg = "transparent", width = 5.5, height = 4.5, dpi = 300)

fig_b_1 <- fig_b <- ggplot(data.frame(Component1 = component1_scores, Response = response_var),
                aes(x = Component1, y = Response)) +
  geom_point(size = 2.5, alpha = 0.7) +
  geom_smooth(method = "lm", color = "steelblue", fill = "black", alpha = 0.3) +
  annotate("text", 
           x = Inf, y = Inf, 
           label = annotation_text,
           hjust = 1.3, vjust = 1.3,
           size = 4, 
           fontface = "bold",
           color = "black") +
  labs(
    x = paste0("PLSR component 1 (", round(var_explained, 1), "%)"),
    y = "Recruitment Deviations",
    title = ""
  ) +
  theme_classic() +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
   theme(
    panel.background = element_rect(fill='transparent'), #transparent panel bg
    plot.background = element_rect(fill='transparent', color=NA), #transparent plot bg
    panel.grid.major = element_blank(), #remove major gridlines
    panel.grid.minor = element_blank(), #remove minor gridlines
    legend.background = element_rect(fill='transparent'), #transparent legend bg
    legend.box.background = element_rect(fill='transparent') #transparent legend panel
  )

fig_b_1

ggsave("avg_lineareg_pc.png", fig_b_1, bg = "transparent", width = 5.5, height = 4.5, dpi = 300)

fig_c_1 <- ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "",
       x = "Predictor",
       y = "VIP Score") +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )+
   theme(
    panel.background = element_rect(fill='transparent'), #transparent panel bg
    plot.background = element_rect(fill='transparent', color=NA), #transparent plot bg
    panel.grid.major = element_blank(), #remove major gridlines
    panel.grid.minor = element_blank(), #remove minor gridlines
    legend.background = element_rect(fill='transparent'), #transparent legend bg
    legend.box.background = element_rect(fill='transparent') #transparent legend panel
  )

ggsave("avg_VIP.png", fig_c_1, bg = "transparent", width = 5.5, height = 4.5, dpi = 300)
```



# PSLR - NOT spatially separated Feb to Sept
```{r}
# combined 
ROMS_CUTI_environmental_combined_average <- ROMS_CUTI_environmental_combined_all_yr %>% 
  filter(region == 'all') %>% 
  filter(Month %in% c("Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep")) %>% 
  group_by(Year) %>%
  summarise(across(
    c(DO_avg, pH_avg, Temperature_avg, Chla_avg, Vwind_avg,CUTI),
    ~ mean(.x, na.rm = TRUE),
    .names = "mean_{.col}"
  )) %>%
  ungroup()

combined_monthly_indices_NOT_SPATIAL_averaging <- combined_monthly_indices_NOT_SPATIAL %>% 
  filter(Month %in% c("Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep")) %>% 
  group_by(Year) %>%
  summarise(across(
    c(mean_pdo, npgo_avg, mean_sl, oni_avg),
    ~ mean(.x, na.rm = TRUE),
    .names = "mean_{.col}"
  )) %>%
  ungroup()


all_indices <-left_join(ROMS_CUTI_environmental_combined_average,combined_monthly_indices_NOT_SPATIAL_averaging, by = "Year")

# combined 
df_gopher_avg <-left_join(all_indices,goph_recruit, by = "Year") 

df_gopher_avg <- df_gopher_avg %>% 
  select(dev, mean_mean_pdo, mean_CUTI, mean_mean_sl,mean_pH_avg, mean_DO_avg, mean_Temperature_avg, mean_Chla_avg) %>% 
  rename(deviation = dev, 
         CUTI = mean_CUTI,
         PDO = mean_mean_pdo,
         "Sea level height" = mean_mean_sl, 
         pH = mean_pH_avg, 
         DO = mean_DO_avg, 
         Temperature = mean_Temperature_avg, 
         "Primary Production" = mean_Chla_avg)

# Define X and Y together and filter complete cases
X_raw <- df_gopher_avg %>% 
  select(PDO, CUTI,  "Sea level height" ,pH, DO, Temperature, "Primary Production")

# Combine into one frame with response
data_complete <- cbind(dev = df_gopher_avg$deviation, X_raw) %>% 
  as.data.frame() %>% 
  na.omit()  # remove rows with any NA

# Now separate into X and Y
Y <- data_complete$dev
X <- as.matrix(data_complete %>% select(-dev))

plsr_model <- plsr(Y ~ X, scale = TRUE, validation = "LOO")
pls_scores <- scores(plsr_model)

df_pls <- data.frame(
  dev = Y,
  Comp1 = pls_scores[, 1],
  Comp2 = pls_scores[, 2]
)

# Summary of model
summary(plsr_model)

# Root Mean Squared Error of Prediction
RMSEP(plsr_model)

# Choose number of components based on RMSEP or % variance explained
plot(RMSEP(plsr_model), legendpos = "topright")

# Variance explained
explvar(plsr_model)  # % of variance explained in X by each component

# Component loadings: how original vars contribute to latent variables
loadings(plsr_model)

# Scores: the new coordinate representation of observations
pls_scores <- scores(plsr_model)

# Biplot: visualize scores and loadings
biplot(plsr_model, comps = 1:2)

# Fit a linear model using first 2 PLS components
lm_pls <- lm(dev ~ Comp1 + Comp2, data = df_pls)
summary(lm_pls)

# check residuals 
simulated_res <- simulateResiduals(fittedModel = lm_pls)
plot(simulated_res) #these look good

selectNcomp(plsr_model, method = "onesigma")

lm_pls_1comp <- lm(dev ~ Comp1, data = df_pls)
summary(lm_pls_1comp)

plot(RMSEP(plsr_model), legendpos = "topright")

# 1-component model is optimal, so we use opt.comp = 1
vip_scores <- VIP(plsr_model, opt.comp = 1)

# Turn into data frame properly
vip_df <- data.frame(
  Variable = names(vip_scores),
  VIP = vip_scores
)

ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = .8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "Variable Importance in Projection (VIP)",
       x = "Predictor",
       y = "VIP Score")
```

### table of correlations and weights
```{r}
# Choose which component to analyze 
comp_num <- 1

# 1. WEIGHT² - Variable importance/contribution to the component
weights_raw <- loading.weights(plsr_model)[, comp_num]
weights_squared <- weights_raw^2

# 2. CORRELATION - Between each predictor and the response variable
# Get the names of predictors used in the PLS model
predictor_names <- colnames(X)

# Use same predictors from the original full dataset for correlation
X_original <- pslr_mar %>% select(all_of(predictor_names))
Y_original <- pslr_mar$dev

# Ensure there are no NAs in either X_original or Y_original
complete_rows <- complete.cases(X_original, Y_original)
X_original <- X_original[complete_rows, ]
Y_original <- Y_original[complete_rows]

# Calculate correlations
correlations <- cor(X_original, Y_original)

# 3. LOADING - Direction and magnitude
loadings_values <- loadings(plsr_model)[, comp_num]

# Create summary table
pls_summary_table <- data.frame(
  Predictor = predictor_names,
  Weight_squared = round(weights_squared, 3),
  Correlation = round(correlations, 3),
  Loading_value = round(loadings_values, 3),
  Loading_direction = ifelse(loadings_values > 0, "+", "-")
)

# View the table
print(pls_summary_table)

```


### figure for plsr
```{r}
# Extract predictor names from X
predictor_names <- colnames(X)

# ========== FIGURE A: PLS BIPLOT ==========

loadings_data <- loadings(plsr_model)[, 1:2]
loadings_df <- data.frame(
  Variable = rownames(loadings_data),
  Component1 = loadings_data[, 1],
  Component2 = loadings_data[, 2]
)

fig_a_repro <- ggplot(loadings_df, aes(x = Component1, y = Component2)) +
  # Unit circle
  geom_path(data = data.frame(
    x = cos(seq(0, 2 * pi, length.out = 100)),
    y = sin(seq(0, 2 * pi, length.out = 100))
  ), aes(x = x, y = y), color = "black", linewidth = 1) +

  # Arrows and labels
  geom_segment(aes(x = 0, y = 0, xend = Component1, yend = Component2),
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "steelblue", linewidth = 1.2) +
  geom_text(aes(label = Variable), 
            color = "steelblue", size = 4, fontface = "bold",
            nudge_x = ifelse(loadings_df$Component1 > 0, 0.05, -0.05),
            nudge_y = ifelse(loadings_df$Component2 > 0, 0.05, -0.05)) +
  
  # Optional: Response direction (illustrative only)
  # You can calculate actual correlation direction if desired
  geom_segment(aes(x = 0, y = 0, xend = 0.6, yend = 0.4), 
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "indianred", linewidth = 1.5) +
  geom_text(aes(x = 0.68, y = 0.45, label = "Recruitment"), 
             color = "indianred", size = 4, fontface = "bold") +
  
  xlim(-1.1, 1.1) + ylim(-1.1, 1.1) +
  labs(x = "Component 1", y = "Component 2", title = "Reproductive Season Average") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  coord_fixed()
# ========== FIGURE B: COMPONENT 1 vs RESPONSE ==========

# Ensure response is matched to filtered data
component1_scores <- scores(plsr_model)[, 1]
response_var <- Y  # this Y comes from the filtered, complete-case data

# Compute R² and p-value
var_explained <- explvar(plsr_model)[1]
lm_comp1 <- lm(response_var ~ component1_scores)
lm_summary <- summary(lm_comp1)
p_value <- lm_summary$coefficients[2, 4]
r_squared <- lm_summary$r.squared

# Format p-value
p_text <- if (p_value < 0.001) {
  "p < 0.001"
} else if (p_value < 0.01) {
  paste0("p = ", format(round(p_value, 3), nsmall = 3))
} else {
  paste0("p = ", format(round(p_value, 2), nsmall = 2))
}

annotation_text <- paste0("R² = ", format(round(r_squared, 3), nsmall = 3), "\n", p_text)

fig_b_repro <- ggplot(data.frame(Component1 = component1_scores, Response = response_var),
                aes(x = Component1, y = Response)) +
  geom_point(size = 2.5, alpha = 0.7) +
  geom_smooth(method = "lm", color = "steelblue", fill = "black", alpha = 0.3) +
  annotate("text", 
           x = Inf, y = Inf, 
           label = annotation_text,
           hjust = 1.3, vjust = 1.3,
           size = 4, 
           fontface = "bold",
           color = "black") +
  labs(
    x = paste0("PLSR component 1 (", round(var_explained, 1), "%)"),
    y = "Recruitment Deviations",
    title = ""
  ) +
  theme_classic() +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )


# ========== FIGURE C: VIP PLOT ==========

fig_c_repro <- ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "",
       x = "Predictor",
       y = "VIP Score") +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )


# ========== COMBINE ALL THREE FIGURES ==========
combined_plot <- fig_a_repro + fig_b_repro + fig_c_repro + 
  plot_layout(ncol = 3)
combined_plot


```

### pslr figure for defense
```{r}
fig_a_1 <- ggplot(loadings_df, aes(x = Component1, y = Component2)) +
  geom_path(data = data.frame(
    x = cos(seq(0, 2 * pi, length.out = 100)),
    y = sin(seq(0, 2 * pi, length.out = 100))
  ), aes(x = x, y = y), color = "black", linewidth = 1) +

  # Arrows and labels
  geom_segment(aes(x = 0, y = 0, xend = Component1, yend = Component2),
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "steelblue", linewidth = 1.2) +
  geom_text(aes(label = Variable), 
            color = "steelblue", size = 4, fontface = "bold",
            nudge_x = ifelse(loadings_df$Component1 > 0, 0.05, -0.05),
            nudge_y = ifelse(loadings_df$Component2 > 0, 0.05, -0.05)) +
  
  # Optional: Response direction (illustrative only)
  # You can calculate actual correlation direction if desired
  geom_segment(aes(x = 0, y = 0, xend = 0.6, yend = 0.4), 
               arrow = arrow(length = unit(0.3, "cm")), 
               color = "indianred", linewidth = 1.5) +
  geom_text(aes(x = 0.68, y = 0.45, label = "Recruitment"), 
             color = "indianred", size = 4, fontface = "bold") +
  
  xlim(-1.1, 1.1) + ylim(-1.1, 1.1) +
  labs(x = "Component 1", y = "Component 2", title = "") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  coord_fixed() + 
   theme(
    panel.background = element_rect(fill='transparent'), #transparent panel bg
    plot.background = element_rect(fill='transparent', color=NA), #transparent plot bg
    panel.grid.major = element_blank(), #remove major gridlines
    panel.grid.minor = element_blank(), #remove minor gridlines
    legend.background = element_rect(fill='transparent'), #transparent legend bg
    legend.box.background = element_rect(fill='transparent') #transparent legend panel
  )

fig_a_1

ggsave("avg_radarplot_pc.png", fig_a_1, bg = "transparent", width = 5.5, height = 4.5, dpi = 300)

fig_b_1 <- fig_b <- ggplot(data.frame(Component1 = component1_scores, Response = response_var),
                aes(x = Component1, y = Response)) +
  geom_point(size = 2.5, alpha = 0.7) +
  geom_smooth(method = "lm", color = "steelblue", fill = "black", alpha = 0.3) +
  annotate("text", 
           x = Inf, y = Inf, 
           label = annotation_text,
           hjust = 1.3, vjust = 1.3,
           size = 4, 
           fontface = "bold",
           color = "black") +
  labs(
    x = paste0("PLSR component 1 (", round(var_explained, 1), "%)"),
    y = "Recruitment Deviations",
    title = ""
  ) +
  theme_classic() +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
   theme(
    panel.background = element_rect(fill='transparent'), #transparent panel bg
    plot.background = element_rect(fill='transparent', color=NA), #transparent plot bg
    panel.grid.major = element_blank(), #remove major gridlines
    panel.grid.minor = element_blank(), #remove minor gridlines
    legend.background = element_rect(fill='transparent'), #transparent legend bg
    legend.box.background = element_rect(fill='transparent') #transparent legend panel
  )

fig_b_1

ggsave("avg_lineareg_pc.png", fig_b_1, bg = "transparent", width = 5.5, height = 4.5, dpi = 300)

fig_c_1 <- ggplot(vip_df, aes(x = reorder(Variable, VIP), y = VIP)) +
  geom_col(fill = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "indianred4", size = 1) +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "indianred3", size = 1) +
  coord_flip() +
  theme_classic() +
  labs(title = "",
       x = "Predictor",
       y = "VIP Score") +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )+
   theme(
    panel.background = element_rect(fill='transparent'), #transparent panel bg
    plot.background = element_rect(fill='transparent', color=NA), #transparent plot bg
    panel.grid.major = element_blank(), #remove major gridlines
    panel.grid.minor = element_blank(), #remove minor gridlines
    legend.background = element_rect(fill='transparent'), #transparent legend bg
    legend.box.background = element_rect(fill='transparent') #transparent legend panel
  )

ggsave("avg_VIP.png", fig_c_1, bg = "transparent", width = 5.5, height = 4.5, dpi = 300)
```




# Combined PSLR Figure Non Spatial
```{r}
combined_plot <- fig_a_march + fig_b_march + fig_c_march + fig_a_year + fig_b_year + fig_c_year + fig_a_repro + fig_b_repro + fig_c_repro +
  plot_layout(ncol = 3) 
combined_plot
ggsave("combined_pslr_non_spatial.png", width = 15, height = 10, dpi = 300)
```

## getting natural lengths from SA
```{r}
#getting length bins
natlen <- goph2019$natlen

natlen1 <- natlen %>% 
  filter(natlen$`Beg/Mid` == "B") %>% 
  select(-Area,-Bio_Pattern, -Sex, -BirthSeas, -Settlement, -Platoon, -Morph, -Seas, -Time, -Era, -`Beg/Mid`)

# Convert data to long format
df_long <- natlen1 %>%
  pivot_longer(cols = `4`:`40`, names_to = "Category", values_to = "Value") %>% 
  select(Category,Yr,Value) %>% 
  filter(Yr > 1994) %>% 
  filter(Yr < 2020)

df_long <- df_long %>%
  mutate(Category = as.numeric(Category)) %>%
  arrange(Yr, Category)

# Create the bubble plot
ggplot(df_long, aes(x = Yr, y = Category, size = Value)) +
  geom_point(shape = 20, color = "black", alpha = .5) +  
  scale_size_continuous(range = c(2, 15)) +  
  scale_fill_viridis_d() +  
  labs(title = "Length Compositions", x = "Year", y = "Length (cm)", size = "Number of Fish", fill = "Beg/Mid") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),
        legend.position = "right")+
  theme_classic()


ggplot(df_long, aes(x = Yr, y = Category, fill = Value)) +
  geom_tile() +
  scale_fill_viridis_c() +  # Better color contrast
  labs(title = "Age-Length Composition Over Time",
       x = "Age or Length Category",
       y = "Time",
       fill = "Abundance") +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
#recommended work flow, define model directory
# this is the files from the pfmc website 
model_path <- "Old_stock_assessments/Copper"
copper2023 <- r4ss::SS_output(model_path, printstats = FALSE)
with.covar = T		# T: without -nohess; F: with -nohess 
parameters <- copper2023$parameters
copper_recruit <- copper2023$recruit

#filter for years
copper_recruit <-copper_recruit %>% 
  filter(Yr >= 1995, Yr <= 2017) %>% 
  rename(Year = Yr) %>% 
  mutate(Species = "copper")

# data frame with ROMS model
df_merged_copper <- left_join(copper_recruit, pc1_by_year, by = "Year") %>% 
  filter(!Year == "1998") %>% 
  select(PC1_avg, dev, Species, Year)
 
# data frame with CUTI index
df_merged_copper_cuti <- left_join(df_merged_copper, yearly_averages_lat , by = "Year")%>% 
  select(average_CUTI, dev, Species, Year, PC1_avg)

# data frame with surface level
df_merged_copper_SL <- left_join(df_merged_copper_cuti,yearly_avg_sl, by = "Year") %>% 
  select(mean_sl, dev, Species, Year, PC1_avg)

# data frame including PDO
df_merged_copper_SL_PDO <- left_join(df_merged_copper_SL,yearly_avg_pdo, by = "Year") %>% 
  select(mean_pdo,PC1_avg,mean_sl, dev, Species, Year)

# data frame with all indices
df_copper_all <-left_join(df_merged_copper_SL_PDO,yearly_avg_npgo, by = "Year") %>% 
  select(mean_pdo,PC1_avg,mean_sl, npgo_avg, dev, Species, Year)

```





# PISCO variability - 2001 to 2018
```{r}
# inserting pisco index of abundance from stock assessment 
pisco_data <- read_csv("Data/PISCO_age0_index.csv")
```

# Historical recruitment against invidual ROMS outputs 
```{r}
#join with ocean data PC
df_merged_goph_ROMS <- left_join(goph_recruit, ROMS_outputs, by = "Year") 
 # filter(!Year == 1998)
df_merged_goph_monthly <- left_join(goph_recruit, monthly_averages, by = "Year") 
df_merged_goph_monthly_wind <- left_join(goph_recruit, monthly_averages_wind_2, by = "Year") 

```


```{r}
# Ensure Month is an ordered factor
month_levels <- c("Feb", "March", "April", "May", "June", "July")
df_merged_goph_monthly$Month <- factor(df_merged_goph_monthly$Month, levels = month_levels, ordered = TRUE)
df_merged_goph_monthly_wind$Month <- factor(df_merged_goph_monthly_wind$Month, levels = month_levels, ordered = TRUE)

# Run linear models by month (e.g., DO_avg ~ dev for each month)
do_model_results <- df_merged_goph_monthly %>%
  group_by(Month) %>%
  group_modify(~ tidy(lm(dev ~ DO_avg, data = .x))) %>%
  filter(term == "DO_avg")  # Keep only slope terms
do_model_results

# Run linear models by month (e.g., DO_avg ~ dev for each month)
pH_model_results <- df_merged_goph_monthly %>%
  group_by(Month) %>%
  group_modify(~ tidy(lm(dev ~ pH_avg, data = .x))) %>%
  filter(term == "pH_avg")  # Keep only slope terms
pH_model_results

# Run linear models by month (e.g., DO_avg ~ dev for each month)
temp_model_results <- df_merged_goph_monthly %>%
  group_by(Month) %>%
  group_modify(~ tidy(lm(dev ~ Temperature_avg, data = .x))) %>%
  filter(term == "Temperature_avg")  # Keep only slope terms
temp_model_results

# Run linear models by month (e.g., DO_avg ~ dev for each month)
wind_model_results <- df_merged_goph_monthly_wind %>%
  group_by(Month) %>%
  group_modify(~ tidy(lm(dev ~ Vwind_avg, data = .x))) %>%
  filter(term == "Vwind_avg")  # Keep only slope terms
wind_model_results

# Run linear models by month (e.g., DO_avg ~ dev for each month)
chla_model_results <- df_merged_goph_monthly %>%
  group_by(Month) %>%
  group_modify(~ tidy(lm(dev ~ Chla_avg, data = .x))) %>%
  filter(term == "Chla_avg")  # Keep only slope terms
chla_model_results

```
### DO graph
```{r}
# Monthly graphs for dissolved oxygen

# 2. Function to run model and extract R² and p-value
model_stats <- df_merged_goph_monthly %>%
  group_by(Month) %>%
  summarise(
    model = list(lm(dev ~ DO_avg, data = cur_data())),
    .groups = "drop"
  ) %>%
  mutate(
    glance_out = map(model, glance),
    r_squared = map_dbl(glance_out, "r.squared"),
    p_value = map_dbl(glance_out, "p.value")
  ) %>%
  select(Month, r_squared, p_value)

# 3. Join model stats back to main data for labeling
df_plot_do <- left_join(df_merged_goph_monthly, model_stats, by = "Month")

# 1. Identify significant months
significant_months <- model_stats %>%
  filter(p_value < 0.05) %>%
  pull(Month)

# 2. Create a new column indicating if month is significant
df_plot_do <- df_plot_do %>%
  mutate(significant = Month %in% significant_months)

# 3. Plot
do <- ggplot(df_plot_do, aes(x = DO_avg, y = dev)) +
  geom_point(color = "steelblue", size = 2) +
  # Add regression lines only for significant months
  geom_smooth(
    data = df_plot_do %>% filter(significant),
    method = "lm",
    se = TRUE,
    color = "firebrick"
  ) +
  facet_wrap(~Month, ncol = 3, scales = "fixed") +
  theme_classic() +
  labs(
    title = "Dissolved Oxygen",
    x = "Dissolved Oxygen (mg/L)",
    y = "Recruitment Deviation"
  ) +
  geom_text(
    data = model_stats,
    aes(
      x = -Inf, y = Inf,
      label = paste0("R² = ", round(r_squared, 2), "\nP = ", signif(p_value, 2))
    ),
    hjust = -0.1, vjust = 1.2,
    inherit.aes = FALSE,
    size = 3.5
  )

do
```

### pH graph
```{r}
# Monthly graphs for pH
# 2. Function to run model and extract R² and p-value
model_stats <- df_merged_goph_monthly %>%
  group_by(Month) %>%
  summarise(
    model = list(lm(dev ~ pH_avg, data = cur_data())),
    .groups = "drop"
  ) %>%
  mutate(
    glance_out = map(model, glance),
    r_squared = map_dbl(glance_out, "r.squared"),
    p_value = map_dbl(glance_out, "p.value")
  ) %>%
  select(Month, r_squared, p_value)

# 3. Join model stats back to main data for labeling
df_plot_pH <- left_join(df_merged_goph_monthly, model_stats, by = "Month")

# 1. Identify significant months
significant_months <- model_stats %>%
  filter(p_value < 0.05) %>%
  pull(Month)

# 2. Create a new column indicating if month is significant
df_plot_pH <- df_plot_pH %>%
  mutate(significant = Month %in% significant_months)

# 3. Plot
pH <- ggplot(df_plot_pH, aes(x = pH_avg, y = dev)) +
  geom_point(color = "steelblue", size = 2) +
  # Add regression lines only for significant months
  geom_smooth(
    data = df_plot_pH %>% filter(significant),
    method = "lm",
    se = TRUE,
    color = "firebrick"
  ) +
  facet_wrap(~Month, ncol = 3, scales = "fixed") +
  theme_classic() +
  labs(
    title = "pH",
    x = "pH",
    y = "Recruitment Deviation"
  ) +
  geom_text(
    data = model_stats,
    aes(
      x = -Inf, y = Inf,
      label = paste0("R² = ", round(r_squared, 2), "\nP = ", signif(p_value, 2))
    ),
    hjust = -0.1, vjust = 1.2,
    inherit.aes = FALSE,
    size = 3.5
  )

pH
```
### Temp graph
```{r}
# Monthly graphs for Temperature
# 2. Function to run model and extract R² and p-value
model_stats <- df_merged_goph_monthly %>%
  group_by(Month) %>%
  summarise(
    model = list(lm(dev ~ Temperature_avg, data = cur_data())),
    .groups = "drop"
  ) %>%
  mutate(
    glance_out = map(model, glance),
    r_squared = map_dbl(glance_out, "r.squared"),
    p_value = map_dbl(glance_out, "p.value")
  ) %>%
  select(Month, r_squared, p_value)

# 3. Join model stats back to main data for labeling
df_plot_temp <- left_join(df_merged_goph_monthly, model_stats, by = "Month")

# 1. Identify significant months
significant_months <- model_stats %>%
  filter(p_value < 0.05) %>%
  pull(Month)

# 2. Create a new column indicating if month is significant
df_plot_temp <- df_plot_temp %>%
  mutate(significant = Month %in% significant_months)

# 3. Plot
temp <- ggplot(df_plot_temp, aes(x = Temperature_avg, y = dev)) +
  geom_point(color = "steelblue", size = 2) +
  # Add regression lines only for significant months
  geom_smooth(
    data = df_plot_temp %>% filter(significant),
    method = "lm",
    se = TRUE,
    color = "firebrick"
  ) +
  facet_wrap(~Month, ncol = 3, scales = "fixed") +
  theme_classic() +
  labs(
    title = "Temperature",
    x = "Temperature (\u00B0C)",
    y = "Recruitment Deviation"
  ) +
  geom_text(
    data = model_stats,
    aes(
      x = -Inf, y = Inf,
      label = paste0("R² = ", round(r_squared, 2), "\nP = ", signif(p_value, 2))
    ),
    hjust = -0.1, vjust = 1.2,
    inherit.aes = FALSE,
    size = 3.5
  )

temp
```
### Wind graphs
```{r}
# Monthly graphs for Wind

# 2. Function to run model and extract R² and p-value
model_stats <- df_merged_goph_monthly_wind %>%
  group_by(Month) %>%
  summarise(
    model = list(lm(dev ~ Vwind_avg, data = cur_data())),
    .groups = "drop"
  ) %>%
  mutate(
    glance_out = map(model, glance),
    r_squared = map_dbl(glance_out, "r.squared"),
    p_value = map_dbl(glance_out, "p.value")
  ) %>%
  select(Month, r_squared, p_value)

# 3. Join model stats back to main data for labeling
df_plot_wind <- left_join(df_merged_goph_monthly_wind, model_stats, by = "Month")

# 1. Identify significant months
significant_months <- model_stats %>%
  filter(p_value < 0.05) %>%
  pull(Month)

# 2. Create a new column indicating if month is significant
df_plot_wind <- df_plot_wind %>%
  mutate(significant = Month %in% significant_months)

# 3. Plot
wind <- ggplot(df_plot_wind, aes(x = Vwind_avg, y = dev)) +
  geom_point(color = "steelblue", size = 2) +
  # Add regression lines only for significant months
  geom_smooth(
    data = df_plot_wind %>% filter(significant),
    method = "lm",
    se = TRUE,
    color = "firebrick"
  ) +
  facet_wrap(~Month, ncol = 3, scales = "fixed") +
  theme_classic() +
  labs(
    title = "Meridional Wind",
    x = "Wind Speed (m/s)",
    y = "Recruitment Deviation"
  ) +
  geom_text(
    data = model_stats,
    aes(
      x = -Inf, y = Inf,
      label = paste0("R² = ", round(r_squared, 2), "\nP = ", signif(p_value, 2))
    ),
    hjust = -0.1, vjust = 1.2,
    inherit.aes = FALSE,
    size = 3.5
  )

wind
```

### CHL graphs
```{r}
# Monthly graphs for Primary Production

# 2. Function to run model and extract R² and p-value
model_stats <- df_merged_goph_monthly %>%
  group_by(Month) %>%
  summarise(
    model = list(lm(dev ~ Chla_avg, data = cur_data())),
    .groups = "drop"
  ) %>%
  mutate(
    glance_out = map(model, glance),
    r_squared = map_dbl(glance_out, "r.squared"),
    p_value = map_dbl(glance_out, "p.value")
  ) %>%
  select(Month, r_squared, p_value)

# 3. Join model stats back to main data for labeling
df_plot_pp <- left_join(df_merged_goph_monthly, model_stats, by = "Month")

# 1. Identify significant months
significant_months <- model_stats %>%
  filter(p_value < 0.05) %>%
  pull(Month)

# 2. Create a new column indicating if month is significant
df_plot_pp <- df_plot_pp %>%
  mutate(significant = Month %in% significant_months)

# 3. Plot
pp <- ggplot(df_plot_pp, aes(x = Chla_avg, y = dev)) +
  geom_point(color = "steelblue", size = 2) +
  # Add regression lines only for significant months
  geom_smooth(
    data = df_plot_pp %>% filter(significant),
    method = "lm",
    se = TRUE,
    color = "firebrick"
  ) +
  facet_wrap(~Month, ncol = 3, scales = "fixed") +
  theme_classic() +
  labs(
    title = "Primary Production",
    x = "Primary Production (m/s)",
    y = "Recruitment Deviation"
  ) +
  geom_text(
    data = model_stats,
    aes(
      x = -Inf, y = Inf,
      label = paste0("R² = ", round(r_squared, 2), "\nP = ", signif(p_value, 2))
    ),
    hjust = -0.1, vjust = 1.2,
    inherit.aes = FALSE,
    size = 3.5
  )

pp
```


### All together 
```{r}
# Set theme with larger axis titles and numbers
larger_axis_theme <- 
  theme(
    axis.line = element_line(color = "black"),
    legend.position = "none",
    axis.title = element_text(size = 10),   # Axis titles
    axis.text = element_text(size = 9),
    title = element_text(size = 12)# Axis numbers
  )

# Then combine them
monthly_ROMS <- pH + do + temp + wind + plot_layout(ncol = 2) + larger_axis_theme

monthly_ROMS

ggsave("monthly_ROMS.png", width = 14, height = 10, dpi = 300)
```



# Figures 
## Fig themes
```{r}
# Set theme with larger axis titles and numbers
larger_axis_theme <- theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(color = "black"),
    legend.position = "none",
    axis.title = element_text(size = 16),   # Axis titles
    axis.text = element_text(size = 14),
    title = element_text(size = 20)# Axis numbers
  )
```

## Fig 2. Recruitment Timeseries
```{r}
# Set theme with larger axis titles and numbers
larger_axis_theme <- theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.line = element_line(color = "black"),
    legend.position = "none",
    axis.title = element_text(size = 8),   # Axis titles
    axis.text = element_text(size = 7),
    title = element_text(size = 10)# Axis numbers
  )

# ========== Time series of recruitment devs from SA ==========
stock_assessment <- ggplot(goph_recruit_nf, aes(x = Year, y = dev)) +
  geom_line(color = "steelblue", size = 1.2) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = 1)+
  theme_classic() +
  labs(title = "A) Stock Assessment", y = "Recruitment Deviation", x = "Year") + 
  larger_axis_theme


# ========== Time series of PISCO index of abundance ==========
pisco_index <- ggplot(pisco_data, aes(x = Year, y = obs)) +
  geom_line(color = "navyblue", size = 1.2) +
  theme_classic() +
  labs(title = "B) PISCO", y = "Index of Abundance", x = "Year") + 
  scale_x_continuous(limits = c(1987, max(pisco_data$Year))) +
  larger_axis_theme


# ============= Corrleation plot ===========================

recruit_merged <- left_join(pisco_data, goph_recruit, by = "Year")
summary(recruit_merged)

# Fit a linear model 
lm_recruit <- lm(dev ~ obs, data = recruit_merged)
summary(lm_recruit)


recruit_plot <- ggplot(recruit_merged, aes(x = obs, y = dev)) +
  geom_point(size = 3, shape = 21, fill = "grey30") +
  geom_smooth(method = "lm", se = TRUE, size = 1.2, color = "black") +
  annotate("text", x = Inf, y = Inf, label = paste0("p < 0.001 r² = 0.87"),
           hjust = 1, vjust = 1, size = 5, fontface = "italic") +
  labs(
    x = "PISCO Index",
    y = "Recruitment Deviations (Stock Assessment)",
    title = ""
  ) +
  larger_axis_theme +
  theme(axis.title.y = element_blank()) + 
  theme_classic()

recruit_plot

# ========== Combined Plot ==========
# Then combine them
fig2 <- stock_assessment / pisco_index | recruit_plot + plot_layout(ncol = 2)

fig2

ggsave("figure2recruitmenthistorical.png", width = 10, height = 4, dpi = 300)


# ========== Time series of recruitment devs from SA for thesis defense presentation ==========
stock_assessment <- ggplot(goph_recruit_nf, aes(x = Year, y = dev)) +
  geom_line(color = "black", size = 1.2) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = .7)+
  theme_classic() +
  geom_vline(xintercept = 1995, linetype = "solid", color = "grey", size = 1) +
  labs(title = "", y = "Recruitment Deviation", x = "Year") + 
    theme(
    plot.background = element_rect(fill = "transparent", colour = NA), # Transparent plot background
    panel.background = element_rect(fill = "transparent", colour = NA) # Transparent panel background
  )+
  larger_axis_theme 

stock_assessment <- ggplot(goph_recruit_nf, aes(x = Year, y = dev)) +
  # negative deviations (red)
  geom_line(color = "black", size = .75, alpha = .5) +
  geom_point(
    data = subset(goph_recruit_nf, dev < 0),
    color = "red",
    size = 2.5
  ) +
  # positive deviations (sage green-ish)
  geom_point(
    data = subset(goph_recruit_nf, dev >= 0),
    color = "#9DC183",  # sage green
    size = 2.5
  ) +
  geom_hline(yintercept = 0, linetype = "dotted", color = "black", size = .7) +
  geom_vline(xintercept = 1995, linetype = "dashed", color = "black", size = 1) +
  theme_classic() +
  labs(title = "", y = "Recruitment Deviation", x = "Year") + 
  theme(
    plot.background = element_rect(fill = "transparent", colour = NA),
    panel.background = element_rect(fill = "transparent", colour = NA)
  ) +
  larger_axis_theme


stock_assessment

#stock_assessment_2 <- ggplot(goph_recruit, aes(x = Year, y = dev)) +
 # geom_line(color = "navyblue", size = 1.2) +
 # geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = .7)+
 # theme_classic() +
 # labs(title = "Filtered Time Series", y = "Recruitment Deviation", x = "Year") + 
 # larger_axis_theme

#stock_assessment_2

#defense_dev_time_series <- stock_assessment + stock_assessment_2 +plot_layout(ncol = 1)

#defense_dev_time_series

ggsave("figure2recruitmenthistorical.png", bg = "transparent",
       width = 5, height = 3, dpi = 300)
```

```{r}
library(ggpubr)

# Step 1: Merge the two datasets by Year
cor_data <- inner_join(
  goph_recruit_nf %>% select(Year, dev),
  pisco_data %>% select(Year, obs),
  by = "Year"
)

# Step 2: Create the correlation plot
correlation_plot <- ggplot(cor_data, aes(x = dev, y = obs)) +
  geom_point(color = "darkblue", size = 3) +
  geom_smooth(method = "lm", se = TRUE, color = "firebrick") +
  theme_classic() +
  labs(
    title = "C) Correlation: Recruitment Deviation vs. PISCO Index",
    x = "Recruitment Deviation (SA)",
    y = "PISCO Index of Abundance"
  ) + 
   stat_cor(method = "pearson", label.x = min(cor_data$dev), label.y = max(cor_data$obs)) + # Optional
  larger_axis_theme 

# Print it
print(correlation_plot)

```

## Fig 3. ROMS output timeseries 
```{r}
do <- ggplot(ROMS_outputs, aes(x = Year, y = DO_Avg)) +
  geom_line(size = 1.5) +
  geom_ribbon(aes(ymin = DO_Avg - DO_SD, ymax = DO_Avg + DO_SD), alpha = 0.4 ) +
  labs(title = "Dissolved Oxygen", y = "DO (mg/L)", x = "Year") +
  theme_classic() + 
  larger_axis_theme + 
  theme(axis.title.x = element_blank(), axis.text.x = element_blank())
do

pH <- ggplot(ROMS_outputs, aes(x = Year, y = pH_Avg)) +
geom_line(size = 1.5)+
geom_ribbon(aes(ymin = pH_Avg - pH_SD, ymax = pH_Avg + pH_SD), alpha = 0.4) +
  labs(title = "pH", y = "pH", x = "Year") +
  theme_minimal() + 
  larger_axis_theme + 
  theme(axis.title.x = element_blank(), axis.text.x = element_blank())

 
temp <- ggplot(ROMS_outputs, aes(x = Year, y = Temperature_Avg)) +
geom_line(size = 1.5)+
geom_ribbon(aes(ymin = Temperature_Avg - Temperature_SD, ymax = Temperature_Avg + Temperature_SD), alpha = 0.4, color = NA) +
  labs(title = "Temperature", y = "Temperature (°C)", x = "Year") +
  theme_minimal()+
  larger_axis_theme 
temp 

wind <- ggplot(ROMS_outputs, aes(x = Year, y = Wind)) +
geom_line(size = 1.5) +
geom_ribbon(aes(ymin = Wind - Wind_SD, ymax = Wind + Wind_SD), alpha = 0.2, color = NA) +
  labs(title = "Wind Stress", y = "Meridional Wind (m/s)", x = "Year") +
  theme_minimal()+
  larger_axis_theme 
wind 

# Combine them
(do + pH + temp + wind) + plot_layout(guides = "collect") & theme(legend.position = "bottom") 


ggsave("figure3ROMShistorical.png", width = 12, height = 5, dpi = 300)

```

## Fig 3A. ROMS output timeseries spatially separated
```{r}
colors <- wes_palette("AsteroidCity1", type = "discrete")

spatial_colors <- c("mid" = colors[1], 
                      "north" = colors[4],
                 "south" = colors[3], 
                 "all" = colors[2])

ROMS_CUTI_environmental_combined_all_yr <- ROMS_CUTI_environmental_combined_all_yr %>% 
  filter(Year > 1994) %>% 
  filter(Year < 2019)
#  rename("Region" = "region")

df_graph <- ROMS_CUTI_environmental_combined_all_yr %>%
  mutate(
    region = factor(Region, levels = c("south","mid","north", "all")),
    Month = factor(Month, levels = month.abb, ordered = TRUE),
    date  = as.Date(paste(Year, as.character(Month), "15"), format = "%Y %b %d")
  )

do <- ggplot(df_graph, aes(x = date, y = DO_avg, color = Region)) +
  geom_line(size = 1) +
 # geom_ribbon(aes(ymin = DO_avg - DO_sd, ymax = DO_avg + DO_sd), alpha = 0.4 ) +
  labs(title = "Dissolved Oxygen", y = "DO (mg/L)", x = "Year") +
  theme_classic() + 
  larger_axis_theme + 
  scale_color_manual(values = spatial_colors, name = "Region") +
  theme(axis.title.x = element_blank(), axis.text.x = element_blank()) 
do

pH <- ggplot(df_graph, aes(x = date, y = pH_avg, color = Region)) +
  geom_line(size = 1)+
  #geom_ribbon(aes(ymin = pH_avg - pH_sd, ymax = pH_avg + pH_sd), alpha = 0.4) +
  labs(title = "pH", y = "pH", x = "Year") +
  theme_minimal() + 
  larger_axis_theme + 
  scale_color_manual(values = spatial_colors, name = "Region") +
  theme(axis.title.x = element_blank(), axis.text.x = element_blank())

 
pp <- ggplot(df_graph, aes(x = date, y = Chla_avg, color = Region)) +
  geom_line(size = 1)+
  labs(title = "Primary Production", y = "Primary Production (mg/m²)", x = "Year") +
  theme_minimal()+
  scale_color_manual(values = spatial_colors, name = "Region") +
  larger_axis_theme  +
  theme(axis.title.x = element_blank(), axis.text.x = element_blank())

pp 

temp <- ggplot(df_graph, aes(x = date, y = Temperature_avg, color = Region)) +
  geom_line(size = 1)+
  #geom_ribbon(aes(ymin = Temperature_Avg - Temperature_SD, ymax = Temperature_Avg + Temperature_SD), alpha = 0.4, color = NA) +
  labs(title = "Temperature", y = "Temperature (°C)", x = "Year") +
  theme_minimal()+ 
  scale_color_manual(values = spatial_colors, name = "Region") +
  larger_axis_theme +
  theme(axis.title.x = element_blank(), axis.text.x = element_blank())

temp 

wind <- ggplot(df_graph, aes(x = date, y = Vwind_avg, color = Region)) +
geom_line(size = 1) +
#geom_ribbon(aes(ymin = Wind - Wind_SD, ymax = Wind + Wind_SD), alpha = 0.2, color = NA) +
  labs(title = "Wind Stress", y = "Meridional Wind (m/s)", x = "Year") +
  theme_minimal()+ 
  scale_color_manual(values = spatial_colors, name = "Region") +
  larger_axis_theme 
wind 


cuti <- ggplot(df_graph, aes(x = date, y = CUTI, color = Region)) +
geom_line(size = 1) +
  labs(title = "CUTI", y = "CUTI (m/s)", x = "Year") +
  theme_minimal()+ 
  scale_color_manual(values = spatial_colors, name = "Region") +
  larger_axis_theme 
cuti 


# Combine them
((do + pH) / (temp + pp) / (wind + cuti)) + plot_layout(guides = "collect") & theme(legend.position = "bottom") 


ggsave("figure3ROMShistorical.png", width = 12, height = 7, dpi = 300)
```



## Fig 4. Abundace Indicies Timeseries 
```{r}
# ========== PDO ==========
# Prepare data
df_pdo$Source <- "Monthly"
df_pdo$Date <- df_pdo$time  # assume `time` is a Date object

yearly_avg_pdo$Source <- "Yearly Avg"
# Convert Year to Date format for consistency (e.g., Jan 1st of each year)
yearly_avg_pdo$Date <- as.Date(paste0(yearly_avg_pdo$Year, "-01-01"))

# Rename y column to match
names(df_pdo)[names(df_pdo) == "PDO"] <- "Value"
names(yearly_avg_pdo)[names(yearly_avg_pdo) == "mean_pdo"] <- "Value"

# Combine
combined_df <- rbind(
  df_pdo[, c("Date", "Value", "Source")],
  yearly_avg_pdo[, c("Date", "Value", "Source")]
)


ggplot(combined_df, aes(x = Date, y = Value, color = Source)) +
  geom_line(size = 1) +
  theme_classic() +
  labs(
    title = "Pacific Decadal Oscillation",
    y = "PDO",
    x = "Date"
  ) +
  scale_color_manual(values = c("Monthly" = "lightblue", "Yearly Avg" = "navy"))+
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = 1)


# ========== NPGO ==========
# Prepare data
npgo$Source <- "Monthly"

yearly_avg_npgo$Source <- "Yearly Avg"
# Convert Year to Date format for consistency (e.g., Jan 1st of each year)
yearly_avg_npgo$Date <- as.Date(paste0(yearly_avg_npgo$Year, "-01-01"))

# Rename y column to match
names(npgo)[names(npgo) == "NPGO"] <- "Value"
names(yearly_avg_npgo)[names(yearly_avg_npgo) == "npgo_avg"] <- "Value"

# Combine
combined_df <- rbind(
  npgo[, c("Date", "Value", "Source")],
  yearly_avg_npgo[, c("Date", "Value", "Source")]
)


ggplot(combined_df, aes(x = Date, y = Value, color = Source)) +
  geom_line(size = 1) +
  theme_classic() +
  labs(
    title = "North Pacific Gyre Oscillation",
    y = "NPGO Index",
    x = "Date"
  ) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = 1)+
  scale_color_manual(values = c("Monthly" = "tan", "Yearly Avg" = "tan4"))

# ========== ONI ==========

# ========== CUTI ==========
# Prepare data
npgo$Source <- "Monthly"

yearly_avg_npgo$Source <- "Yearly Avg"
# Convert Year to Date format for consistency (e.g., Jan 1st of each year)
yearly_avg_npgo$Date <- as.Date(paste0(yearly_avg_npgo$Year, "-01-01"))

# Rename y column to match
names(npgo)[names(npgo) == "NPGO"] <- "Value"
names(yearly_avg_npgo)[names(yearly_avg_npgo) == "npgo_avg"] <- "Value"

# Combine
combined_df <- rbind(
  npgo[, c("Date", "Value", "Source")],
  yearly_avg_npgo[, c("Date", "Value", "Source")]
)


ggplot(combined_df, aes(x = Date, y = Value, color = Source)) +
  geom_line(size = 1) +
  theme_classic() +
  labs(
    title = "North Pacific Gyre Oscillation",
    y = "NPGO Index",
    x = "Date"
  ) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = 1)+
  scale_color_manual(values = c("Monthly" = "tan", "Yearly Avg" = "tan4"))
```

# Monthly Correlation Analysis - not spatially explicity
```{r}
# Join with environmental data
#full_data <- left_join(goph_recruit, ROMS_environmental_combined, by = "Year")
full_data <- left_join(goph_recruit, combined_monthly_indices_NOT_SPATIAL, by = "Year")

# List of variables you want to correlate with recruitment
vars_to_correlate <- c("mean_sl", "mean_pdo", "npgo_avg", "oni_avg")

# Calculate correlations by month
cor_data <- full_data %>%
  pivot_longer(cols = all_of(vars_to_correlate), names_to = "Variable", values_to = "Value") %>%
  group_by(Variable, Month) %>%
  summarise(
    cor_test = list(cor.test(Value, dev, method = "pearson")),
    .groups = "drop"
  ) %>%
  mutate(
    correlation = map_dbl(cor_test, ~ .x$estimate),
    pval        = map_dbl(cor_test, ~ .x$p.value),
    t_stat      = map_dbl(cor_test, ~ .x$statistic),
    significant = pval < 0.05
  ) %>%
  select(-cor_test)



# Order months properly
cor_data$Month <- factor(cor_data$Month, levels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"))

cor_data <- cor_data %>%
  mutate(Variable = dplyr::recode(as.character(Variable),
    "mean_pdo"        = "PDO",
    "mean_sl"         = "Sea Level",
    "npgo_avg"        = "NPGO",
    "oni_avg"         = "ONI",
  ))

desired_order <- c(
   "PDO","Sea Level", "NPGO", "ONI")

cor_data$Variable <- factor(cor_data$Variable, levels = desired_order)

ggplot(cor_data, aes(x = Month, y = correlation, color = significant, group = 1)) +
  geom_point(size = 3) +
 geom_line(size = 1) +
  facet_wrap(~Variable, ncol = 2) +
  geom_hline(yintercept = 0, linetype = "solid", size = 0.25) +
  geom_hline(yintercept = c(-0.25, 0.25), linetype = "dashed", color = "black", size = 0.75) +
  scale_color_manual(values = c("FALSE" = "black", "TRUE" = "indianred")) +
  theme_classic() +
  labs(
    title = "",
    y = "Correlation with Recruitment",
    color = "Significant"
  )+   theme_bw() +
  theme(strip.text = element_text(size = 12, face = "bold"), 
        axis.line = element_line(color = "black"),
        legend.position = "none",
        axis.title = element_text(size = 16),   # Axis titles
        axis.text = element_text(size = 14),
        axis.text.x = element_text(angle = 45, hjust = 1),  # 
        title = element_text(size = 20))

ggsave("monthlycorr_OBNONSPATIAL_allmonths.png", width = 8, height = 6, dpi = 300)

# Making a data frame with significant months 
significant_months <- cor_data %>%
  filter(significant == TRUE)
```

## plots for defense presentation
```{r}
# Keep only Dissolved Oxygen
cor_do <- cor_data %>%
  dplyr::filter(Variable == "Dissolved Oxygen") %>%
  droplevels()

# Plot just the DO panel
do_plot <- ggplot(cor_do, aes(x = Month, y = correlation, color = significant, group = 1)) +
  geom_point(size = 3) +
  geom_line(size = 1) +
  geom_hline(yintercept = 0, linetype = "solid", size = 0.25) +
  geom_hline(yintercept = c(-0.25, 0.25), linetype = "dashed", color = "black", size = 0.75) +
  scale_y_continuous(limits = c(-0.5, .5)) +
  scale_color_manual(values = c("FALSE" = "black", "TRUE" = "indianred")) +
  labs(title = "Dissolved Oxygen", y = "Correlation with Recruitment", x = NULL) +
  theme_classic() +
  theme(
    strip.text = element_text(size = 12, face = "bold"),
    axis.line = element_line(color = "black"),
    legend.position = "none",
    axis.title = element_text(size = 16),
    axis.text = element_text(size = 14),
    axis.text.x = element_text(angle = 45, hjust = 1),
    title = element_text(size = 20)
  ) + 
   theme(
    panel.background = element_rect(fill='transparent'), #transparent panel bg
    plot.background = element_rect(fill='transparent', color=NA), #transparent plot bg
    panel.grid.major = element_blank(), #remove major gridlines
    panel.grid.minor = element_blank(), #remove minor gridlines
    legend.background = element_rect(fill='transparent'), #transparent legend bg
    legend.box.background = element_rect(fill='transparent') #transparent legend panel
  )

print(do_plot)

# Optional: save just the DO figure
ggsave("monthlycorr_DO.png", do_plot, bg = "transparent", width = 5.5, height = 4.5, dpi = 300)
```

```{r}
# Keep only what's needed and order months
month_levels <- c("Jan","Feb","Mar","Apr","May","Jun",
                  "Jul","Aug","Sep","Oct","Nov","Dec")

do_monthly <- full_data %>%
  dplyr::select(Year, Month, dev, DO_avg) %>%
  dplyr::filter(!is.na(DO_avg), !is.na(dev), !is.na(Month)) %>%
  dplyr::mutate(Month = factor(Month, levels = month_levels))

# months to show trend lines for
months_with_trend <- c("Jan","Mar","Jul")

# data used for the trend lines only
trend_data <- do_monthly %>% dplyr::filter(Month %in% months_with_trend)

do_12panel <- ggplot(do_monthly, aes(x = DO_avg, y = dev)) +
  geom_point(size = 2, alpha = 0.7) +
  stat_smooth(
    data = trend_data,       # <- only Jan, Mar, Jul
    method = "lm", se = TRUE, linewidth = 0.9, color = "indianred"
  ) +
  facet_wrap(~ Month, ncol = 4) +
  theme_classic() +
  labs(
    title = "",
    x = "Dissolved Oxygen (mg/L)",
    y = "Recruitment Deviation"
  ) +
  larger_axis_theme +
   theme(
    panel.background = element_rect(fill='transparent'), #transparent panel bg
    plot.background = element_rect(fill='transparent', color=NA), #transparent plot bg
    panel.grid.major = element_blank(), #remove major gridlines
    panel.grid.minor = element_blank(), #remove minor gridlines
    legend.background = element_rect(fill='transparent'), #transparent legend bg
    legend.box.background = element_rect(fill='transparent') #transparent legend panel
  )

print(do_12panel)

ggsave("DO_by_month_lm.png", do_12panel, width = 9, height = 8, dpi = 300)

# Save
ggsave("DO_by_month_lm.png", do_12panel, width = 9, height = 8, dpi = 300)

```

```{r}
# One-panel scatter + linear regression for January only
jan_data <- full_data %>%
  dplyr::select(Year, Month, dev, DO_avg) %>%
  dplyr::filter(!is.na(DO_avg), !is.na(dev), Month == "Jan")

jan_plot <- ggplot(jan_data, aes(x = DO_avg, y = dev)) +
  geom_point(size = 2, alpha = 0.8) +
  stat_smooth(method = "lm", se = FALSE, linewidth = 1, color = "indianred") +
  theme_classic() +
  labs(
    title = "",
    x = "Dissolved Oxygen (mg/L)",
    y = "Recruitment Deviation"
  ) +
  larger_axis_theme +
   theme(
    panel.background = element_rect(fill='transparent'), #transparent panel bg
    plot.background = element_rect(fill='transparent', color=NA), #transparent plot bg
    panel.grid.major = element_blank(), #remove major gridlines
    panel.grid.minor = element_blank(), #remove minor gridlines
    legend.background = element_rect(fill='transparent'), #transparent legend bg
    legend.box.background = element_rect(fill='transparent') #transparent legend panel
  )
  

print(jan_plot)

# Save (adjust size as you like)
ggsave("DO_Jan_lm.png", jan_plot, bg = "transparent",width = 6, height = 5, dpi = 300)

```

```{r}
# plots for physical drivers
make_var_plot <- function(df, var_name, plot_title = var_name, out_file = NULL) {
  d <- df %>%
    dplyr::filter(Variable == var_name) %>%
    droplevels()

  p <- ggplot(d, aes(x = Month, y = correlation, color = significant, group = 1)) +
    geom_point(size = 3) +
    geom_line(size = 1) +
    geom_hline(yintercept = 0, linetype = "solid", size = 0.25) +
    geom_hline(yintercept = c(-0.25, 0.25), linetype = "dashed", color = "black", size = 0.75) +
    scale_y_continuous(limits = c(-0.65, 0.65)) +
    scale_color_manual(values = c("FALSE" = "black", "TRUE" = "indianred")) +
    labs(title = plot_title, y = "Correlation with Recruitment", x = NULL) +
    theme_classic() +
    theme(
      strip.text = element_text(size = 12, face = "bold"),
      axis.line = element_line(color = "black"),
      legend.position = "none",
      axis.title = element_text(size = 16),
      axis.text = element_text(size = 14),
      axis.text.x = element_text(angle = 45, hjust = 1),
      title = element_text(size = 20),
      panel.background = element_rect(fill = "transparent", colour = NA),
      plot.background  = element_rect(fill = "transparent", colour = NA),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      legend.background = element_rect(fill = "transparent", colour = NA),
      legend.box.background = element_rect(fill = "transparent", colour = NA)
    )
  

  print(p)

  if (!is.null(out_file)) {
    ggsave(out_file, p, bg = "transparent", width = 4, height = 4, dpi = 300)
  }

  invisible(p)
}

# Make the three plots
p_wind <- make_var_plot(
  cor_data,
  var_name   = "Meridional Wind",
  plot_title = "Meridional Wind Stress",
  out_file   = "monthlycorr_MeridionalWindStress.png"
)

# Optional: save just the DO figure
ggsave("monthlycorr_wind.png", p_wind, bg = "transparent", width = 5.5, height = 4.5, dpi = 300)

p_sea_level <- make_var_plot(
  cor_data,
  var_name   = "Sea Level",
  plot_title = "Sea Level",
  out_file   = "monthlycorr_SeaLevel.png"
)

# Optional: save just the DO figure
ggsave("monthlycorr_SL.png", p_sea_level, bg = "transparent", width = 5.5, height = 4.5, dpi = 300)

p_cuti <- make_var_plot(
  cor_data,
  var_name   = "CUTI",
  plot_title = "CUTI",
  out_file   = "monthlycorr_CUTI.png"
)

# Optional: save just the DO figure
ggsave("monthlycorr_CUTI.png", p_cuti, bg = "transparent", width = 5.5, height = 4.5, dpi = 300)

```

```{r}
# same function as above but for the biochemical parameters
# Make the three plots
p_DO <- make_var_plot(
  cor_data,
  var_name   = "Dissolved Oxygen",
  plot_title = "Dissolved Oxygen",
  out_file   = "monthlycorr_DO.png"
)


p_pH <- make_var_plot(
  cor_data,
  var_name   = "pH",
  plot_title = "pH",
  out_file   = "monthlycorr_pH.png"
)


p_temp <- make_var_plot(
  cor_data,
  var_name   = "Temperature",
  plot_title = "Temperature",
  out_file   = "monthlycorr_temp.png"
)


p_pprod <- make_var_plot(
  cor_data,
  var_name   = "Primary Production",
  plot_title = "Primary Production",
  out_file   = "monthlycorr_pp.png"
)

```

```{r}
# same function as above but for the ocean basin indices 
# Make the three plots
p_NPGO <- make_var_plot(
  cor_data,
  var_name   = "NPGO",
  plot_title = "NPGO",
  out_file   = "monthlycorr_NPGO.png"
)


p_pH <- make_var_plot(
  cor_data,
  var_name   = "PDO",
  plot_title = "PDO",
  out_file   = "monthlycorr_PDO.png"
)


p_temp <- make_var_plot(
  cor_data,
  var_name   = "ONI",
  plot_title = "ONI",
  out_file   = "monthlycorr_ONI.png"
)

```

# Monthly Correlation Analysis - spatially explicit
```{r}
# Join with environmental data
full_data <- left_join(goph_recruit, ROMS_CUTI_environmental_combined_all_yr, by = "Year")

# List of variables you want to correlate with recruitment
vars_to_correlate <- c("DO_avg", "pH_avg", "Temperature_avg", 
                       "Chla_avg", "Vwind_avg", "CUTI")

# Calculate correlations by month
cor_data <- full_data %>%
  pivot_longer(cols = all_of(vars_to_correlate), names_to = "Variable", values_to = "Value") %>%
  group_by(Variable, Month, Region) %>%
  summarise(
    cor_test = list(cor.test(Value, dev, method = "pearson")),
    .groups = "drop"
  ) %>%
  mutate(
    correlation = map_dbl(cor_test, ~ .x$estimate),
    pval        = map_dbl(cor_test, ~ .x$p.value),
    t_stat      = map_dbl(cor_test, ~ .x$statistic),
    significant = pval < 0.05
  ) %>%
  select(-cor_test)



# Order months properly
#cor_data$Month <- factor(cor_data$Month, levels = c("Feb", "Mar", "Apr", "May", "Jun", "Jul"))
cor_data$Month <- factor(cor_data$Month, levels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"))

cor_data <- cor_data %>%
  mutate(Variable = dplyr::recode(as.character(Variable),
    "Chla_avg"        = "Primary Production",
    "DO_avg"          = "Dissolved Oxygen",
    "pH_avg"          = "pH",
    "Temperature_avg" = "Temperature",
    "Vwind_avg"       = "Meridional Wind"
  ))

desired_order <- c(
  "Dissolved Oxygen", "Temperature", "pH", "Primary Production", "Meridional Wind", "CUTI"
)

cor_data$Variable <- factor(cor_data$Variable, levels = desired_order)

# graph with region by color
ggplot(cor_data, aes(x = Month, y = correlation, color = Region)) +
  facet_wrap(~Variable, ncol = 2) +
  geom_hline(yintercept = 0, linetype = "solid", size = 0.25) +
  geom_hline(yintercept = c(-0.25, 0.25), linetype = "dashed", color = "black", size = 0.75) +
  scale_color_manual(values = spatial_colors, name = "Region") +
  theme_classic() +
   # points: shape encodes significance
  geom_point(aes(shape = significant), size = 3, stroke = 1.1) +
  scale_shape_manual(
    values = c(`TRUE` = 16, `FALSE` = 1),           # 16 = filled circle, 1 = open circle
    labels = c(`TRUE` = "p < 0.05", `FALSE` = "ns")
  ) +
  geom_line() +
  labs(
    title = "",
    y = "Correlation with Recruitment",
    color = "Significant"
  )+   theme_bw() +
  theme(strip.text = element_text(size = 12, face = "bold"), 
        axis.line = element_line(color = "black"),
        legend.position = "bottom",
        axis.title = element_text(size = 16),   # Axis titles
        axis.text = element_text(size = 14),
        axis.text.x = element_text(angle = 45, hjust = 1),  # 
        title = element_text(size = 20))



# this is graph with region by shape
ggplot(cor_data, aes(x = Month, y = correlation)) +
  facet_wrap(~Variable, ncol = 2) +
  geom_hline(yintercept = 0, linetype = "solid", size = 0.25) +
  geom_hline(yintercept = c(-0.25, 0.25), linetype = "dashed", color = "black", size = 0.75) +


  # points: shape encodes Region, color encodes significance
  geom_point(aes(shape = Region, color = significant), size = 3, stroke = 1.1) +

  # legends & scales
  scale_shape_discrete(name = "Region") +
  scale_color_manual(
    values = c(`TRUE` = "indianred", `FALSE` = "grey"),
    name   = "Significance",
    labels = c(`TRUE` = "p < 0.05", `FALSE` = "ns")
  ) +

  labs(
    title = "",
    y     = "Correlation with Recruitment"
  ) +
  theme_bw() +
  theme(
    strip.text   = element_text(size = 12, face = "bold"),
    axis.line    = element_line(color = "black"),
    legend.position = "right",
    axis.title   = element_text(size = 16),
    axis.text    = element_text(size = 14),
    axis.text.x  = element_text(angle = 45, hjust = 1),
    title        = element_text(size = 20)
  )


ggsave("monthlycorr_allmonths_spatially_separated.png", width = 9, height = 10, dpi = 300)

# Making a data frame with significant months 
significant_months <- cor_data %>%
  filter(significant == TRUE) %>% 
  filter(Region == "all") %>% 
  filter(Month == "Dec")
```

## plots for defense presentation
```{r}
# Keep only Dissolved Oxygen
cor_do <- cor_data %>%
  dplyr::filter(Variable == "Dissolved Oxygen") %>%
  droplevels()

# Plot just the DO panel
do_plot <- ggplot(cor_do, aes(x = Month, y = correlation, color = significant, group = 1)) +
  geom_point(size = 3) +
  geom_line(size = 1) +
  geom_hline(yintercept = 0, linetype = "solid", size = 0.25) +
  geom_hline(yintercept = c(-0.25, 0.25), linetype = "dashed", color = "black", size = 0.75) +
  scale_y_continuous(limits = c(-0.5, .5)) +
  scale_color_manual(values = c("FALSE" = "black", "TRUE" = "indianred")) +
  labs(title = "Dissolved Oxygen", y = "Correlation with Recruitment", x = NULL) +
  theme_classic() +
  theme(
    strip.text = element_text(size = 12, face = "bold"),
    axis.line = element_line(color = "black"),
    legend.position = "none",
    axis.title = element_text(size = 16),
    axis.text = element_text(size = 14),
    axis.text.x = element_text(angle = 45, hjust = 1),
    title = element_text(size = 20)
  ) + 
   theme(
    panel.background = element_rect(fill='transparent'), #transparent panel bg
    plot.background = element_rect(fill='transparent', color=NA), #transparent plot bg
    panel.grid.major = element_blank(), #remove major gridlines
    panel.grid.minor = element_blank(), #remove minor gridlines
    legend.background = element_rect(fill='transparent'), #transparent legend bg
    legend.box.background = element_rect(fill='transparent') #transparent legend panel
  )

print(do_plot)

# Optional: save just the DO figure
ggsave("monthlycorr_DO.png", do_plot, bg = "transparent", width = 5.5, height = 4.5, dpi = 300)
```

```{r}
# Keep only what's needed and order months
month_levels <- c("Jan","Feb","Mar","Apr","May","Jun",
                  "Jul","Aug","Sep","Oct","Nov","Dec")

do_monthly <- full_data %>%
  dplyr::select(Year, Month, dev, DO_avg) %>%
  dplyr::filter(!is.na(DO_avg), !is.na(dev), !is.na(Month)) %>%
  dplyr::mutate(Month = factor(Month, levels = month_levels))

# months to show trend lines for
months_with_trend <- c("Jan","Mar","Jul")

# data used for the trend lines only
trend_data <- do_monthly %>% dplyr::filter(Month %in% months_with_trend)

do_12panel <- ggplot(do_monthly, aes(x = DO_avg, y = dev)) +
  geom_point(size = 2, alpha = 0.7) +
  stat_smooth(
    data = trend_data,       # <- only Jan, Mar, Jul
    method = "lm", se = TRUE, linewidth = 0.9, color = "indianred"
  ) +
  facet_wrap(~ Month, ncol = 4) +
  theme_classic() +
  labs(
    title = "",
    x = "Dissolved Oxygen (mg/L)",
    y = "Recruitment Deviation"
  ) +
  larger_axis_theme +
   theme(
    panel.background = element_rect(fill='transparent'), #transparent panel bg
    plot.background = element_rect(fill='transparent', color=NA), #transparent plot bg
    panel.grid.major = element_blank(), #remove major gridlines
    panel.grid.minor = element_blank(), #remove minor gridlines
    legend.background = element_rect(fill='transparent'), #transparent legend bg
    legend.box.background = element_rect(fill='transparent') #transparent legend panel
  )

print(do_12panel)

ggsave("DO_by_month_lm.png", do_12panel, width = 9, height = 8, dpi = 300)

# Save
ggsave("DO_by_month_lm.png", do_12panel, width = 9, height = 8, dpi = 300)

```

```{r}
# One-panel scatter + linear regression for January only
jan_data <- full_data %>%
  dplyr::select(Year, Month, dev, DO_avg) %>%
  dplyr::filter(!is.na(DO_avg), !is.na(dev), Month == "Jan")

jan_plot <- ggplot(jan_data, aes(x = DO_avg, y = dev)) +
  geom_point(size = 2, alpha = 0.8) +
  stat_smooth(method = "lm", se = FALSE, linewidth = 1, color = "indianred") +
  theme_classic() +
  labs(
    title = "",
    x = "Dissolved Oxygen (mg/L)",
    y = "Recruitment Deviation"
  ) +
  larger_axis_theme +
   theme(
    panel.background = element_rect(fill='transparent'), #transparent panel bg
    plot.background = element_rect(fill='transparent', color=NA), #transparent plot bg
    panel.grid.major = element_blank(), #remove major gridlines
    panel.grid.minor = element_blank(), #remove minor gridlines
    legend.background = element_rect(fill='transparent'), #transparent legend bg
    legend.box.background = element_rect(fill='transparent') #transparent legend panel
  )
  

print(jan_plot)

# Save (adjust size as you like)
ggsave("DO_Jan_lm.png", jan_plot, bg = "transparent",width = 6, height = 5, dpi = 300)

```

```{r}
# plots for physical drivers
make_var_plot <- function(df, var_name, plot_title = var_name, out_file = NULL) {
  d <- df %>%
    dplyr::filter(Variable == var_name) %>%
    droplevels()

  p <- ggplot(d, aes(x = Month, y = correlation, color = significant, group = 1)) +
    geom_point(size = 3) +
    geom_line(size = 1) +
    geom_hline(yintercept = 0, linetype = "solid", size = 0.25) +
    geom_hline(yintercept = c(-0.25, 0.25), linetype = "dashed", color = "black", size = 0.75) +
    scale_y_continuous(limits = c(-0.65, 0.65)) +
    scale_color_manual(values = c("FALSE" = "black", "TRUE" = "indianred")) +
    labs(title = plot_title, y = "Correlation with Recruitment", x = NULL) +
    theme_classic() +
    theme(
      strip.text = element_text(size = 12, face = "bold"),
      axis.line = element_line(color = "black"),
      legend.position = "none",
      axis.title = element_text(size = 16),
      axis.text = element_text(size = 14),
      axis.text.x = element_text(angle = 45, hjust = 1),
      title = element_text(size = 20),
      panel.background = element_rect(fill = "transparent", colour = NA),
      plot.background  = element_rect(fill = "transparent", colour = NA),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      legend.background = element_rect(fill = "transparent", colour = NA),
      legend.box.background = element_rect(fill = "transparent", colour = NA)
    )
  

  print(p)

  if (!is.null(out_file)) {
    ggsave(out_file, p, bg = "transparent", width = 4, height = 4, dpi = 300)
  }

  invisible(p)
}

# Make the three plots
p_wind <- make_var_plot(
  cor_data,
  var_name   = "Meridional Wind",
  plot_title = "Meridional Wind Stress",
  out_file   = "monthlycorr_MeridionalWindStress.png"
)

# Optional: save just the DO figure
ggsave("monthlycorr_wind.png", p_wind, bg = "transparent", width = 5.5, height = 4.5, dpi = 300)

p_sea_level <- make_var_plot(
  cor_data,
  var_name   = "Sea Level",
  plot_title = "Sea Level",
  out_file   = "monthlycorr_SeaLevel.png"
)

# Optional: save just the DO figure
ggsave("monthlycorr_SL.png", p_sea_level, bg = "transparent", width = 5.5, height = 4.5, dpi = 300)

p_cuti <- make_var_plot(
  cor_data,
  var_name   = "CUTI",
  plot_title = "CUTI",
  out_file   = "monthlycorr_CUTI.png"
)

# Optional: save just the DO figure
ggsave("monthlycorr_CUTI.png", p_cuti, bg = "transparent", width = 5.5, height = 4.5, dpi = 300)

```

```{r}
# same function as above but for the biochemical parameters
# Make the three plots
p_DO <- make_var_plot(
  cor_data,
  var_name   = "Dissolved Oxygen",
  plot_title = "Dissolved Oxygen",
  out_file   = "monthlycorr_DO.png"
)


p_pH <- make_var_plot(
  cor_data,
  var_name   = "pH",
  plot_title = "pH",
  out_file   = "monthlycorr_pH.png"
)


p_temp <- make_var_plot(
  cor_data,
  var_name   = "Temperature",
  plot_title = "Temperature",
  out_file   = "monthlycorr_temp.png"
)


p_pprod <- make_var_plot(
  cor_data,
  var_name   = "Primary Production",
  plot_title = "Primary Production",
  out_file   = "monthlycorr_pp.png"
)

```

```{r}
# same function as above but for the ocean basin indices 
# Make the three plots
p_NPGO <- make_var_plot(
  cor_data,
  var_name   = "NPGO",
  plot_title = "NPGO",
  out_file   = "monthlycorr_NPGO.png"
)


p_pH <- make_var_plot(
  cor_data,
  var_name   = "PDO",
  plot_title = "PDO",
  out_file   = "monthlycorr_PDO.png"
)


p_temp <- make_var_plot(
  cor_data,
  var_name   = "ONI",
  plot_title = "ONI",
  out_file   = "monthlycorr_ONI.png"
)

```


# ROMS output time series - not spatially separated
```{r}
# Create a Date column
monthly_averages_all_year_timeseries <- monthly_averages_all_year %>%
  mutate(
    Month = match(Month, month.abb),  # Convert "Jan" to 1, etc.
    Date = ymd(paste(Year, Month, "01", sep = "-"))
  )

colors <- wes_palette("AsteroidCity1", n = 5)

# Individual plots

p1 <- ggplot(monthly_averages_all_year_timeseries, aes(x = Date, y = DO_avg)) +
  geom_line(color = colors[1], size = 1) +
   geom_ribbon(aes(ymin = DO_avg - DO_sd,
                  ymax = DO_avg + DO_sd),
              fill = colors[1], alpha = 0.3) +
  labs(title = "Dissolved Oxygen", y = "mg/L") +
  theme_bw() +
  theme(axis.title.x = element_blank(),axis.text.x = element_blank(), axis.title = element_text(size = 12),   # Axis titles
        axis.text = element_text(size = 10),
        title = element_text(size = 16))

p2 <- ggplot(monthly_averages_all_year_timeseries, aes(x = Date, y = pH_avg)) +
  geom_line(color = colors[2], size = 1) +
   geom_ribbon(aes(ymin = pH_avg - pH_sd,
                  ymax = pH_avg + pH_sd),
              fill = colors[2], alpha = 0.3) +
  labs(title = "pH", y = "pH") +
  theme_bw() +
  theme(axis.title.x = element_blank(),axis.text.x = element_blank(), axis.title = element_text(size = 12),   # Axis titles
        axis.text = element_text(size = 10),
        title = element_text(size = 16))

p3 <- ggplot(monthly_averages_all_year_timeseries, aes(x = Date, y = Temperature_avg)) +
  geom_line(color = colors[3], size = 1) +
  geom_ribbon(aes(ymin = Temperature_avg - Temperature_sd,
                  ymax = Temperature_avg + Temperature_sd), 
              fill = colors[3], alpha = 0.3) +
  labs(title = "Temperature", y = "°C") +
  theme_bw()+
  theme(axis.title.x = element_blank(),axis.text.x = element_blank(), axis.title = element_text(size = 12),   # Axis titles
        axis.text = element_text(size = 10),
        title = element_text(size = 16))

p4 <- ggplot(monthly_averages_all_year_timeseries, aes(x = Date, y = Chla_avg)) +
  geom_line(color = colors[4], size = 1) +
    geom_ribbon(aes(ymin = Chla_avg - Chla_sd,
                  ymax = Chla_avg + Chla_sd),
              fill = colors[4], alpha = 0.3) +
  labs(title = "Primary Production", y = "mg/m²") +
  theme_bw()+
  theme(axis.title.x = element_blank(),axis.text.x = element_blank(), axis.title = element_text(size = 12),   # Axis titles
        axis.text = element_text(size = 10),
        title = element_text(size = 16))

p5 <- ggplot(monthly_averages_all_year_timeseries, aes(x = Date, y = Vwind_avg)) +
  geom_line(color = colors[5], size = 1) +
  geom_ribbon(aes(ymin = Vwind_avg - Vwind_avg,
                  ymax = Vwind_avg + Vwind_avg),
              fill = colors[5], alpha = 0.3) +
  scale_x_date(date_breaks = "3 years", date_labels = "%Y") +
  labs(title = "Meridional Wind", y = "m/s", x = "Date") +
  theme_bw()+ 
  theme(axis.title = element_text(size = 12),   # Axis titles
        axis.text = element_text(size = 10),
        title = element_text(size = 16))

# Combine with patchwork
p1 / p2 / p3 / p4 / p5 

ggsave("ROMS_historical_timeseries.png", width = 8, height = 10, dpi = 300)

```
# Indicies times series (NPGO,PDO,ONI)
```{r}
summary(combined_monthly_indices_NOT_SPATIAL)

# 1. Create a Date column
combined_monthly_indices_for_plotting_1 <- combined_monthly_indices_NOT_SPATIAL %>%
  mutate(
    Month = match(Month, month.abb),
    Date = ymd(paste(Year, Month, "01", sep = "-"))
  )

# 2. Reshape to long format for ggplot
indices_long <- combined_monthly_indices_for_plotting_1 %>%
  select(Date, PDO = mean_pdo, ONI = oni_avg, NPGO = npgo_avg, "Sea Level Height" = "mean_sl") %>%
  pivot_longer(cols = -Date, names_to = "Index", values_to = "Value")

# 3. Plot with custom color mapping
ggplot(indices_long, aes(x = Date, y = Value, fill = Value > 0)) +
  geom_col(width = 25) +  # bar width adjusts spacing
  scale_fill_manual(values = c("TRUE" = "indianred", "FALSE" = "navy"), guide = "none") +
  facet_wrap(~Index, ncol = 1, scales = "free_y") +
  theme_bw() +
scale_x_date(
  date_breaks = "3 years",
  date_labels = "%Y",
  limits = as.Date(c("1994-01-01", "2018-12-31"))
) +
  labs(title = "",
       x = NULL, y = NULL) +
  theme(
    strip.text = element_text(size = 14, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1, size = 12),
    panel.spacing = unit(0.6, "lines") 
  ) +   
  theme(axis.title = element_text(size = 14),   # Axis titles
              axis.text = element_text(size = 12),
        title = element_text(size = 20))

ggsave("basin_index_timeseries.png", width = 6, height = 6, dpi = 300)
```
```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)

# Build Date & long data (same as yours)
combined_monthly_indices_for_plotting_1 <- combined_monthly_indices_NOT_SPATIAL %>%
  mutate(Month = match(Month, month.abb),
         Date  = ymd(paste(Year, Month, "01", sep = "-")))

indices_long <- combined_monthly_indices_for_plotting_1 %>%
  select(Date, PDO = mean_pdo, ONI = oni_avg, NPGO = npgo_avg, `Sea Level Height` = mean_sl) %>%
  pivot_longer(cols = -Date, names_to = "Index", values_to = "Value")

# Plot: bars for PDO/ONI/NPGO; line for Sea Level Height
ggplot() +
  geom_col(
    data = dplyr::filter(indices_long, Index != "Sea Level Height"),
    aes(x = Date, y = Value, fill = Value > 0),
    width = 25
  ) +
  geom_line(
    data = dplyr::filter(indices_long, Index == "Sea Level Height"),
    aes(x = Date, y = Value),
    linewidth = 0.6
  ) +
  facet_wrap(~Index, ncol = 1, scales = "free_y") +
  scale_fill_manual(values = c("TRUE" = "indianred", "FALSE" = "navy"), guide = "none") +
  theme_bw() +
  scale_x_date(
    date_breaks = "3 years",
    date_labels = "%Y",
    limits = as.Date(c("1994-01-01", "2018-12-31"))
  ) +
  labs(title = "", x = NULL, y = NULL) +
  theme(
    strip.text   = element_text(size = 14, face = "bold"),
    axis.text.x  = element_text(angle = 45, hjust = 1, size = 12),
    panel.spacing = unit(0.6, "lines"),
    axis.title   = element_text(size = 14),
    axis.text    = element_text(size = 12),
    title        = element_text(size = 20)
  )

ggsave("basin_index_timeseries.png", width = 6, height = 6, dpi = 300)

```


# Correlation between DO,pH, and temperature - feb to jul average. FIG 8 and 9 plot and linear regresions
## Fig 8 
```{r}
# spatial colors
colors <- wes_palette("AsteroidCity1", type = "discrete")

spatial_colors <- c("mid" = colors[1], 
                      "north" = colors[4],
                 "south" = colors[3], 
                 "all" = colors[2])


df <- ROMS_CUTI_environmental_combined_all_yr %>% 
  filter(Year > 1994) %>% 
 # filter(region %in% c("all", "mid")) %>% 
  filter(Month %in% c( "Feb", "Mar", "Apr", "May", "Jun", "Jul")) %>% 
  group_by(region, Year) %>%
  summarise(across(
    c(DO_avg, pH_avg, Temperature_avg),
    ~ mean(.x, na.rm = TRUE),
    .names = "mean_{.col}"
  )) %>%
  ungroup()


# 1. Join and prepare
df5 <- df %>% 
  select(Year, mean_DO_avg, mean_pH_avg, mean_Temperature_avg, region)
df6 <- left_join(goph_recruit, df5, by = "Year")


# 2. Pivot and relabel
df_long <- df6 %>%
  pivot_longer(cols = c(mean_DO_avg, mean_pH_avg, mean_Temperature_avg), 
               names_to = "Variable", values_to = "Value") %>%
  filter(!is.na(dev) & !is.na(Value)) %>%
  mutate(Variable = case_when(
    Variable == "mean_DO_avg" ~ "DO",
    Variable == "mean_pH_avg" ~ "pH",
    Variable == "mean_Temperature_avg" ~ "Temperature"
  ))


# 3. Calculate lm stats and join back
lm_stats <- df_long %>%
  group_by(Variable, region) %>%
  do({
    model <- lm(dev ~ Value, data = .)
    glance_mod <- glance(model)
    tidy_mod <- tidy(model)
    tibble(
      r_squared = glance_mod$r.squared,
      p_value   = tidy_mod$p.value[2]
    )
  }) %>%
  ungroup()

# Join r² and p-values into plotting data frame
df_plot <- df_long %>%
  left_join(lm_stats, by = "Variable", "region")

# DO plot
df_do <- df_long %>% filter(Variable == "DO")

plot_do <- ggplot(df_do, aes(x = Value, y = dev, color = region)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE,linewidth = 1) +
  labs(x = "DO (mg/L)", y = "Recruitment Deviation", title = "Dissolved Oxygen") +
  theme_bw() +
  scale_color_manual(values = spatial_colors, name = "Region") +
  larger_axis_theme

plot_do

# pH plot
df_ph <- df_long %>% filter(Variable == "pH")

plot_ph <- ggplot(df_ph, aes(x = Value, y = dev, color = region)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE,linewidth = 1) +
  labs(x = "pH", y = "", title = "pH") +
  theme_bw() +
  scale_color_manual(values = spatial_colors, name = "Region") +
  larger_axis_theme


# Temperature plot
df_temp <- df_long %>% filter(Variable == "Temperature")

plot_temp <- ggplot(df_temp, aes(x = Value, y = dev, color = region)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE,linewidth = 1) +
  labs(x = "Temperature (°C)", y = "", title = "Temperature") +
  theme_bw() +
  scale_color_manual(values = spatial_colors, name = "Region") +
  larger_axis_theme


# Combine
combined_plot <- plot_do + plot_ph + plot_temp + 
  plot_layout(ncol = 3, guides = "collect") & 
  theme(axis.title.y = element_text(size = 14)) + theme(legend.position = "bottom") 

combined_plot

ggsave("ROMS_feb_to_jul_regressions.png", width = 10, height = 5, dpi = 300)


# Extract R² and p-values from each lm by Variable and region
lm_summary <- df_long %>%
  group_by(Variable, region) %>%
  do({
    model <- lm(dev ~ Value, data = .)
    glance_mod <- broom::glance(model)
    tidy_mod <- broom::tidy(model)
    tibble(
      Variable = unique(.$Variable),
      region = unique(.$region),
      r_squared = glance_mod$r.squared,
      p_value = tidy_mod$p.value[2]
    )
  }) %>%
  ungroup()

# Arrange for clarity
lm_summary <- lm_summary %>%
  arrange(Variable, region)

# View results
print(lm_summary)
```

## Fig 9
```{r}
library(broom)
library(purrr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(patchwork)

# shapes and colors
shape_vals <- c("DO" = 16, "pH" = 17, "Temperature" = 15)
linetype_vals <- c("DO" = "solid", "pH" = "dashed", "Temperature" = "dotdash")

# raw series
raw_dev <- df_long %>%
  distinct(Year, dev) %>%
  arrange(Year)

# fit models and predict
lm_preds <- df_long %>%
  group_by(region, Variable) %>%
  nest() %>%
  mutate(
    model = map(data, ~ lm(dev ~ Value, data = .x)),
    aug   = map2(model, data, ~ augment(.x, newdata = .y, se_fit = TRUE))
  ) %>%
  unnest(aug) %>%
  mutate(
    pred_lo = .fitted - 1.96 * .se.fit,
    pred_hi = .fitted + 1.96 * .se.fit
  ) %>%
  ungroup()

# helper for one variable
make_plot <- function(var_label, xlab = "Year") {
  ggplot() +
    geom_hline(yintercept = 0, linetype = "dashed") +
    geom_line(data = raw_dev, aes(Year, dev), color = "black", linewidth = 0.9) +
    geom_point(data = raw_dev, aes(Year, dev), color = "black", size = 2) +
    geom_ribbon(
      data = filter(lm_preds, Variable == var_label),
      aes(x = Year, ymin = pred_lo, ymax = pred_hi, fill = region),
      alpha = 0.18
    ) +
    geom_line(
      data = filter(lm_preds, Variable == var_label),
      aes(x = Year, y = .fitted, color = region, group = region),
      linewidth = 1
    ) +
    geom_point(
      data = filter(lm_preds, Variable == var_label),
      aes(x = Year, y = .fitted, color = region),
      size = 2
    ) +
    scale_color_manual(values = spatial_colors, name = "Region") +
    scale_fill_manual(values  = spatial_colors, name = "Region") +
    scale_shape_manual(values = shape_vals, name = "Variable") +
    labs(x = xlab, y = "Recruitment Deviation", title = var_label) +
    theme_bw() +
    theme(legend.position = "bottom") +
    larger_axis_theme
}

# create plots
plot_DO <- make_plot("DO")
plot_pH <- make_plot("pH")
plot_Temp <- make_plot("Temperature")

# combine
combined_plot <- plot_DO + plot_pH + plot_Temp +
  plot_layout(ncol = 3, guides = "collect") &
  theme(legend.position = "bottom")

combined_plot

```






# Correlation between DO,pH, and temperature - march only. FIG 8 and 9 plot and linear regresions
## Fig 8 
```{r}
# spatial colors
colors <- wes_palette("AsteroidCity1", type = "discrete")

spatial_colors <- c("mid" = colors[1], 
                      "north" = colors[4],
                 "south" = colors[3], 
                 "all" = colors[2])


df <- ROMS_CUTI_environmental_combined_all_yr %>% 
  filter(Year > 1994) %>% 
 # filter(region %in% c("all", "mid")) %>% 
  filter(Month %in% c("Mar")) %>% 
  group_by(region, Year) %>%
  summarise(across(
    c(DO_avg, pH_avg, Temperature_avg),
    ~ mean(.x, na.rm = TRUE),
    .names = "mean_{.col}"
  )) %>%
  ungroup()


# 1. Join and prepare
df5 <- df %>% 
  select(Year, mean_DO_avg, mean_pH_avg, mean_Temperature_avg, region)
df6 <- left_join(goph_recruit, df5, by = "Year")


# 2. Pivot and relabel
df_long <- df6 %>%
  pivot_longer(cols = c(mean_DO_avg, mean_pH_avg, mean_Temperature_avg), 
               names_to = "Variable", values_to = "Value") %>%
  filter(!is.na(dev) & !is.na(Value)) %>%
  mutate(Variable = case_when(
    Variable == "mean_DO_avg" ~ "DO",
    Variable == "mean_pH_avg" ~ "pH",
    Variable == "mean_Temperature_avg" ~ "Temperature"
  ))


# 3. Calculate lm stats and join back
lm_stats <- df_long %>%
  group_by(Variable, region) %>%
  do({
    model <- lm(dev ~ Value, data = .)
    glance_mod <- glance(model)
    tidy_mod <- tidy(model)
    tibble(
      r_squared = glance_mod$r.squared,
      p_value   = tidy_mod$p.value[2]
    )
  }) %>%
  ungroup()

# Join r² and p-values into plotting data frame
df_plot <- df_long %>%
  left_join(lm_stats, by = "Variable", "region")

# DO plot
df_do <- df_long %>% filter(Variable == "DO")

plot_do <- ggplot(df_do, aes(x = Value, y = dev, color = region)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE,linewidth = 1) +
  labs(x = "DO (mg/L)", y = "Recruitment Deviation", title = "Dissolved Oxygen") +
  theme_bw() +
  scale_color_manual(values = spatial_colors, name = "Region") +
  larger_axis_theme

plot_do

# pH plot
df_ph <- df_long %>% filter(Variable == "pH")

plot_ph <- ggplot(df_ph, aes(x = Value, y = dev, color = region)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE,linewidth = 1) +
  labs(x = "pH", y = "", title = "pH") +
  theme_bw() +
  scale_color_manual(values = spatial_colors, name = "Region") +
  larger_axis_theme


# Temperature plot
df_temp <- df_long %>% filter(Variable == "Temperature")

plot_temp <- ggplot(df_temp, aes(x = Value, y = dev, color = region)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE,linewidth = 1) +
  labs(x = "Temperature (°C)", y = "", title = "Temperature") +
  theme_bw() +
  scale_color_manual(values = spatial_colors, name = "Region") +
  larger_axis_theme


# Combine
combined_plot <- plot_do + plot_ph + plot_temp + 
  plot_layout(ncol = 3, guides = "collect") & 
  theme(axis.title.y = element_text(size = 14)) + theme(legend.position = "bottom") 

combined_plot

ggsave("ROMS_march_regressions.png", width = 10, height = 5, dpi = 300)


# Extract R² and p-values from each lm by Variable and region
lm_summary <- df_long %>%
  group_by(Variable, region) %>%
  do({
    model <- lm(dev ~ Value, data = .)
    glance_mod <- broom::glance(model)
    tidy_mod <- broom::tidy(model)
    tibble(
      Variable = unique(.$Variable),
      region = unique(.$region),
      r_squared = glance_mod$r.squared,
      p_value = tidy_mod$p.value[2]
    )
  }) %>%
  ungroup()

# Arrange for clarity
lm_summary <- lm_summary %>%
  arrange(Variable, region)

# View results
print(lm_summary)
```

## Fig 9
```{r}
library(broom)
library(purrr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(patchwork)

# shapes and colors
shape_vals <- c("DO" = 16, "pH" = 17, "Temperature" = 15)
linetype_vals <- c("DO" = "solid", "pH" = "dashed", "Temperature" = "dotdash")

# raw series
raw_dev <- df_long %>%
  distinct(Year, dev) %>%
  arrange(Year)

# fit models and predict
lm_preds <- df_long %>%
  group_by(region, Variable) %>%
  nest() %>%
  mutate(
    model = map(data, ~ lm(dev ~ Value, data = .x)),
    aug   = map2(model, data, ~ augment(.x, newdata = .y, se_fit = TRUE))
  ) %>%
  unnest(aug) %>%
  mutate(
    pred_lo = .fitted - 1.96 * .se.fit,
    pred_hi = .fitted + 1.96 * .se.fit
  ) %>%
  ungroup()

# helper for one variable
make_plot <- function(var_label, xlab = "Year") {
  ggplot() +
    geom_hline(yintercept = 0, linetype = "dashed") +
    geom_line(data = raw_dev, aes(Year, dev), color = "black", linewidth = 0.9) +
    geom_point(data = raw_dev, aes(Year, dev), color = "black", size = 2) +
    geom_ribbon(
      data = filter(lm_preds, Variable == var_label),
      aes(x = Year, ymin = pred_lo, ymax = pred_hi, fill = region),
      alpha = 0.18
    ) +
    geom_line(
      data = filter(lm_preds, Variable == var_label),
      aes(x = Year, y = .fitted, color = region, group = region),
      linewidth = 1
    ) +
    geom_point(
      data = filter(lm_preds, Variable == var_label),
      aes(x = Year, y = .fitted, color = region),
      size = 2
    ) +
    scale_color_manual(values = spatial_colors, name = "Region") +
    scale_fill_manual(values  = spatial_colors, name = "Region") +
    scale_shape_manual(values = shape_vals, name = "Variable") +
    labs(x = xlab, y = "Recruitment Deviation", title = var_label) +
    theme_bw() +
    theme(legend.position = "bottom") +
    larger_axis_theme
}

# create plots
plot_DO <- make_plot("DO")
plot_pH <- make_plot("pH")
plot_Temp <- make_plot("Temperature")

# combine
combined_plot <- plot_DO + plot_pH + plot_Temp +
  plot_layout(ncol = 3, guides = "collect") &
  theme(legend.position = "bottom")

combined_plot

```






# Correlation between PDO and temperature, pH, and DO (supplemental)
```{r}
# Fit linear models
model_ph <- lm(mean_pdo ~ pH_avg, data = ROMS_environmental_combined_mar_only)
model_do <- lm(mean_pdo ~ DO_avg, data = ROMS_environmental_combined_mar_only)
model_temp <- lm(mean_pdo ~ Temperature_avg, data = ROMS_environmental_combined_mar_only)

# Extract p-values and R-squared
get_model_info <- function(model) {
  summary_model <- summary(model)
  r2 <- round(summary_model$r.squared, 2)
  pval <- signif(summary_model$coefficients[2, 4], 2)
  list(r2 = r2, pval = pval)
}

info_ph <- get_model_info(model_ph)
info_do <- get_model_info(model_do)
info_temp <- get_model_info(model_temp)

# Define base theme
base_theme <- theme_classic(base_size = 14) +
  theme(
    axis.title = element_text(),
    axis.text = element_text(color = "black"),
    panel.border = element_rect(color = "black", fill = NA, size = 1),
    plot.title = element_text(hjust = 0.5)
  )

# Plot 1: pH vs. PDO
p1 <- ggplot(ROMS_environmental_combined_mar_only, aes(x = pH_avg, y = mean_pdo)) +
  geom_point(size = 3, shape = 21, fill = "grey30") +
  geom_smooth(method = "lm", se = FALSE, size = 1.2, color = "black") +
  annotate("text", x = Inf, y = Inf, label = paste0("p = ", info_ph$pval),
           hjust = 1.1, vjust = 1.5, size = 5, fontface = "italic") +
  labs(
    x = 'pH',
    y = "PDO",
    title = ""
  ) +
  base_theme

# Plot 2: DO vs. PDO
p2 <- ggplot(ROMS_environmental_combined_mar_only, aes(x = DO_avg, y = mean_pdo)) +
  geom_point(size = 3, shape = 21, fill = "grey30") +
  geom_smooth(method = "lm", se = FALSE, size = 1.2, color = "black") +
  annotate("text", x = Inf, y = Inf, label = paste0("p = ", info_do$pval),
           hjust = 1.1, vjust = 1.5, size = 5, fontface = "italic") +
  labs(
    x = "Dissolved Oxygen (mg/L)",
    y = NULL,
    title = ""
  ) +
  base_theme +
  theme(axis.title.y = element_blank())

# Plot 3: Temperature vs. PDO
p3 <- ggplot(ROMS_environmental_combined_mar_only, aes(x = Temperature_avg, y = mean_pdo)) +
  geom_point(size = 3, shape = 21, fill = "grey30") +
  geom_smooth(method = "lm", se = FALSE, size = 1.2, color = "black") +
  annotate("text", x = Inf, y = Inf, label = paste0("p > 0.001"),
           hjust = 1.1, vjust = 1.5, size = 5, fontface = "italic") +
  labs(
    x = "Temperature (°C)",
    y = NULL,
    title = ""
  ) +
  base_theme +
  theme(axis.title.y = element_blank())

# Combine with patchwork
(p1 | p2 | p3) +
  plot_annotation(
    theme = theme(plot.title = element_text(size = 16, face = "bold", hjust = 0.5))
  )

ggsave("PDO_ROMS_correlation.png", width = 8, height = 4, dpi = 300, bg = "white")

```

```{r}
ROMS_environmental_combined_mar_only

ggplot(ROMS_environmental_combined_mar_only, aes(x = pH_avg, y = mean_pdo)) +
  geom_point()+
  geom_smooth(method = "lm", se = FALSE, size = 1.5)

ggplot(ROMS_environmental_combined_mar_only, aes(x = DO_avg, y = mean_pdo)) +
  geom_point()+
  geom_smooth(method = "lm", se = FALSE, size = 1.5)

ggplot(ROMS_environmental_combined_mar_only, aes(x = Temperature_avg, y = mean_pdo)) +
  geom_point()+
  geom_smooth(method = "lm", se = FALSE, size = 1.5)
```


# Exploring rolling averages for pH, DO, and temperautre 
```{r}

# --- 1. prepare data ---
df_env <- ROMS_output_monthly_NMSA %>%
  filter(Year > 1994) %>%
  group_by(region, Year, Month) %>%
  summarise(across(
    c(DO_avg, pH_avg, Temperature_avg),
    ~ mean(.x, na.rm = TRUE),
    .names = "mean_{.col}"
  ), .groups = "drop")

df_env_joined <- left_join(df_env, goph_recruit, by = "Year") %>%
  filter(Month %in% c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"))

df_long <- df_env_joined %>%
  pivot_longer(
    cols = starts_with("mean_"),
    names_to = "Variable",
    values_to = "Value"
  ) %>%
  mutate(Variable = case_when(
    Variable == "mean_DO_avg" ~ "DO",
    Variable == "mean_pH_avg" ~ "pH",
    Variable == "mean_Temperature_avg" ~ "Temperature"
  ))

month_order <- c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")
df_long <- df_long %>% mutate(Month_num = match(Month, month_order))

# --- 2. rolling windows ---
df_long_roll <- df_long %>%
  arrange(region, Variable, Year, Month_num) %>%
  group_by(region, Variable) %>%
  mutate(
    roll3 = rollapply(Value, 3, mean, align = "right", fill = NA, na.rm = TRUE),
    roll6 = rollapply(Value, 6, mean, align = "right", fill = NA, na.rm = TRUE)
  ) %>%
  ungroup()

# --- helper for extracting stats ---
get_lm_stats <- function(data) {
  model <- tryCatch(lm(dev ~ Value, data = data), error = function(e) NULL)
  if (is.null(model)) return(tibble(r_squared = NA, p_value = NA))
  g <- glance(model)
  t <- tidy(model)
  tibble(r_squared = g$r.squared, p_value = t$p.value[2])
}

# --- 3. single-month models ---
lm_month <- df_long_roll %>%
  group_by(region, Variable, Month) %>%
  nest() %>%
  mutate(stats = map(data, get_lm_stats)) %>%
  unnest(stats) %>%
  mutate(window = "single_month")

# --- 4. rolling 3-month models ---
lm_roll3 <- df_long_roll %>%
  group_by(region, Variable, Month) %>%
  nest() %>%
  mutate(stats = map(data, ~ {
    dat <- .x %>% filter(!is.na(roll3)) %>% mutate(Value = roll3)
    get_lm_stats(dat)
  })) %>%
  unnest(stats) %>%
  mutate(window = "3_month")

# --- 5. rolling 6-month models ---
lm_roll6 <- df_long_roll %>%
  group_by(region, Variable, Month) %>%
  nest() %>%
  mutate(stats = map(data, ~ {
    dat <- .x %>% filter(!is.na(roll6)) %>% mutate(Value = roll6)
    get_lm_stats(dat)
  })) %>%
  unnest(stats) %>%
  mutate(window = "6_month")

# --- 6. combine all results ---
lm_all <- bind_rows(lm_month, lm_roll3, lm_roll6) %>%
  select(region, Variable, window, Month, r_squared, p_value) %>%
  arrange(Variable, region, window, Month)

# --- 7. inspect results ---
print(lm_all)

```

```{r}
# Ensure months are in correct order
month_levels <- c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")

lm_all <- lm_all %>%
  mutate(Month = factor(Month, levels = month_levels))

# --- R² heatmap ---
heat_r2 <- ggplot(lm_all, aes(x = region, y = Month, fill = r_squared)) +
  geom_tile(color = "white") +
  facet_grid(Variable ~ window) +
  scale_fill_viridis_c(option = "C", name = expression(r^2)) +
  labs(
    title = "",
    x = "Region", y = "Month"
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid = element_blank(),
    strip.background = element_rect(fill = "grey90", color = NA),
    strip.text = element_text(face = "bold")
  )

heat_r2
```

```{r}
# make sure Month is in correct chronological order
month_levels <- c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")
lm_all <- lm_all %>%
  mutate(Month = factor(Month, levels = month_levels))

# mask out non-significant results (p >= 0.05)
lm_sig <- lm_all %>%
  mutate(r_squared_sig = ifelse(p_value < 0.05, r_squared, NA))

lm_sig <- lm_sig %>%
  mutate(
    window = case_when(
      window == "single_month" ~ "Single",
      window == "3_month" ~ "3 month",
      window == "6_month" ~ "6 month",
      TRUE ~ window
    ),
    label = paste0(window, " (", Month, ")")
  ) %>% 
  filter(!window == "6 month")

# plot
heat_r2_sig <- ggplot(subset, aes(x = Month, y = region, fill = r_squared_sig)) +
  geom_tile(color = "grey90", linewidth = 0.3, na.rm = FALSE) +
  facet_grid(window ~ Variable) +
  scale_fill_viridis_c(option = "mako", name = expression(r^2),
                        na.value = "white", direction = -1) +
  labs(
    title = expression(""),
    x = "Month",
    y = ""
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_blank(),
    panel.grid = element_blank(),
    strip.text = element_text(size = 12, face = "bold")
  )

heat_r2_sig

ggsave("heat_r2_sig_all.png", width = 12, height = 4, dpi = 300)
```
## subset for WSN
```{r}
subset <- lm_sig %>% 
  filter(Month %in% c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug")) %>% 
  filter(region == "all")

# DO
heat_r2_sig_do <- subset %>%
  filter(Variable == "DO") %>%
  ggplot(aes(x = Month, y = region, fill = r_squared_sig)) +
  geom_tile(color = "grey90", linewidth = 0.3, na.rm = FALSE) +
  # Add X's where r_squared_sig is NA
  geom_text(
    data = subset(subset, Variable == "DO" & is.na(r_squared_sig)),
    aes(label = "n.s."),
    color = "grey40", size = 4
  ) +
  facet_grid(window ~ .) +
  scale_fill_viridis_c(option = "mako", name = expression(r^2), na.value = "white", direction = -1) +
  labs(title = "Dissolved Oxygen (DO)", x = "Month", y = "") +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_blank(),
    panel.grid = element_blank(),
    strip.text = element_text(size = 12, face = "bold")
  )
heat_r2_sig_do

ggsave("heat_r2_sig_do.png", width = 8, height = 4, dpi = 300)

# pH
heat_r2_sig_ph <- subset %>%
  filter(Variable == "pH") %>%
  ggplot(aes(x = Month, y = region, fill = r_squared_sig)) +
  geom_tile(color = "grey90", linewidth = 0.3, na.rm = FALSE) +
  facet_grid(window ~ .) +
  scale_fill_viridis_c(option = "mako", name = expression(r^2), na.value = "white", direction = -1) +
  labs(title = "pH", x = "Month", y = "") +
  theme_bw() +
  geom_text(
  data = subset(subset, Variable == "pH" & is.na(r_squared_sig)),
  aes(label = "n.s."),
  color = "grey40", size = 4
) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_blank(),
    panel.grid = element_blank(),
    strip.text = element_text(size = 12, face = "bold")
  )

heat_r2_sig_ph
ggsave("heat_r2_sig_pH.png", width = 8, height = 4, dpi = 300)

# Temperature
heat_r2_sig_temp <- subset %>%
  filter(Variable == "Temperature") %>%
  ggplot(aes(x = Month, y = region, fill = r_squared_sig)) +
  geom_tile(color = "grey90", linewidth = 0.3, na.rm = FALSE) +
  facet_grid(window ~ .) +
  scale_fill_viridis_c(option = "mako", name = expression(r^2), na.value = "white", direction = -1) +
  labs(title = "Temperature", x = "Month", y = "") +
  theme_bw() +
  geom_text(
  data = subset(subset, Variable == "Temperature" & is.na(r_squared_sig)),
  aes(label = "n.s."),
  color = "grey40", size = 4
  )+
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
      axis.text.y = element_blank(),
    panel.grid = element_blank(),
    strip.text = element_text(size = 12, face = "bold")
  )

heat_r2_sig_temp
ggsave("heat_r2_sig_temp.png", width = 8, height = 4, dpi = 300)


subset_TEMP <- df_env_joined %>% 
  select(mean_Temperature_avg, Year, Month, region, dev) %>% 
  filter(Month == "Mar") %>% 
  filter(region == "all")

linear_graph_wsn <- ggplot(aes(x=mean_Temperature_avg, y = dev), data = subset_TEMP) +
  geom_point() +
  geom_smooth(method = "lm", color = "black")+  
  geom_text(aes(x = mean_Temperature_avg, label = Year), size = 4, vjust = -0.5)+
  labs(
    x = "Temperature (°C)",
    y = "Recruitment deviations"
  ) +
  theme_classic()+
  larger_axis_theme

  

linear_graph_wsn
ggsave("linear_graph_wsn_temp.png", width = 5, height = 5, dpi = 300)

```

```{r}
library(dplyr)
library(ggplot2)
library(patchwork)

# Function to build each plot with consistent scaling
make_heat_plot <- function(data, var_name, title) {
  ggplot(
    data = data %>% filter(Variable == var_name),
    aes(x = Month, y = region, fill = r_squared_sig)
  ) +
    geom_tile(color = "grey90", linewidth = 0.3, na.rm = FALSE) +
    # add X where r_squared_sig is NA
    geom_text(
      data = subset(data, Variable == var_name & is.na(r_squared_sig)),
      aes(label = "×"),
      color = "grey30", size = 4
    ) +
    facet_grid(window ~ .) +
    scale_fill_viridis_c(
      option = "mako",
      name = expression(r^2),
      limits = c(0.15, 0.3),
      na.value = "white"
    ) +
    labs(title = title, x = "Month", y = "Region") +
    theme_bw() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      panel.grid = element_blank(),
      strip.text = element_text(size = 12, face = "bold"),
      plot.title = element_text(size = 14, face = "bold", hjust = 0.5)
    )
}

# Build each plot
heat_r2_sig_do   <- make_heat_plot(lm_sig, "DO",   "Dissolved Oxygen")
heat_r2_sig_ph   <- make_heat_plot(lm_sig, "pH",   "pH")
heat_r2_sig_temp <- make_heat_plot(lm_sig, "Temperature", "Temperature")

heat_r2_sig_do
ggsave("heat_r2_sig_do.png", width = 10, height = 4, dpi = 300)

heat_r2_sig_ph
ggsave("heat_r2_sig_ph.png", width = 10, height = 4, dpi = 300)

heat_r2_sig_temp 
ggsave("heat_r2_sig_temp.png", width = 10, height = 4, dpi = 300)
```


```{r}
# this is the figure that selected best r sqaure value

# month order + helper
month_levels <- c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")

month_range_label <- function(end_month, k) {
  idx <- match(end_month, month_levels)
  start_idx <- ((idx - (k - 1) - 1) %% 12) + 1  # wrap across year if needed
  paste0(month_levels[start_idx], " - ", month_levels[idx])
}


# find the single row with the max R² per region × variable
best_r2 <- lm_all %>%
  group_by(region, Variable) %>%
  slice_max(order_by = r_squared, n = 1, with_ties = FALSE) %>%
  ungroup() %>%
  arrange(Variable, region)

print(best_r2)


# add a display label just for the graph text
best_r2 <- best_r2 %>%
  mutate(
    Month_chr = as.character(Month),
    label_display = case_when(
      window %in% c("3_month", "3 month avg") ~ month_range_label(Month_chr, 3),
      window %in% c("6_month", "6 month avg") ~ month_range_label(Month_chr, 6),
      TRUE ~ Month_chr
    )
  )

win_shapes <- c("Single month" = 16, "3 month avg" = 17, "6 month avg" = 15)

p_best_pts <- ggplot(best_r2,
                     aes(x = region, y = r_squared, color = region)) +
  geom_point(size = 3) +
  geom_text(aes(label = label_display), nudge_y = 0.002, nudge_x = -.25, size = 3.5) +
  facet_wrap(~ Variable, nrow = 1, scales = "free_y") +
  scale_color_manual(values = spatial_colors, name = "Region") +
  scale_shape_manual(values = win_shapes, name = "Window") +
  labs(
    y = expression(R^2)
  ) +
  theme_bw() +
  larger_axis_theme +
  theme(
    legend.position = "bottom",
    axis.title.x = element_blank(),
    axis.text.x  = element_blank(),
    axis.ticks.x = element_blank(),
    panel.grid.minor = element_blank(),
    strip.text = element_text(size = 14, face = "bold")
  ) 

p_best_pts
```

```{r}
# this code combinds heat map and dot plot of best r squares
heat_r2_sig + p_best_pts

# combine
combined_plot <- heat_r2_sig + p_best_pts  +
  plot_layout(ncol = 1) &
  theme(legend.position = "right")
combined_plot

ggsave("ROMS_historical_linear_reg.png", width = 10, height = 8, dpi = 300)

```

## predictive historical time series 
```{r}
library(dplyr)
library(ggplot2)
library(patchwork)

# Raw recruitment series (optional overlay)
raw_dev <- goph_recruit %>%
  distinct(Year, dev) %>%
  arrange(Year)

# Helper: make one panel per variable
make_best_panel <- function(var_label) {
  ggplot() +
    geom_hline(yintercept = 0, linetype = "dashed") +
    # raw recruitment deviation
    geom_point(data = raw_dev, aes(Year, dev), color = "black", size = 2) +
    geom_line(data = raw_dev, aes(Year, dev), color = "black", linetype = "dashed") +
    # best-model predictions for this variable (by region)
    geom_ribbon(
      data = dplyr::filter(preds, Variable == var_label),
      aes(x = Year, ymin = pred_lo, ymax = pred_hi, fill = region, group = region),
      alpha = 0.15
    ) +
    geom_line(
      data = dplyr::filter(preds, Variable == var_label),
      aes(x = Year, y = .fitted, color = region, group = region),
      linewidth = 1
    ) +
    geom_point(
      data = dplyr::filter(preds, Variable == var_label),
      aes(x = Year, y = .fitted, color = region),
      size = 2
    ) +
    scale_color_manual(values = spatial_colors, name = "Region") +
    scale_fill_manual(values  = spatial_colors, name = "Region") +
    labs(
      title = var_label,
      x = "Year", y = "Recruitment deviation",
    ) +
    theme_bw() +
    theme(legend.position = "bottom") +
    larger_axis_theme
}

# Build the three plots
p_DO  <- make_best_panel("DO")
p_pH  <- make_best_panel("pH")
p_Tmp <- make_best_panel("Temperature")

# Option A: show separately
p_DO; p_pH; p_Tmp

# Option B: arrange together (e.g., vertical stack)

(p_DO + p_pH + p_Tmp)  / p_best_pts 

ggsave("ROMS_historical_linear_reg_timeseries.png", width = 10, height = 8, dpi = 300)

```

```{r}
library(dplyr)
library(tidyr)
library(zoo)
library(purrr)
library(broom)

# 0) helpers
month_levels <- c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")

pick_predictor <- function(df, win_key) {
  if (win_key == "single_month")      dplyr::mutate(df, pred_x = Value)
  else if (win_key == "3_month")      dplyr::mutate(df, pred_x = roll3)
  else if (win_key == "6_month")      dplyr::mutate(df, pred_x = roll6)
  else stop("Unknown window key: ", win_key)
}

# 1) Monthly env (compute rolls BEFORE any month filtering)
df_env_full <- ROMS_output_monthly_NMSA %>%
  filter(Year > 1994) %>%
  group_by(region, Year, Month) %>%
  summarise(across(c(DO_avg, pH_avg, Temperature_avg),
                   ~ mean(.x, na.rm = TRUE), .names = "mean_{.col}"),
            .groups = "drop")

df_env_long <- df_env_full %>%
  pivot_longer(starts_with("mean_"),
               names_to = "Variable", values_to = "Value") %>%
  mutate(Variable = gsub("^mean_|_avg$", "", as.character(Variable))) %>% 
  left_join(goph_recruit, by = "Year") %>%
  mutate(Month_num = match(Month, month_levels)) %>%
  arrange(region, Variable, Year, Month_num) %>%
  group_by(region, Variable) %>%
  mutate(
    roll3 = zoo::rollapply(Value, 3, mean, align = "right", fill = NA),
    roll6 = zoo::rollapply(Value, 6, mean, align = "right", fill = NA)
  ) %>%
  ungroup()

# 2) Canonicalize best windows/months (from your best_r2 table)
best_r2_use <- best_r2 %>%
  mutate(
    Month = as.character(Month),
    window_key = case_when(
      window %in% c("single_month", "Single month") ~ "single_month",
      window %in% c("3_month", "3 month avg")       ~ "3_month",
      window %in% c("6_month", "6 month avg")       ~ "6_month",
      TRUE ~ as.character(window)
    )
  )

# 3) Build predictions for each Region × Variable using its best window/month
preds <- best_r2_use %>%
  group_split(region, Variable) %>%
  map_dfr(function(br) {
    r  <- br$region[1]; v <- br$Variable[1]
    m  <- br$Month[1];  wk <- br$window_key[1]

    dat <- df_env_long %>%
      filter(region == r, Variable == v, Month == m) %>%
      pick_predictor(wk) %>%
      filter(!is.na(pred_x), !is.na(dev))

    if (nrow(dat) < 3) return(tibble())  # guard against empty fits

    fit <- lm(dev ~ pred_x, data = dat)
    aug <- augment(fit, newdata = dat, se_fit = TRUE)

    dat %>%
      select(region, Variable, Year, dev) %>%
      bind_cols(aug %>% select(.fitted, .se.fit)) %>%
      mutate(pred_lo = .fitted - 1.96 * .se.fit,
             pred_hi = .fitted + 1.96 * .se.fit)
  })

# (optional) persist so you don’t lose it again
# saveRDS(preds, "preds_best_models.rds")

p_DO  <- make_best_panel("DO")
p_pH  <- make_best_panel("pH")
p_Tmp <- make_best_panel("Temperature")

# arrange together
(p_DO / p_pH / p_Tmp) + plot_layout(guides = "collect") &
  theme(legend.position = "bottom")
```

## quantifying preditive power of models 
```{r}
library(dplyr)
rsq <- function(obs, pred) if (length(obs) > 1) 1 - sum((obs-pred)^2)/sum((obs-mean(obs))^2) else NA_real_

# 1) Split by sign of observed dev
by_sign <- preds %>%
  mutate(sign = if_else(dev < 0, "neg", "pos"),
         abs_err = abs(dev - .fitted),
         sq_err  = (dev - .fitted)^2) %>%
  group_by(region, Variable, sign) %>%
  summarise(
    n     = dplyr::n(),
    MAE   = mean(abs_err, na.rm = TRUE),
    RMSE  = sqrt(mean(sq_err, na.rm = TRUE)),
    R2    = rsq(dev, .fitted),
    .groups = "drop"
  ) %>%
  tidyr::pivot_wider(names_from = sign, values_from = c(n, MAE, RMSE, R2),
                     names_sep = "_")

# 2) Sign classification skill (predict negative if fitted < 0)
class_skill <- preds %>%
  transmute(region, Variable,
            true_neg = dev < 0,
            pred_neg = .fitted < 0) %>%
  group_by(region, Variable) %>%
  summarise(
    TP = sum(pred_neg &  true_neg),
    FP = sum(pred_neg & !true_neg),
    TN = sum(!pred_neg & !true_neg),
    FN = sum(!pred_neg &  true_neg),
    sensitivity_neg = TP / (TP + FN),  # recall for negative years
    specificity_pos = TN / (TN + FP),  # correctly identify positives
    precision_neg   = TP / (TP + FP),
    F1_neg = ifelse((precision_neg + sensitivity_neg) > 0,
                    2 * precision_neg * sensitivity_neg / (precision_neg + sensitivity_neg), NA_real_),
    balanced_acc = (sensitivity_neg + specificity_pos) / 2,
    .groups = "drop"
  )

# 3) Merge a compact table: lower error/higher skill on "neg" supports your statement
summary_sign_perf <- dplyr::left_join(by_sign, class_skill,
                                      by = c("region","Variable"))

summary_sign_perf

by_sign_rmse <- by_sign %>%   # this is your table
  mutate(
    delta_RMSE = RMSE_pos - RMSE_neg,         # >0 means “better for negative years”
    ratio_RMSE = RMSE_neg / RMSE_pos,         # <1 means “better for negative years”
    rel_improve = delta_RMSE / RMSE_pos       # % improvement when focusing on negatives
  ) %>%
  arrange(Variable, region)

by_sign_rmse

# printable CSV for thesis 
table_out <- by_sign %>%
  dplyr::select(region, Variable, n_pos, n_neg, RMSE_neg, RMSE_pos) %>%
  dplyr::arrange(Variable, region)

# (optional) round RMSEs
table_out <- table_out %>% dplyr::mutate(dplyr::across(starts_with("RMSE"), ~round(.x, 3)))

write.csv(table_out, "rmse_by_sign.csv", row.names = FALSE)
```

# extracting for the projections
```{r}
library(dplyr)
library(purrr)
library(broom)

# Make sure best_r2 has the canonical window key
best_r2_use <- best_r2 %>%
  mutate(
    window_key = case_when(
      window %in% c("single_month", "Single month") ~ "single_month",
      window %in% c("3_month", "3 month avg")       ~ "3_month",
      window %in% c("6_month", "6 month avg")       ~ "6_month",
      TRUE ~ as.character(window)
    ),
    Month = as.character(Month)
  )

pick_predictor <- function(df, win_key) {
  if (win_key == "single_month") df %>% mutate(pred_x = Value)
  else if (win_key == "3_month") df %>% mutate(pred_x = roll3)
  else if (win_key == "6_month") df %>% mutate(pred_x = roll6)
  else stop("Unknown window key: ", win_key)
}

# Build the training rows (yearly, end-month only) for each best model,
# fit lm(dev ~ pred_x), and extract coefficients & fit stats
best_model_coefs <- best_r2_use %>%
  group_split(region, Variable) %>%
  map_dfr(function(br) {
    r  <- br$region[1]
    v  <- br$Variable[1]
    m  <- br$Month[1]
    wk <- br$window_key[1]

    dat <- df_env_long %>%
      filter(region == r, Variable == v, Month == m) %>%
      pick_predictor(wk) %>%
      filter(!is.na(pred_x), !is.na(dev)) %>%
      select(region, Variable, Year, Month, pred_x, dev)

    mdl <- lm(dev ~ pred_x, data = dat)
    tg  <- tidy(mdl)
    gg  <- glance(mdl)

    tibble(
      region   = r,
      Variable = v,
      window   = wk,
      end_month = m,
      intercept = tg$estimate[tg$term == "(Intercept)"],
      slope     = tg$estimate[tg$term == "pred_x"],
      r_squared = gg$r.squared,
      p_value   = tg$p.value[tg$term == "pred_x"],
      sigma     = gg$sigma,
      n         = gg$df.residual + 2L,
      year_min  = min(dat$Year, na.rm = TRUE),
      year_max  = max(dat$Year, na.rm = TRUE)
    )
  })

best_model_coefs %>% arrange(Variable, region)

```

```{r}
library(dplyr)
library(tidyr)
library(zoo)
library(purrr)
library(broom)

# --- 1) Build long monthly env with roll means (NO month filter here) ---
df_env_full <- ROMS_CUTI_environmental_combined_all_yr %>%
  filter(Year > 1994) %>%
  group_by(region, Year, Month) %>%
  summarise(across(c(DO_avg, pH_avg, Temperature_avg),
                   ~ mean(.x, na.rm = TRUE), .names = "mean_{.col}"),
            .groups = "drop")

df_env_long <- df_env_full %>%
  pivot_longer(starts_with("mean_"), names_to = "Variable", values_to = "Value") %>%
  mutate(Variable = case_when(
    Variable == "mean_DO_avg" ~ "DO",
    Variable == "mean_pH_avg" ~ "pH",
    Variable == "mean_Temperature_avg" ~ "Temperature"
  )) %>%
  left_join(goph_recruit, by = "Year")

month_levels <- c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")

df_env_long <- df_env_long %>%
  mutate(Month_num = match(Month, month_levels)) %>%
  arrange(region, Variable, Year, Month_num) %>%
  group_by(region, Variable) %>%
  mutate(
    roll3 = rollapply(Value, 3, mean, align = "right", fill = NA),  # need full 3 months
    roll6 = rollapply(Value, 6, mean, align = "right", fill = NA)   # need full 6 months
  ) %>%
  ungroup()

# --- 2) Normalize best_r2 window labels and build a SAFE fitter ---
best_r2_use <- best_r2 %>%
  mutate(
    window_key = case_when(
      window %in% c("single_month", "Single month") ~ "single_month",
      window %in% c("3_month", "3 month avg")       ~ "3_month",
      window %in% c("6_month", "6 month avg")       ~ "6_month",
      TRUE ~ as.character(window)
    ),
    Month = as.character(Month)
  )

pick_predictor <- function(df, win_key) {
  if (win_key == "single_month")      df %>% mutate(pred_x = Value)
  else if (win_key == "3_month")      df %>% mutate(pred_x = roll3)
  else if (win_key == "6_month")      df %>% mutate(pred_x = roll6)
  else stop("Unknown window key: ", win_key)
}

safe_fit_best <- function(r, v, m, wk) {
  dat <- df_env_long %>%
    filter(region == r, Variable == v, Month == m) %>%
    pick_predictor(wk) %>%
    filter(!is.na(pred_x), !is.na(dev)) %>%
    select(region, Variable, Year, Month, pred_x, dev)

  n_ok <- nrow(dat)
  if (n_ok < 3 || isTRUE(all(diff(dat$pred_x) == 0, na.rm = TRUE))) {
    return(tibble(
      region = r, Variable = v, window = wk, end_month = m,
      intercept = NA_real_, slope = NA_real_,
      r_squared = NA_real_, p_value = NA_real_,
      sigma = NA_real_, n = n_ok, note = "insufficient data"
    ))
  }

  mdl <- lm(dev ~ pred_x, data = dat)
  tg  <- broom::tidy(mdl)
  gg  <- broom::glance(mdl)

  tibble(
    region = r, Variable = v, window = wk, end_month = m,
    intercept = tg$estimate[tg$term == "(Intercept)"],
    slope     = tg$estimate[tg$term == "pred_x"],
    r_squared = gg$r.squared,
    p_value   = tg$p.value[tg$term == "pred_x"],
    sigma     = gg$sigma,
    n         = n_ok,
    note      = NA_character_
  )
}

# Fit best model for EACH region × variable without crashing
best_model_coefs <- pmap_dfr(
  list(best_r2_use$region, best_r2_use$Variable, best_r2_use$Month, best_r2_use$window_key),
  safe_fit_best
)

best_model_coefs %>% arrange(Variable, region)
```

# Future projections
## input future ocean from other code
```{r}
ocean_future <- read.csv('cleaned_future_ocean_spatially.csv')
```

## 
```{r}
library(dplyr)
library(tidyr)
library(zoo)

# ocean_future columns expected: Year, Month, ESM, Region, DO_avg, pH_avg, Temperature_avg
# best_model_coefs: region, Variable (DO/pH/Temperature), window (single_month/3_month/6_month or recoded),
#                   end_month, intercept, slope

project_recruitment <- function(ocean_future, best_model_coefs) {
  month_levels <- c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")

  # Canonicalize best-model labels
  best_coefs <- best_model_coefs %>%
    mutate(
      region    = as.character(region),
      Variable  = as.character(Variable),
      window    = case_when(
        window %in% c("single_month","Single month") ~ "single_month",
        window %in% c("3_month","3 month avg")       ~ "3_month",
        window %in% c("6_month","6 month avg")       ~ "6_month",
        TRUE ~ as.character(window)
      ),
      end_month = as.character(end_month)
    )

  # Long + rolling means for FUTURE data (do rolls per ESM × region × variable)
  fut_long <- ocean_future %>%
    rename(region = Region) %>%
    mutate(Month = factor(Month, levels = month_levels)) %>%
    pivot_longer(c(DO_avg, pH_avg, Temperature_avg),
                 names_to = "Variable", values_to = "Value") %>%
    mutate(
      Variable = case_when(
        Variable == "DO_avg" ~ "DO",
        Variable == "pH_avg" ~ "pH",
        Variable == "Temperature_avg" ~ "Temperature",
        TRUE ~ as.character(Variable))) %>% 
    arrange(ESM, region, Variable, Year, Month) %>%
    group_by(ESM, region, Variable) %>%
    mutate(
      roll3 = rollapply(Value, 3, mean, align = "right", fill = NA),
      roll6 = rollapply(Value, 6, mean, align = "right", fill = NA)
    ) %>%
    ungroup() %>%
    mutate(Month_chr = as.character(Month))

  # Keep rows matching each Region×Variable’s chosen end-month, attach coefs, compute X & prediction
  preds <- fut_long %>%
    inner_join(best_coefs %>%
                 select(region, Variable, window, end_month, intercept, slope),
               by = c("region", "Variable")) %>%
    filter(Month_chr == end_month) %>%
    mutate(
      X = case_when(
        window == "single_month" ~ Value,
        window == "3_month"      ~ roll3,
        window == "6_month"      ~ roll6,
        TRUE ~ NA_real_
      ),
      pred_dev = intercept + slope * X
    ) %>%
    select(ESM, region, Year, Month, Variable, window, end_month, X, pred_dev) %>%
    arrange(Variable, region, ESM, Year)

  preds
}

# Run it
recruit_future <- project_recruitment(ocean_future, best_model_coefs)

# Peek
dplyr::glimpse(recruit_future)

ensemble_future <- recruit_future %>%
  group_by(region, Variable, Year, Month) %>%
  summarize(
    pred_mean = mean(pred_dev, na.rm = TRUE),
    pred_lo   = quantile(pred_dev, 0.05, na.rm = TRUE),
    pred_hi   = quantile(pred_dev, 0.95, na.rm = TRUE),
    .groups = "drop"
  )
```


```{r}
library(dplyr)
library(ggplot2)

# If not already created:
# recruit_future <- project_recruitment(ocean_future, best_model_coefs)
# Columns expected: ESM, region, Year, Month, Variable, window, end_month, X, pred_dev

# Ensemble summary across ESMs (works even if only 1 ESM)
ensemble_future <- recruit_future %>%
  group_by(region, Variable, Year) %>%
  summarise(
    pred_mean = mean(pred_dev, na.rm = TRUE),
    pred_lo   = quantile(pred_dev, 0.10, na.rm = TRUE),
    pred_hi   = quantile(pred_dev, 0.90, na.rm = TRUE),
    .groups = "drop"
  )

# Raw recruitment series (optional overlay)
raw_dev <- goph_recruit %>%
  distinct(Year, dev) %>%
  arrange(Year)

# Plot: one panel per parameter
p_proj <- ggplot() +
  geom_hline(yintercept = 0, linetype = "dashed") + 
  geom_line(data = raw_dev, aes(Year, dev), color = "black", linewidth = 0.5) +
 # geom_point(data = raw_dev, aes(Year, dev), color = "black", size = 2) +
  # individual ESM projections (spaghetti)
  geom_point(
    data = recruit_future,
    aes(x = Year, y = pred_dev, group = interaction(ESM, region), color = region, shape = ESM),
    alpha = 0.25, linewidth = 0.5
  ) +
    geom_line(
    data = recruit_future,
    aes(x = Year, y = pred_dev, group = interaction(ESM, region), color = region, shape = ESM),linewidth = .5
  ) +
  facet_wrap(~ Variable, nrow = 3) +
  scale_color_manual(values = spatial_colors, name = "Region") +
  scale_fill_manual(values  = spatial_colors, name = "Region") +
  labs(
    title = "",
    subtitle = "",
    x = "Year", y = "Projected recruitment deviation"
  ) +
  theme_bw() +
  larger_axis_theme +
  theme(legend.position = "bottom")

p_proj

```
```{r}
library(dplyr)
library(ggplot2)
library(patchwork)

# Optional: lock a consistent ESM order across all panels
esm_levels <- recruit_future %>% distinct(ESM) %>% pull(ESM) %>% as.character()

rawdev_2 <- raw_dev %>% 
  filter(Year %in% c(2000,2001,2002,2005,2006,2007,2008,2009,2010,2011,2015,2017))

make_proj_by_esm <- function(var_label) {
  dfv <- recruit_future %>%
    filter(Variable == var_label) %>%
    mutate(ESM = factor(ESM, levels = esm_levels))

  ggplot() +
    geom_hline(yintercept = 0, linetype = "dashed") +
    # Raw recruitment for context
    #geom_point(data = raw_dev, aes(Year, dev), color = "black", linewidth = 0.5) +
    # Projections for this variable, faceted by ESM
    geom_point(
      data = dfv,
      aes(x = Year, y = pred_dev,
          group = interaction(ESM, region),
          color = region),
      alpha = 0.25, size = 1.6
    ) +
   geom_line(
      data = dfv,
      aes(x = Year, y = pred_dev,
          group = interaction(ESM, region),
          color = region),
      linewidth = 0.5
    ) +
    facet_wrap(~ ESM, nrow = 1) +
    scale_color_manual(values = spatial_colors, name = "Region") +
    scale_shape_discrete(name = "ESM") +
    labs(
      title = var_label,
      x = "Year", y = "Projected recruitment deviation"
    ) +
    theme_bw() +
    theme(legend.position = "bottom")
}

# Build the three plots (one per parameter)
p_DO  <- make_proj_by_esm("DO")
p_pH  <- make_proj_by_esm("pH")
p_Tmp <- make_proj_by_esm("Temperature")

# Show individually:
p_DO; p_pH; p_Tmp

# Or stack them into one figure:
#(p_DO / p_pH / p_Tmp) + plot_layout(guides = "collect") &
#  theme(legend.position = "right")

ggsave("Recruitment_future_projection_timeseries.png", width = 10, height = 8, dpi = 300)

p_Tmp 
ggsave("Recruitment_future_projection_timeseries_Tmp.png", width = 10, height = 4, dpi = 300)


p_pH 
ggsave("Recruitment_future_projection_timeseries_pH.png", width = 10, height = 4, dpi = 300)

p_DO
ggsave("Recruitment_future_projection_timeseries_DO.png", width = 10, height = 4, dpi = 300)
```

```{r}
correlation <- left_join(recruit_future, rawdev_2) %>% 
  filter(ESM == "IPSL") %>% 
  filter(region == "south") %>% 
  filter(Variable == "DO")

x <- lm(dev ~ pred_dev, data = correlation)

summary(x)
```

```{r}
esm_levels    <- c("GFDL","HADL","IPSL")
region_levels <- names(spatial_colors)  # e.g. c("mid","north","south","all")

slope_ci2 <- slope_ci %>%
  mutate(
    ESM    = factor(ESM, levels = esm_levels),
    region = factor(region, levels = region_levels),
    model_id = factor(
      paste(ESM, region),
      levels = as.vector(unlist(lapply(esm_levels, function(e) paste(e, region_levels))))
    )
  )

lim_y <- max(abs(c(slope_ci2$lo, slope_ci2$hi)), na.rm = TRUE)

ggplot(slope_ci2, aes(x = model_id, y = slope, color = region, shape = ESM)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_errorbar(aes(ymin = lo, ymax = hi), width = 0) +
  geom_point() +
  facet_wrap(~ Variable, ncol = 3) +
  coord_cartesian(ylim = c(-lim_y, lim_y)) +
  scale_color_manual(values = spatial_colors) +
  labs(x = "Model", y = "Slope of trend",
       title = "") +
  theme_classic() +
  larger_axis_theme+
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(size = 14, face = "bold")
  )

ggsave("Recruitment_future_projection_slope_figure.png", width = 10, height = 5, dpi = 300)

```

```{r}
prob_neg <- recruit_future %>%
  group_by(Variable, region, Year) %>%
  summarize(p_neg = mean(pred_dev < 0, na.rm=TRUE), .groups="drop")

ggplot(prob_neg, aes(Year, p_neg, color=region, group=region)) +
  geom_line() +
  facet_wrap(~ Variable, ncol=1) +
  scale_color_manual(values=spatial_colors) +
  scale_y_continuous(labels=scales::percent) +
  labs(y="P(recruitment deviation < 0)", title="Annual probability across ESMs") +
  theme_bw() + theme(legend.position="bottom")
```


```{r}
# uses recruit_decadal you already computed (one mean per decade/region/ESM)
ggplot(recruit_decadal,
       aes(x = factor(decade), y = mean_dev, color = region, group = region)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_line(linewidth = 0.9) +
  geom_point(size = 2) +
  facet_grid(Variable ~ ESM) +
  scale_color_manual(values = spatial_colors, name = "Region") +
  labs(x = "Decade", y = "Decadal mean projected recruitment deviation",
       title = "") +
  theme_bw() +
  theme(legend.position = "bottom",
        strip.text = element_text(size = 10))


```
```{r}
# Build annual-by-decade data (no averaging across years)
recruit_decadal_annual <- recruit_future %>%
  mutate(decade = floor(Year/10)*10) %>%
  # keep annual values; one row per Year so boxplot has a distribution
  select(Variable, region, ESM, decade, Year, pred_dev)

ggplot(recruit_decadal_annual,
       aes(x = factor(decade), y = pred_dev, fill = region)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_boxplot(outlier.alpha = .2) +
  facet_grid(ESM ~ Variable) +
  scale_fill_manual(values = spatial_colors, name = "Region") +
  labs(x = "Decade", y = "Projected recruitment deviation",
       title = "Decadal spread (annual values) by ESM and region") +
  theme_bw() +
  theme(legend.position = "bottom",
        strip.text = element_text(size = 14, face = "bold"))


```


```{r}
library(dplyr)
library(ggplot2)
library(scales)

# 1) One value per ESM × region × Variable × Year
rf_year <- recruit_future %>%
  filter(Variable == "DO") %>% 
  group_by(ESM, region, Variable, Year) %>%
  summarise(pred_dev = mean(pred_dev, na.rm = TRUE), .groups = "drop")

# 2) % of years > 0 by decade
freq_decade <- rf_year %>%
  mutate(decade = 10 * floor(Year/10)) %>%
  group_by(ESM, region, Variable, decade) %>%
  summarise(
    n_years = dplyr::n(),
    n_above = sum(pred_dev > 0, na.rm = TRUE),
    p_above = n_above / n_years,
    .groups = "drop"
  ) %>%
  mutate(
    decade = factor(decade, levels = sort(unique(decade)))  # tidy x-order
  )

# (optional) Order regions by overall tendency to be > 0
region_order <- freq_decade %>%
  group_by(region) %>%
  summarise(avg = mean(p_above, na.rm = TRUE), .groups = "drop") %>%
  arrange(desc(avg)) %>% pull(region)

freq_decade <- freq_decade %>%
  mutate(region = factor(region, levels = region_order))

# 3) Heatmap: % years > 0, faceted by ESM and Variable
p_freq <- ggplot(freq_decade, aes(x = decade, y = region, fill = p_above)) +
  geom_tile(color = "white", linewidth = 0.3) +
  geom_text(aes(label = percent(p_above, accuracy = 1)), size = 2.8) +
  facet_grid(Variable ~ ESM, switch = "y") +
  scale_fill_viridis_c(limits = c(0, 1), name = "% years > 0") +
  labs(x = "Decade", y = NULL,
       title = "Share of years with projected recruitment deviation > 0") +
  theme_bw(base_size = 11) +
  theme(
    panel.grid = element_blank(),
    strip.background = element_rect(fill = "grey95", colour = NA),
    axis.ticks = element_blank()
  )

p_freq

desired <- c("north","mid","south","all")


freq_period <- rf_year %>%
  mutate(period = case_when(
    Year <= 2025 ~ "2000–2025",
    Year <= 2050 ~ "2026–2050",
    Year <= 2075 ~ "2051–2075",
    TRUE         ~ "2076–2100"
  )) %>%
  group_by(ESM, region, Variable, period) %>%
  summarise(p_above = mean(pred_dev > 0, na.rm = TRUE), .groups = "drop") %>%
  mutate(period = factor(period, levels = c("2000–2025","2026–2050","2051–2075", "2076-2100")))

ggplot(freq_period, aes(period, region, fill = p_above)) +
  geom_tile(color = "white", linewidth = 0.3) +
  geom_text(aes(label = percent(p_above, accuracy = 1)), size = 3) +
  facet_grid(Variable ~ ESM) +
  scale_fill_viridis_c(limits = c(0,1), name = "% years > 0") +
  labs(x = NULL, y = NULL,
       title = "Share of years > 0 by period") +
  theme_bw()


```
```{r}
desired <- c("north","mid","south","all")   # top→bottom order you want

freq_period <- rf_year %>%
  mutate(
    region = tolower(region),
    period = case_when(
      Year <= 2025 ~ "2000–2025",
      Year <= 2050 ~ "2026–2050",
      Year <= 2075 ~ "2051–2075",
      TRUE         ~ "2076–2100"
    )
  ) %>%
  group_by(ESM, region, Variable, period) %>%
  summarise(p_above = mean(pred_dev > 0, na.rm = TRUE), .groups = "drop") %>%
  mutate(
    period = factor(period, levels = c("2000–2025","2026–2050","2051–2075","2076–2100")),
    region = factor(region, levels = rev(desired))  # bottom→top = all, south, mid, north
  )

do_future_percent <- ggplot(freq_period, aes(period, region, fill = p_above)) +
  geom_tile(color = "white", linewidth = 0.3) +
  geom_text(aes(label = percent(p_above, accuracy = 1)), size = 3, color = "white") +
  facet_grid(~ ESM, drop = FALSE) +
scale_fill_viridis_c(option = "mako", limits = c(0,1), name = "% years > 0") +
  scale_y_discrete(
    limits = rev(desired),                       # ensures top row = north
    labels = c(north="North", mid="Mid", south="South", all="All"),
    drop = FALSE
  ) +
  labs(x = NULL, y = NULL, title = "") +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(legend.position = "none")

ggsave("Recruitment_projection_DO_positive_percentages.png", width = 10, height = 5, dpi = 300)

```

```{r}
library(forcats)
library(scales)
library(ggplot2)

# Desired top→bottom order
desired <- c("north","mid","south","all")

# ---- A) Isolate DO-model fits (historical) and the rec devs on the same years ----
# We take DO only for the "DO model" panel, and the raw dev for the "Rec dev" panel.
do_fits <- preds %>%
  dplyr::filter(tolower(Variable) %in% c("do","dissolved oxygen","oxygen")) %>%
  dplyr::transmute(
    ESM = "GFDL",
    region = tolower(region),
    Variable = "DO model",
    Year,
    value = .fitted
  )

rec_hist <- preds %>%
  dplyr::select(Year, dev) %>% dplyr::distinct() %>%
  dplyr::transmute(
    ESM = "GFDL",
    region = "all",
    Variable = "Rec dev",
    Year,
    value = dev
  )

# Align to the same year range in case of gaps
common_years <- intersect(do_fits$Year, rec_hist$Year)
do_fits  <- dplyr::filter(do_fits,  Year %in% common_years)
rec_hist <- dplyr::filter(rec_hist, Year %in% common_years)

# ---- B) Compute % of years > 0 by DECADE (swap to periods if you prefer) ----
freq_do <- do_fits %>%
  dplyr::mutate(decade = 10L * floor(Year/10L)) %>%
  dplyr::group_by(ESM, region, Variable, decade) %>%
  dplyr::summarise(p_above = mean(value > 0, na.rm = TRUE), .groups = "drop")

freq_rec <- rec_hist %>%
  dplyr::mutate(decade = 10L * floor(Year/10L)) %>%
  dplyr::group_by(ESM, region, Variable, decade) %>%
  dplyr::summarise(p_above = mean(value > 0, na.rm = TRUE), .groups = "drop")

freq_hist <- dplyr::bind_rows(freq_do, freq_rec) %>%
  dplyr::mutate(
    region = factor(region, levels = rev(desired)),                 # bottom→top
    decade = factor(decade, levels = sort(unique(decade)))
  )

```
```{r}
library(patchwork)

p_do <- freq_hist %>% dplyr::filter(Variable == "DO model") %>%
  ggplot(aes(decade, region, fill = p_above)) +
  geom_tile(color="white", linewidth=.3) +
  geom_text(aes(label = scales::percent(p_above, 1)), size = 3, color = "white") +
  scale_y_discrete(
    limits = rev(c("north","mid","south","all")),
    labels = c(
      north = "North",
      mid   = "Mid",
      south = "South",
      all   = "Regional Average"
    )
  ) +
  scale_fill_viridis_c(option = "mako", limits = c(0,1), name = "% years > 0") +
  labs(x = NULL, y = NULL) +
  theme_bw() +
  theme(
    panel.grid = element_blank(),
    axis.title.x = element_blank(),
    axis.text.x  = element_blank(),   # remove x labels on top plot
    axis.ticks.x = element_blank()
  )

p_rec <- freq_hist %>% dplyr::filter(Variable == "Rec dev") %>%
  ggplot(aes(decade, region, fill = p_above)) +
  geom_tile(color="white", linewidth=.3) +
  geom_text(aes(label = scales::percent(p_above, 1)), size = 3, color = 'white') +
  scale_y_discrete(limits = "all", labels = c(all = "Historical Data")) +
  scale_fill_viridis_c(option = "mako", limits = c(0,1), name = "% years > 0") +
  labs(x = "Decade", y = NULL) +
  theme_bw() +
  theme(panel.grid = element_blank())


(p_do / p_rec) +
  plot_layout(heights = c(3, 1), guides = "collect") &
  theme(legend.position = "right") 


```

```{r}
 do_future_percent | (p_do / p_rec) +
  plot_layout(heights = c(3, 1), guides = "collect") &
  theme(legend.position = "right")

ggsave("Recruitment_projection_DO_positive_percentages_historical.png", width = 10, height = 8, dpi = 300)

```

```{r}
library(dplyr)
library(forcats)

# Desired top→bottom order
desired <- c("north","mid","south","all")

# Map your Variable names to nice facet labels
var_map <- function(x) {
  x <- tolower(x)
  dplyr::case_when(
    x %in% c("do","dissolved oxygen","oxygen") ~ "DO model",
    x %in% c("ph","pht","pco2","p_h")          ~ "pH model",
    x %in% c("temperature","temp","sst")       ~ "Temperature model",
    TRUE ~ paste0(stringr::str_to_title(x), " model")
  )
}

# ---- A) All model fits (historical) + Rec dev on the same years ----
model_fits <- preds %>%
  mutate(
    Variable = var_map(Variable),
    region   = tolower(region)
  ) %>%
  transmute(
    ESM = "GFDL",
    region,
    Variable,          # now one of: DO model / pH model / Temperature model
    Year,
    value = .fitted
  )

rec_hist <- preds %>%
  select(Year, dev) %>% distinct() %>%
  transmute(
    ESM = "GFDL",
    region = "all",
    Variable = "Rec dev",
    Year,
    value = dev
  )

# Align years across panels
common_years <- intersect(unique(model_fits$Year), unique(rec_hist$Year))
model_fits <- filter(model_fits, Year %in% common_years)
rec_hist   <- filter(rec_hist,   Year %in% common_years)

# ---- B) % of years > 0 by decade ----
freq_models <- model_fits %>%
  mutate(decade = 10L * floor(Year/10L)) %>%
  group_by(ESM, Variable, region, decade) %>%
  summarise(p_above = mean(value > 0, na.rm = TRUE), .groups = "drop")

freq_rec <- rec_hist %>%
  mutate(decade = 10L * floor(Year/10L)) %>%
  group_by(ESM, Variable, region, decade) %>%
  summarise(p_above = mean(value > 0, na.rm = TRUE), .groups = "drop")

freq_hist <- bind_rows(freq_models, freq_rec) %>%
  mutate(
    region   = factor(region, levels = rev(desired)),  # bottom→top
    decade   = factor(decade, levels = sort(unique(decade))),
    Variable = factor(Variable,
                      levels = c("DO model", "pH model", "Temperature model", "Rec dev"))
  )

library(ggplot2)
library(scales)

ggplot(freq_hist, aes(decade, region, fill = p_above)) +
  geom_tile(color = "white", linewidth = 0.3) +
  geom_text(aes(label = percent(p_above, 1)), size = 3, color = 'white') +
  facet_grid(~Variable, switch = "y",
             scales = "free_y", space = "free_y", drop = FALSE) +
  scale_fill_viridis_c(option = "mako", limits = c(0,1), name = "% years > 0") +
  scale_y_discrete(
    limits = rev(desired),
    labels = c(north="North", mid="Mid", south="South", all="All"),
    drop   = TRUE
  ) +
  labs(x = "Decade", y = NULL,
       title = "") +
  theme_bw() +
  theme(panel.grid = element_blank())


ggsave("Recruitment_projection_all_positive_percentages_historical.png", width = 10, height = 6, dpi = 300)
```



# Future projections - wsn SUBSET
## input future ocean from other code
```{r}
ocean_future <- read.csv('cleaned_future_ocean_spatially.csv') %>% 
  filter(ESM == "GFDL")
```

## 
```{r}
library(dplyr)
library(tidyr)
library(zoo)

# ocean_future columns expected: Year, Month, ESM, Region, DO_avg, pH_avg, Temperature_avg
# best_model_coefs: region, Variable (DO/pH/Temperature), window (single_month/3_month/6_month or recoded),
#                   end_month, intercept, slope

project_recruitment <- function(ocean_future, best_model_coefs) {
  month_levels <- c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")

  # Canonicalize best-model labels
  best_coefs <- best_model_coefs %>%
    mutate(
      region    = as.character(region),
      Variable  = as.character(Variable),
      window    = case_when(
        window %in% c("single_month","Single month") ~ "single_month",
        window %in% c("3_month","3 month avg")       ~ "3_month",
        window %in% c("6_month","6 month avg")       ~ "6_month",
        TRUE ~ as.character(window)
      ),
      end_month = as.character(end_month)
    )

  # Long + rolling means for FUTURE data (do rolls per ESM × region × variable)
  fut_long <- ocean_future %>%
    rename(region = Region) %>%
    mutate(Month = factor(Month, levels = month_levels)) %>%
    pivot_longer(c(DO_avg, pH_avg, Temperature_avg),
                 names_to = "Variable", values_to = "Value") %>%
    mutate(
      Variable = case_when(
        Variable == "DO_avg" ~ "DO",
        Variable == "pH_avg" ~ "pH",
        Variable == "Temperature_avg" ~ "Temperature",
        TRUE ~ as.character(Variable))) %>% 
    arrange(ESM, region, Variable, Year, Month) %>%
    group_by(ESM, region, Variable) %>%
    mutate(
      roll3 = rollapply(Value, 3, mean, align = "right", fill = NA),
      roll6 = rollapply(Value, 6, mean, align = "right", fill = NA)
    ) %>%
    ungroup() %>%
    mutate(Month_chr = as.character(Month))

  # Keep rows matching each Region×Variable’s chosen end-month, attach coefs, compute X & prediction
  preds <- fut_long %>%
    inner_join(best_coefs %>%
                 select(region, Variable, window, end_month, intercept, slope),
               by = c("region", "Variable")) %>%
    filter(Month_chr == end_month) %>%
    mutate(
      X = case_when(
        window == "single_month" ~ Value,
        window == "3_month"      ~ roll3,
        window == "6_month"      ~ roll6,
        TRUE ~ NA_real_
      ),
      pred_dev = intercept + slope * X
    ) %>%
    select(ESM, region, Year, Month, Variable, window, end_month, X, pred_dev) %>%
    arrange(Variable, region, ESM, Year)

  preds
}

# Run it
recruit_future <- project_recruitment(ocean_future, best_model_coefs)

# Peek
dplyr::glimpse(recruit_future)

ensemble_future <- recruit_future %>%
  group_by(region, Variable, Year, Month) %>%
  summarize(
    pred_mean = mean(pred_dev, na.rm = TRUE),
    pred_lo   = quantile(pred_dev, 0.05, na.rm = TRUE),
    pred_hi   = quantile(pred_dev, 0.95, na.rm = TRUE),
    .groups = "drop"
  )
```


```{r}
library(dplyr)
library(ggplot2)

# If not already created:
# recruit_future <- project_recruitment(ocean_future, best_model_coefs)
# Columns expected: ESM, region, Year, Month, Variable, window, end_month, X, pred_dev

# Ensemble summary across ESMs (works even if only 1 ESM)
ensemble_future <- recruit_future %>%
  group_by(region, Variable, Year) %>%
  summarise(
    pred_mean = mean(pred_dev, na.rm = TRUE),
    pred_lo   = quantile(pred_dev, 0.10, na.rm = TRUE),
    pred_hi   = quantile(pred_dev, 0.90, na.rm = TRUE),
    .groups = "drop"
  )

# Raw recruitment series (optional overlay)
raw_dev <- goph_recruit %>%
  distinct(Year, dev) %>%
  arrange(Year)

# Plot: one panel per parameter
p_proj <- ggplot() +
  geom_hline(yintercept = 0, linetype = "dashed") + 
  geom_line(data = raw_dev, aes(Year, dev), color = "black", linewidth = 0.5) +
 # geom_point(data = raw_dev, aes(Year, dev), color = "black", size = 2) +
  # individual ESM projections (spaghetti)
  geom_point(
    data = recruit_future,
    aes(x = Year, y = pred_dev, group = interaction(ESM, region), color = region, shape = ESM),
    alpha = 0.25, linewidth = 0.5
  ) +
    geom_line(
    data = recruit_future,
    aes(x = Year, y = pred_dev, group = interaction(ESM, region), color = region, shape = ESM),linewidth = .5
  ) +
  facet_wrap(~ Variable, nrow = 3) +
  scale_color_manual(values = spatial_colors, name = "Region") +
  scale_fill_manual(values  = spatial_colors, name = "Region") +
  labs(
    title = "",
    subtitle = "",
    x = "Year", y = "Projected recruitment deviation"
  ) +
  theme_bw() +
  larger_axis_theme +
  theme(legend.position = "bottom")

p_proj

```
```{r}
library(dplyr)
library(ggplot2)
library(patchwork)

# Optional: lock a consistent ESM order across all panels
esm_levels <- recruit_future %>% distinct(ESM) %>% pull(ESM) %>% as.character()

rawdev_2 <- raw_dev %>% 
  filter(Year %in% c(2000,2001,2002,2005,2006,2007,2008,2009,2010,2011,2015,2017))

make_proj_by_esm <- function(var_label) {
  dfv <- recruit_future %>%
    filter(Variable == var_label) %>%
    mutate(ESM = factor(ESM, levels = esm_levels))

  ggplot() +
    geom_hline(yintercept = 0, linetype = "dashed") +
    # Raw recruitment for context
    #geom_point(data = raw_dev, aes(Year, dev), color = "black", linewidth = 0.5) +
    # Projections for this variable, faceted by ESM
    geom_point(
      data = dfv,
      aes(x = Year, y = pred_dev,
          group = interaction(ESM, region),
          color = region),
      alpha = 0.25, size = 1.6
    ) +
   geom_line(
      data = dfv,
      aes(x = Year, y = pred_dev,
          group = interaction(ESM, region),
          color = region),
      linewidth = 0.5
    ) +
    scale_color_manual(values = spatial_colors, name = "Region") +
    labs(
      title = var_label,
      x = "Year", y = "Projected recruitment deviation"
    ) +
    theme_bw() +
    theme(legend.position = "bottom")
}

# Build the three plots (one per parameter)
p_DO  <- make_proj_by_esm("DO")
p_pH  <- make_proj_by_esm("pH")
p_Tmp <- make_proj_by_esm("Temperature")

# Show individually:
p_DO; p_pH; p_Tmp

# Or stack them into one figure:
#(p_DO / p_pH / p_Tmp) + plot_layout(guides = "collect") &
#  theme(legend.position = "right")

ggsave("Recruitment_future_projection_timeseries.png", width = 10, height = 8, dpi = 300)

p_Tmp 
ggsave("Recruitment_future_projection_timeseries_Tmp.png", width = 10, height = 4, dpi = 300)


p_pH 
ggsave("Recruitment_future_projection_timeseries_pH.png", width = 10, height = 4, dpi = 300)

p_DO
ggsave("Recruitment_future_projection_timeseries_DO.png", width = 10, height = 4, dpi = 300)
```

```{r}
correlation <- left_join(recruit_future, rawdev_2) %>% 
  filter(ESM == "IPSL") %>% 
  filter(region == "south") %>% 
  filter(Variable == "DO")

x <- lm(dev ~ pred_dev, data = correlation)

summary(x)
```

```{r}
esm_levels    <- c("GFDL","HADL","IPSL")
region_levels <- names(spatial_colors)  # e.g. c("mid","north","south","all")

slope_ci2 <- slope_ci %>%
  mutate(
    ESM    = factor(ESM, levels = esm_levels),
    region = factor(region, levels = region_levels),
    model_id = factor(
      paste(ESM, region),
      levels = as.vector(unlist(lapply(esm_levels, function(e) paste(e, region_levels))))
    )
  )

lim_y <- max(abs(c(slope_ci2$lo, slope_ci2$hi)), na.rm = TRUE)

ggplot(slope_ci2, aes(x = model_id, y = slope, color = region, shape = ESM)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_errorbar(aes(ymin = lo, ymax = hi), width = 0) +
  geom_point() +
  facet_wrap(~ Variable, ncol = 3) +
  coord_cartesian(ylim = c(-lim_y, lim_y)) +
  scale_color_manual(values = spatial_colors) +
  labs(x = "Model", y = "Slope of trend",
       title = "") +
  theme_classic() +
  larger_axis_theme+
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(size = 14, face = "bold")
  )

ggsave("Recruitment_future_projection_slope_figure.png", width = 10, height = 5, dpi = 300)

```

```{r}
prob_neg <- recruit_future %>%
  group_by(Variable, region, Year) %>%
  summarize(p_neg = mean(pred_dev < 0, na.rm=TRUE), .groups="drop")

ggplot(prob_neg, aes(Year, p_neg, color=region, group=region)) +
  geom_line() +
  facet_wrap(~ Variable, ncol=1) +
  scale_color_manual(values=spatial_colors) +
  scale_y_continuous(labels=scales::percent) +
  labs(y="P(recruitment deviation < 0)", title="Annual probability across ESMs") +
  theme_bw() + theme(legend.position="bottom")
```


```{r}
# uses recruit_decadal you already computed (one mean per decade/region/ESM)
ggplot(recruit_decadal,
       aes(x = factor(decade), y = mean_dev, color = region, group = region)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_line(linewidth = 0.9) +
  geom_point(size = 2) +
  facet_grid(Variable ~ ESM) +
  scale_color_manual(values = spatial_colors, name = "Region") +
  labs(x = "Decade", y = "Decadal mean projected recruitment deviation",
       title = "") +
  theme_bw() +
  theme(legend.position = "bottom",
        strip.text = element_text(size = 10))


```
```{r}
# Build annual-by-decade data (no averaging across years)
recruit_decadal_annual <- recruit_future %>%
  mutate(decade = floor(Year/10)*10) %>%
  # keep annual values; one row per Year so boxplot has a distribution
  select(Variable, region, ESM, decade, Year, pred_dev)

ggplot(recruit_decadal_annual,
       aes(x = factor(decade), y = pred_dev, fill = region)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_boxplot(outlier.alpha = .2) +
  facet_grid(ESM ~ Variable) +
  scale_fill_manual(values = spatial_colors, name = "Region") +
  labs(x = "Decade", y = "Projected recruitment deviation",
       title = "Decadal spread (annual values) by ESM and region") +
  theme_bw() +
  theme(legend.position = "bottom",
        strip.text = element_text(size = 14, face = "bold"))


```


```{r}
library(dplyr)
library(ggplot2)
library(scales)

# 1) One value per ESM × region × Variable × Year
rf_year <- recruit_future %>%
  filter(Variable == "DO") %>% 
  group_by(ESM, region, Variable, Year) %>%
  summarise(pred_dev = mean(pred_dev, na.rm = TRUE), .groups = "drop")

# 2) % of years > 0 by decade
freq_decade <- rf_year %>%
  mutate(decade = 10 * floor(Year/10)) %>%
  group_by(ESM, region, Variable, decade) %>%
  summarise(
    n_years = dplyr::n(),
    n_above = sum(pred_dev > 0, na.rm = TRUE),
    p_above = n_above / n_years,
    .groups = "drop"
  ) %>%
  mutate(
    decade = factor(decade, levels = sort(unique(decade)))  # tidy x-order
  )

# (optional) Order regions by overall tendency to be > 0
region_order <- freq_decade %>%
  group_by(region) %>%
  summarise(avg = mean(p_above, na.rm = TRUE), .groups = "drop") %>%
  arrange(desc(avg)) %>% pull(region)

freq_decade <- freq_decade %>%
  mutate(region = factor(region, levels = region_order))

# 3) Heatmap: % years > 0, faceted by ESM and Variable
p_freq <- ggplot(freq_decade, aes(x = decade, y = region, fill = p_above)) +
  geom_tile(color = "white", linewidth = 0.3) +
  geom_text(aes(label = percent(p_above, accuracy = 1)), size = 2.8) +
  facet_grid(Variable ~ ESM, switch = "y") +
  scale_fill_viridis_c(limits = c(0, 1), name = "% years > 0") +
  labs(x = "Decade", y = NULL,
       title = "Share of years with projected recruitment deviation > 0") +
  theme_bw(base_size = 11) +
  theme(
    panel.grid = element_blank(),
    strip.background = element_rect(fill = "grey95", colour = NA),
    axis.ticks = element_blank()
  )

p_freq

desired <- c("north","mid","south","all")


freq_period <- rf_year %>%
  mutate(period = case_when(
    Year <= 2025 ~ "2000–2025",
    Year <= 2050 ~ "2026–2050",
    Year <= 2075 ~ "2051–2075",
    TRUE         ~ "2076–2100"
  )) %>%
  group_by(ESM, region, Variable, period) %>%
  summarise(p_above = mean(pred_dev > 0, na.rm = TRUE), .groups = "drop") %>%
  mutate(period = factor(period, levels = c("2000–2025","2026–2050","2051–2075", "2076-2100")))

ggplot(freq_period, aes(period, region, fill = p_above)) +
  geom_tile(color = "white", linewidth = 0.3) +
  geom_text(aes(label = percent(p_above, accuracy = 1)), size = 3) +
  facet_grid(Variable ~ ESM) +
  scale_fill_viridis_c(limits = c(0,1), name = "% years > 0") +
  labs(x = NULL, y = NULL,
       title = "Share of years > 0 by period") +
  theme_bw()


```
```{r}
desired <- c("north","mid","south","all")   # top→bottom order you want

freq_period <- rf_year %>%
  mutate(
    region = tolower(region),
    period = case_when(
      Year <= 2025 ~ "2000–2025",
      Year <= 2050 ~ "2026–2050",
      Year <= 2075 ~ "2051–2075",
      TRUE         ~ "2076–2100"
    )
  ) %>%
  group_by(ESM, region, Variable, period) %>%
  summarise(p_above = mean(pred_dev > 0, na.rm = TRUE), .groups = "drop") %>%
  mutate(
    period = factor(period, levels = c("2000–2025","2026–2050","2051–2075","2076–2100")),
    region = factor(region, levels = rev(desired))  # bottom→top = all, south, mid, north
  )

do_future_percent <- ggplot(freq_period, aes(period, region, fill = p_above)) +
  geom_tile(color = "white", linewidth = 0.3) +
  geom_text(aes(label = percent(p_above, accuracy = 1)), size = 3, color = "white") +
  facet_grid(~ ESM, drop = FALSE) +
scale_fill_viridis_c(option = "mako", limits = c(0,1), name = "% years > 0") +
  scale_y_discrete(
    limits = rev(desired),                       # ensures top row = north
    labels = c(north="North", mid="Mid", south="South", all="All"),
    drop = FALSE
  ) +
  labs(x = NULL, y = NULL, title = "") +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(legend.position = "none")

ggsave("Recruitment_projection_DO_positive_percentages.png", width = 10, height = 5, dpi = 300)

```

```{r}
library(forcats)
library(scales)
library(ggplot2)

# Desired top→bottom order
desired <- c("north","mid","south","all")

# ---- A) Isolate DO-model fits (historical) and the rec devs on the same years ----
# We take DO only for the "DO model" panel, and the raw dev for the "Rec dev" panel.
do_fits <- preds %>%
  dplyr::filter(tolower(Variable) %in% c("do","dissolved oxygen","oxygen")) %>%
  dplyr::transmute(
    ESM = "GFDL",
    region = tolower(region),
    Variable = "DO model",
    Year,
    value = .fitted
  )

rec_hist <- preds %>%
  dplyr::select(Year, dev) %>% dplyr::distinct() %>%
  dplyr::transmute(
    ESM = "GFDL",
    region = "all",
    Variable = "Rec dev",
    Year,
    value = dev
  )

# Align to the same year range in case of gaps
common_years <- intersect(do_fits$Year, rec_hist$Year)
do_fits  <- dplyr::filter(do_fits,  Year %in% common_years)
rec_hist <- dplyr::filter(rec_hist, Year %in% common_years)

# ---- B) Compute % of years > 0 by DECADE (swap to periods if you prefer) ----
freq_do <- do_fits %>%
  dplyr::mutate(decade = 10L * floor(Year/10L)) %>%
  dplyr::group_by(ESM, region, Variable, decade) %>%
  dplyr::summarise(p_above = mean(value > 0, na.rm = TRUE), .groups = "drop")

freq_rec <- rec_hist %>%
  dplyr::mutate(decade = 10L * floor(Year/10L)) %>%
  dplyr::group_by(ESM, region, Variable, decade) %>%
  dplyr::summarise(p_above = mean(value > 0, na.rm = TRUE), .groups = "drop")

freq_hist <- dplyr::bind_rows(freq_do, freq_rec) %>%
  dplyr::mutate(
    region = factor(region, levels = rev(desired)),                 # bottom→top
    decade = factor(decade, levels = sort(unique(decade)))
  )

```
```{r}
library(patchwork)

p_do <- freq_hist %>% dplyr::filter(Variable == "DO model") %>%
  ggplot(aes(decade, region, fill = p_above)) +
  geom_tile(color="white", linewidth=.3) +
  geom_text(aes(label = scales::percent(p_above, 1)), size = 3, color = "white") +
  scale_y_discrete(
    limits = rev(c("north","mid","south","all")),
    labels = c(
      north = "North",
      mid   = "Mid",
      south = "South",
      all   = "Regional Average"
    )
  ) +
  scale_fill_viridis_c(option = "mako", limits = c(0,1), name = "% years > 0") +
  labs(x = NULL, y = NULL) +
  theme_bw() +
  theme(
    panel.grid = element_blank(),
    axis.title.x = element_blank(),
    axis.text.x  = element_blank(),   # remove x labels on top plot
    axis.ticks.x = element_blank()
  )

p_rec <- freq_hist %>% dplyr::filter(Variable == "Rec dev") %>%
  ggplot(aes(decade, region, fill = p_above)) +
  geom_tile(color="white", linewidth=.3) +
  geom_text(aes(label = scales::percent(p_above, 1)), size = 3, color = 'white') +
  scale_y_discrete(limits = "all", labels = c(all = "Historical Data")) +
  scale_fill_viridis_c(option = "mako", limits = c(0,1), name = "% years > 0") +
  labs(x = "Decade", y = NULL) +
  theme_bw() +
  theme(panel.grid = element_blank())


(p_do / p_rec) +
  plot_layout(heights = c(3, 1), guides = "collect") &
  theme(legend.position = "right") 


```

```{r}
 do_future_percent | (p_do / p_rec) +
  plot_layout(heights = c(3, 1), guides = "collect") &
  theme(legend.position = "right")

ggsave("Recruitment_projection_DO_positive_percentages_historical.png", width = 10, height = 8, dpi = 300)

```

```{r}
library(dplyr)
library(forcats)

# Desired top→bottom order
desired <- c("north","mid","south","all")

# Map your Variable names to nice facet labels
var_map <- function(x) {
  x <- tolower(x)
  dplyr::case_when(
    x %in% c("do","dissolved oxygen","oxygen") ~ "DO model",
    x %in% c("ph","pht","pco2","p_h")          ~ "pH model",
    x %in% c("temperature","temp","sst")       ~ "Temperature model",
    TRUE ~ paste0(stringr::str_to_title(x), " model")
  )
}

# ---- A) All model fits (historical) + Rec dev on the same years ----
model_fits <- preds %>%
  mutate(
    Variable = var_map(Variable),
    region   = tolower(region)
  ) %>%
  transmute(
    ESM = "GFDL",
    region,
    Variable,          # now one of: DO model / pH model / Temperature model
    Year,
    value = .fitted
  )

rec_hist <- preds %>%
  select(Year, dev) %>% distinct() %>%
  transmute(
    ESM = "GFDL",
    region = "all",
    Variable = "Rec dev",
    Year,
    value = dev
  )

# Align years across panels
common_years <- intersect(unique(model_fits$Year), unique(rec_hist$Year))
model_fits <- filter(model_fits, Year %in% common_years)
rec_hist   <- filter(rec_hist,   Year %in% common_years)

# ---- B) % of years > 0 by decade ----
freq_models <- model_fits %>%
  mutate(decade = 10L * floor(Year/10L)) %>%
  group_by(ESM, Variable, region, decade) %>%
  summarise(p_above = mean(value > 0, na.rm = TRUE), .groups = "drop")

freq_rec <- rec_hist %>%
  mutate(decade = 10L * floor(Year/10L)) %>%
  group_by(ESM, Variable, region, decade) %>%
  summarise(p_above = mean(value > 0, na.rm = TRUE), .groups = "drop")

freq_hist <- bind_rows(freq_models, freq_rec) %>%
  mutate(
    region   = factor(region, levels = rev(desired)),  # bottom→top
    decade   = factor(decade, levels = sort(unique(decade))),
    Variable = factor(Variable,
                      levels = c("DO model", "pH model", "Temperature model", "Rec dev"))
  )

library(ggplot2)
library(scales)

ggplot(freq_hist, aes(decade, region, fill = p_above)) +
  geom_tile(color = "white", linewidth = 0.3) +
  geom_text(aes(label = percent(p_above, 1)), size = 3, color = 'white') +
  facet_grid(~Variable, switch = "y",
             scales = "free_y", space = "free_y", drop = FALSE) +
  scale_fill_viridis_c(option = "mako", limits = c(0,1), name = "% years > 0") +
  scale_y_discrete(
    limits = rev(desired),
    labels = c(north="North", mid="Mid", south="South", all="All"),
    drop   = TRUE
  ) +
  labs(x = "Decade", y = NULL,
       title = "") +
  theme_bw() +
  theme(panel.grid = element_blank())


ggsave("Recruitment_projection_all_positive_percentages_historical.png", width = 10, height = 6, dpi = 300)
```

